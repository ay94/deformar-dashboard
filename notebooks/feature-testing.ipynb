{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 00:00:25 - INFO - PyTorch version 2.2.2 available.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from experiment_utils.env_setup import init\n",
    "from experiment_utils.utils import FileHandler\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_utils.utils import FileHandler\n",
    "from experiment_utils.env_setup import init\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Any, List\n",
    "import yaml\n",
    "\n",
    "@dataclass\n",
    "class DevelopmentConfig:\n",
    "    debug: bool = False\n",
    "    port: int = 8000\n",
    "    def __post_init__(self):\n",
    "        if not isinstance(self.debug, bool):\n",
    "            raise ValueError(f\"Expected boolean for debug, got {type(self.debug).__name__}\")\n",
    "        if not (1 <= self.port <= 65535):\n",
    "            raise ValueError(\"Port must be between 1 and 65535\")\n",
    "    @staticmethod\n",
    "    def from_dict(config_dict: Dict[str, Any]):\n",
    "        return DevelopmentConfig(**config_dict)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TabConfig:\n",
    "    tab_value: str\n",
    "    tab_label: str\n",
    "    \n",
    "@dataclass\n",
    "class AppConfig:\n",
    "    tabs: List[TabConfig] = field(default_factory=list)\n",
    "    variants: List[str] = field(default_factory=list)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if not all(isinstance(tab, TabConfig) for tab in self.tabs):\n",
    "            raise ValueError(\"Tabs must be a list of TabConfig instances\")\n",
    "        if not all(isinstance(variant, str) for variant in self.variants):\n",
    "            raise ValueError(\"Variants must be a list of strings\")\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(config_dict: Dict[str, Any]):\n",
    "        tabs = [TabConfig(**tab) for tab in config_dict.get('tabs', [])]\n",
    "        variants = config_dict.get('variants', [])\n",
    "        return AppConfig(tabs=tabs, variants=variants)\n",
    "\n",
    "class DashboardConfigManager:\n",
    "    def __init__(self, config_path: Path):\n",
    "        self.config_path = config_path\n",
    "        config_fh = FileHandler(config_path.parent)\n",
    "        try:\n",
    "            self.config = config_fh.load_yaml(config_path.name)\n",
    "        except FileNotFoundError as e:\n",
    "            raise FileNotFoundError(f\"Configuration file not found at {config_path}\") from e\n",
    "        except yaml.YAMLError as e:\n",
    "            raise ValueError(\"Error parsing YAML configuration.\") from e\n",
    "        except ValueError as e:\n",
    "            raise ValueError(\"Validation error in configuration.\") from e\n",
    "\n",
    " \n",
    "    @property\n",
    "    def development_config(self) -> DevelopmentConfig:\n",
    "        return DevelopmentConfig.from_dict(\n",
    "            self.config.get(\"development\", {})\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def app_config(self) -> AppConfig:\n",
    "        return AppConfig.from_dict(\n",
    "            self.config.get(\"dashboard\", {})\n",
    "        )\n",
    "    @property\n",
    "    def data_dir(self) -> Path:\n",
    "        base_folder = init()\n",
    "        return base_folder / self.config.get(\"dashboard\", {}).get('data_dir', '')\n",
    "\n",
    "    @property\n",
    "    def data_config(self) -> Dict:\n",
    "        return self.config.get(\"dashboard\", {}).get(\"dashboard_data\", {}).get(\"data\", {})\n",
    "\n",
    "    @property\n",
    "    def variants(self) -> Dict:\n",
    "        return self.config.get(\"dashboard\", {}).get(\"variants\", {})\n",
    "    \n",
    "    @property\n",
    "    def dataset_tab(self) -> Dict:\n",
    "        return self.config.get(\"dashboard\", {}).get(\"dataset_tab\", {})\n",
    "    \n",
    "    @property\n",
    "    def decision_tab(self) -> Dict:\n",
    "        return self.config.get(\"dashboard\", {}).get(\"decision_tab\", {})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from tqdm.autonotebook import tqdm\n",
    "from experiment_utils.utils import FileHandler\n",
    "import pandas as pd\n",
    "from flask_caching import Cache\n",
    "import numpy as np\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Any\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "@dataclass\n",
    "class DashboardData:\n",
    "    analysis_data: pd.DataFrame = field(default_factory=pd.DataFrame)\n",
    "    train_data: pd.DataFrame = field(default_factory=pd.DataFrame)\n",
    "    kmeans_results: pd.DataFrame = field(default_factory=pd.DataFrame)\n",
    "    results: pd.DataFrame = field(default_factory=pd.DataFrame)\n",
    "    entity_report: pd.DataFrame = field(default_factory=pd.DataFrame)\n",
    "    token_report: pd.DataFrame = field(default_factory=pd.DataFrame)\n",
    "    entity_confusion_data: pd.DataFrame = field(default_factory=pd.DataFrame)\n",
    "    centroids_avg_similarity_matrix: pd.DataFrame = field(default_factory=pd.DataFrame)\n",
    "    attention_weights_similarity_heatmap: go.Figure = field(default_factory=go.Figure)\n",
    "    attention_weights_similarity_matrix: np.ndarray = field(default_factory=lambda: np.array([]))\n",
    "    attention_similarity_heatmap: go.Figure = field(default_factory=go.Figure)\n",
    "    attention_similarity_matrix: np.ndarray = field(default_factory=lambda: np.array([]))\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # Round float columns to four decimal places\n",
    "        self.round_floats(self.analysis_data)\n",
    "        self.round_floats(self.kmeans_results)\n",
    "        self.round_floats(self.results)\n",
    "\n",
    "        # Convert list to string in the 'Word Pieces' column of analysis_data if it exists\n",
    "        if 'Word Pieces' in self.analysis_data.columns:\n",
    "            self.analysis_data['Word Pieces'] = self.analysis_data['Word Pieces'].apply(\n",
    "                lambda x: ', '.join(x) if isinstance(x, list) else x\n",
    "            )\n",
    "        \n",
    "        self.analysis_data['Consistency Ratio'] = np.where(\n",
    "            self.analysis_data['Total Train Occurrences'] != 0,  # Condition to check for non-zero denominator\n",
    "            self.analysis_data['Consistency Count'] / self.analysis_data['Total Train Occurrences'],  # Normal calculation if denominator is not zero\n",
    "            0\n",
    "        )\n",
    "\n",
    "        self.analysis_data['Inconsistency Ratio'] = np.where(\n",
    "            self.analysis_data['Total Train Occurrences'] != 0,\n",
    "            self.analysis_data['Inconsistency Count'] / self.analysis_data['Total Train Occurrences'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        self.analysis_data['Normalized Token Entropy'] = DashboardData.normalized_entropy(self.analysis_data, 'Local Token Entropy', 'Token Max Entropy')  # filling 0/0 division as it generates Nan\n",
    "        self.analysis_data['Normalized Word Entropy'] = DashboardData.normalized_entropy(self.analysis_data, 'Local Token Entropy', 'Token Max Entropy')  # filling 0/0 division as it generates Nan\n",
    "        self.analysis_data['Normalized Prediction Entropy'] = DashboardData.normalized_entropy(self.analysis_data, 'Prediction Entropy', 'Prediction Max Entropy')  # filling 0/0 division as it generates Nan\n",
    "        self.analysis_data['Error Type'] = self.analysis_data.apply(\n",
    "            lambda row: DashboardData.annotate_error(\n",
    "                row['True Labels'], \n",
    "                row['Pred Labels']\n",
    "                ), \n",
    "            axis=1\n",
    "            )\n",
    "    \n",
    "    def is_loaded(self, attribute):\n",
    "        \"\"\"Checks if the given attribute is loaded based on its type.\"\"\"\n",
    "        attr_value = getattr(self, attribute)\n",
    "        if isinstance(attr_value, pd.DataFrame):\n",
    "            return not attr_value.empty\n",
    "        elif isinstance(attr_value, go.Figure):\n",
    "            return len(attr_value.data) > 0  # Check if the figure has data\n",
    "        return False  # Default case if the attribute type is unrecognized\n",
    "\n",
    "    @staticmethod\n",
    "    def round_floats(df):\n",
    "        for col in df.select_dtypes(include=['float']).columns:\n",
    "            df[col] = df[col].round(4)\n",
    "            \n",
    "    @staticmethod\n",
    "    def from_dict(dict_data: Dict[str, Any]):\n",
    "        return DashboardData(**dict_data)\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalized_entropy(df, raw_entropy, max_entropy):\n",
    "        result = np.full(df.shape[0], np.nan)\n",
    "        zero_mask = (df[raw_entropy] == 0) & (df[max_entropy] == 0)\n",
    "        result[zero_mask] = 0\n",
    "        negative_one_mask = (df[raw_entropy] == -1) & (df[max_entropy] == -1)\n",
    "        result[negative_one_mask] = -1\n",
    "        valid_mask = (df[max_entropy] != 0) & ~zero_mask & ~negative_one_mask\n",
    "        result[valid_mask] = df[raw_entropy][valid_mask] / df[max_entropy][valid_mask]\n",
    "        zero_div_mask = (df[max_entropy] == 0) & (df[raw_entropy] != 0)\n",
    "        result[zero_div_mask] = 0\n",
    "        return result\n",
    "    @staticmethod\n",
    "    def annotate_error(true_label, pred_label):\n",
    "        # If both are the same, it's correct (no error)\n",
    "        if true_label == pred_label:\n",
    "            return \"No Errors\"\n",
    "        \n",
    "        # Handle cases where one or both labels are 'O'\n",
    "        if true_label == 'O' and pred_label != 'O':\n",
    "            return \"Chunk\"  # False entity predicted\n",
    "        if true_label != 'O' and pred_label == 'O':\n",
    "            return \"Entity and Chunk\"  # Missed entity and chunk boundary\n",
    "        \n",
    "        # Extract entity types without position tags (like \"B-\", \"I-\")\n",
    "        true_entity = true_label.split(\"-\")[-1] if \"-\" in true_label else true_label\n",
    "        pred_entity = pred_label.split(\"-\")[-1] if \"-\" in pred_label else pred_label\n",
    "\n",
    "        # If entity types are different (e.g., LOC vs. PER)\n",
    "        if true_entity != pred_entity:\n",
    "            # If both entity type and position (B- vs I-) are wrong\n",
    "            return \"Entity and Chunk\" if true_label[0] != pred_label[0] else \"Entity\"\n",
    "\n",
    "        # If entity types are the same but position tags (B- vs I-) are wrong\n",
    "        return \"Chunk\"\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, config_manager, variant_name):\n",
    "        self.data_config = config_manager.data_config\n",
    "        self.data_dir = config_manager.data_dir / variant_name\n",
    "        self.dashboard_data = {}\n",
    "\n",
    "    def load(self, file_name, file_config):\n",
    "        file_handler = FileHandler(self.data_dir / file_config['folder'])\n",
    "        file_type = file_config[\"format\"]\n",
    "        file_path = file_handler.file_path / f\"{file_name}.{file_type}\"\n",
    "\n",
    "        try:\n",
    "            if file_path.exists():\n",
    "                # Load Plotly figures specifically\n",
    "                if file_type == \"npy\":\n",
    "                    return file_handler.load_numpy(file_path.with_suffix('.npy'))\n",
    "\n",
    "                # Handle regular JSON data files\n",
    "                elif file_type == \"json\":\n",
    "                    data = file_handler.read_json(file_path)\n",
    "                    if \"column_mappings\" in file_config and file_config[\"column_mappings\"]:\n",
    "                        data = self.apply_column_mappings(data, file_config[\"column_mappings\"])\n",
    "                    return data\n",
    "            else:\n",
    "                logging.warning(\"File does not exist: %s\", file_path)\n",
    "        except Exception as e:\n",
    "            logging.error(\"Failed to load data from %s: %s\", file_path, e)\n",
    "            return None\n",
    "        \n",
    "    def apply_column_mappings(self, data: pd.DataFrame, column_mappings: dict) -> pd.DataFrame:\n",
    "        \"\"\" Rename columns in the DataFrame based on provided mappings. \"\"\"\n",
    "        return data.rename(columns=column_mappings)\n",
    "\n",
    "\n",
    "    def load_all(self):\n",
    "        \n",
    "        logging.info(\"Loading Dashboard Data from  %s\", self.data_dir)\n",
    "        for file_name, file_config in tqdm(self.data_config.items()):\n",
    "            self.dashboard_data[file_name] = self.load(file_name, file_config)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "class DataManager:\n",
    "    def __init__(self, config_manager, server) -> None:\n",
    "        self.config_manager = config_manager\n",
    "        self.variants = config_manager.variants\n",
    "        self.cache = Cache(server, config={\n",
    "            'CACHE_TYPE': 'filesystem',\n",
    "            'CACHE_DIR': 'cache-directory',\n",
    "            'CACHE_DEFAULT_TIMEOUT': 3600  # Cache timeout of 1 hour\n",
    "        })\n",
    "        self.cache.init_app(server)\n",
    "        self.variants_data = self.load_all_variants_from_cache()\n",
    "    \n",
    "    def load_all_variants_from_cache(self):\n",
    "        data = {}\n",
    "        for variant in self.variants:\n",
    "            cached_data = self.cache.get(variant)\n",
    "            if cached_data:\n",
    "                data[variant] = cached_data\n",
    "        return data\n",
    "\n",
    "    \n",
    "    def load_variant(self, variant):\n",
    "        \"\"\"Loads data for a specific variant, with caching.\"\"\"\n",
    "        cached_data = self.cache.get(variant)\n",
    "        if cached_data is None:\n",
    "            loader = DataLoader(self.config_manager, variant)\n",
    "            loader.load_all()\n",
    "            data = DashboardData.from_dict(loader.dashboard_data)\n",
    "            self.variants_data[variant] = data\n",
    "            self.cache.set(variant, data)  # Cache the newly loaded data\n",
    "            return data  # Return the new data\n",
    "        self.variants_data[variant] = cached_data\n",
    "        return cached_data  # Return the cached data if it was already loaded\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"Loads data for all variants using the load_variant method for consistency.\"\"\"\n",
    "        for variant in self.variants:\n",
    "            # Delegate the loading and caching to load_variant method\n",
    "            self.variants_data[variant] = self.load_variant(variant)\n",
    "        return self.variants_data\n",
    "\n",
    "    def is_data_loaded(self):\n",
    "        \"\"\"Checks if all variants have data loaded in the cache.\"\"\"\n",
    "        for variant in self.variants:\n",
    "            if self.cache.get(variant) is None:\n",
    "                return False  # Return False if any variant is not loaded\n",
    "        return True  # Return True if all variants are loaded\n",
    "    \n",
    "    def is_any_variant_loaded(self):\n",
    "        \"\"\"\n",
    "        Check if any variant is loaded in the cache.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if at least one variant is loaded, False otherwise.\n",
    "        \"\"\"\n",
    "        for variant in self.variants:\n",
    "            if self.cache.get(variant) is not None:\n",
    "                return True  # Return True if any variant is loaded\n",
    "        return False  # Return False if no variants are loaded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = Path(\"/Users/ay227/Desktop/Final-Year/Thesis-Experiments/Online-Dashboard-Phase/dashboard-config.yaml\")\n",
    "config_manager = DashboardConfigManager(CONFIG_PATH)\n",
    "dev_config = config_manager.development_config    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/Users/ay227/Library/CloudStorage/GoogleDrive-ahmed.younes.sam@gmail.com/My Drive/Final Year Experiments/Thesis-Experiments/Experiments/ExperimentData/corpora.json', 'r') as file:\n",
    "    corpora = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "الصالحية B-LOC\n",
      "المفرق B-LOC\n",
      "- O\n",
      "غيث B-PERS\n",
      "الطراونة I-PERS\n",
      "- O\n",
      "أمر O\n",
      "جلالة O\n",
      "الملك O\n",
      "عبدالله B-PERS\n",
      "الثاني I-PERS\n",
      "أمس O\n",
      "بتنفيذ O\n",
      "حزمة O\n",
      "من O\n",
      "المشاريع O\n",
      "التعليمية O\n",
      "والصحية O\n",
      "والتنموية O\n",
      "وأخرى O\n",
      "مرتبطة O\n",
      "بالأندية O\n",
      "الشبابية O\n",
      "و O\n",
      "27 O\n",
      "وحدة O\n",
      "سكنية O\n",
      "في O\n",
      "قضاء O\n",
      "الصالحية B-LOC\n",
      "ونايفة B-LOC\n",
      "في O\n",
      "البادية O\n",
      "الشرقية O\n",
      "خلال O\n",
      "ستة O\n",
      "اشهر O\n",
      "بتمويل O\n",
      "من O\n",
      "الديوان O\n",
      "الملكي O\n",
      "الهاشمي O\n",
      ". O\n"
     ]
    }
   ],
   "source": [
    "for data in corpora['ANERCorp_CamelLab']['splits']['test']:\n",
    "    for word, tag in zip(data['words'], data['tags']):\n",
    "        print(word, tag)\n",
    "\n",
    " \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125102\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame([{'word':w, 'tag':t} for data in corpora['ANERCorp_CamelLab']['splits']['train'] for w, t in zip(data['words'], data['tags'])])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 'tag'\n",
    "word_col = 'word'\n",
    "counts = df['tag'].value_counts().sort_index()\n",
    "types = df.groupby('tag')[\n",
    "\t'word'\n",
    "].nunique()\n",
    "ratios = types / counts\n",
    "\n",
    "token_distribution_df = pd.DataFrame(\n",
    "\t{\n",
    "\t\t'count': counts,\n",
    "\t\t'types': types,\n",
    "\t\t'ratio': ratios,\n",
    "\t}\n",
    ")\n",
    "\n",
    "totals = df['word'].agg([\"size\", \"nunique\"]).tolist()\n",
    "ne_totals = (\n",
    "\tdf[df[label_col] != \"O\"][word_col]\n",
    "\t.agg([\"size\", \"nunique\"])\n",
    "\t.tolist()\n",
    ")\n",
    "\n",
    "token_distribution_df.loc[\"Total\"] = totals + [totals[1] / totals[0]]\n",
    "token_distribution_df.loc[\"Total NEs\"] = ne_totals + [\n",
    "\tne_totals[1] / ne_totals[0]\n",
    "]\n",
    "\n",
    "token_distribution_df['NE Proportions'] = (\n",
    "\t\ttoken_distribution_df['count'] / ne_totals[0]\n",
    "\t)\n",
    "token_distribution_df['NE Proportions'] = token_distribution_df[\n",
    "\t'NE Proportions'\n",
    "].apply(lambda x: round(x * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Types</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>NE Proportions</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860958</td>\n",
       "      <td>-0.365725</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.741621</td>\n",
       "      <td>0.751917</td>\n",
       "      <td>0.802101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Types</th>\n",
       "      <td>0.860958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017137</td>\n",
       "      <td>0.860921</td>\n",
       "      <td>0.836661</td>\n",
       "      <td>0.686173</td>\n",
       "      <td>0.764818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ratio</th>\n",
       "      <td>-0.365725</td>\n",
       "      <td>0.017137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.365622</td>\n",
       "      <td>0.273484</td>\n",
       "      <td>-0.621199</td>\n",
       "      <td>-0.544003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE Proportions</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860921</td>\n",
       "      <td>-0.365622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.741654</td>\n",
       "      <td>0.751765</td>\n",
       "      <td>0.801963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.741621</td>\n",
       "      <td>0.836661</td>\n",
       "      <td>0.273484</td>\n",
       "      <td>0.741654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.396229</td>\n",
       "      <td>0.490564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.751917</td>\n",
       "      <td>0.686173</td>\n",
       "      <td>-0.621199</td>\n",
       "      <td>0.751765</td>\n",
       "      <td>0.396229</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.802101</td>\n",
       "      <td>0.764818</td>\n",
       "      <td>-0.544003</td>\n",
       "      <td>0.801963</td>\n",
       "      <td>0.490564</td>\n",
       "      <td>0.992658</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Count     Types     Ratio  NE Proportions  Precision  \\\n",
       "Count           1.000000  0.860958 -0.365725        1.000000   0.741621   \n",
       "Types           0.860958  1.000000  0.017137        0.860921   0.836661   \n",
       "Ratio          -0.365725  0.017137  1.000000       -0.365622   0.273484   \n",
       "NE Proportions  1.000000  0.860921 -0.365622        1.000000   0.741654   \n",
       "Precision       0.741621  0.836661  0.273484        0.741654   1.000000   \n",
       "Recall          0.751917  0.686173 -0.621199        0.751765   0.396229   \n",
       "F1              0.802101  0.764818 -0.544003        0.801963   0.490564   \n",
       "\n",
       "                  Recall        F1  \n",
       "Count           0.751917  0.802101  \n",
       "Types           0.686173  0.764818  \n",
       "Ratio          -0.621199 -0.544003  \n",
       "NE Proportions  0.751765  0.801963  \n",
       "Precision       0.396229  0.490564  \n",
       "Recall          1.000000  0.992658  \n",
       "F1              0.992658  1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Training data\n",
    "train_data = {\n",
    "    'Tag': ['B-LOC', 'B-PERS', 'I-PERS', 'B-ORG', 'I-ORG', 'B-MISC', 'I-LOC', 'I-MISC'],\n",
    "    'Count': [3776, 2721, 2205, 1576, 1115, 888, 525, 375],\n",
    "    'Types': [905, 1089, 1110, 522, 401, 343, 145, 220],\n",
    "    'Ratio': [0.239672, 0.400221, 0.503401, 0.331218, 0.359641, 0.386261, 0.276190, 0.586667],\n",
    "    'NE Proportions': [28.65, 20.64, 16.73, 11.96, 8.46, 6.74, 3.98, 2.85]\n",
    "}\n",
    "\n",
    "# Test data - classification report on the test\n",
    "test_data = {\n",
    "    'Tag': ['B-LOC', 'B-MISC', 'B-ORG', 'B-PERS', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PERS'],\n",
    "    'Precision': [0.903272, 0.814433, 0.810875, 0.890346, 0.802326, 0.858823, 0.804688, 0.910798],\n",
    "    'Recall': [0.950599, 0.672340, 0.762222, 0.870629, 0.831325, 0.442424, 0.749091, 0.907956],\n",
    "    'F1': [0.926331, 0.736597, 0.785796, 0.880377, 0.816568, 0.584000, 0.775895, 0.909375]\n",
    "}\n",
    "\n",
    "# Convert dictionaries to DataFrames\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Merge the two DataFrames on Tag\n",
    "combined_df = pd.merge(train_df, test_df, on='Tag')\n",
    "\n",
    "# Remove the 'Tag' column for correlation computation\n",
    "numeric_df = combined_df.drop('Tag', axis=1)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "correlation_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Tag=B-LOC<br>Token-Type Ratio=%{x}<br>F1 Score=%{y}<extra></extra>",
         "legendgroup": "B-LOC",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "B-LOC",
         "orientation": "v",
         "showlegend": true,
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.239672
         ],
         "xaxis": "x",
         "y": [
          0.926331
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Tag=B-PERS<br>Token-Type Ratio=%{x}<br>F1 Score=%{y}<extra></extra>",
         "legendgroup": "B-PERS",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "B-PERS",
         "orientation": "v",
         "showlegend": true,
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.400221
         ],
         "xaxis": "x",
         "y": [
          0.880377
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Tag=I-PERS<br>Token-Type Ratio=%{x}<br>F1 Score=%{y}<extra></extra>",
         "legendgroup": "I-PERS",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "I-PERS",
         "orientation": "v",
         "showlegend": true,
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.503401
         ],
         "xaxis": "x",
         "y": [
          0.909375
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Tag=B-ORG<br>Token-Type Ratio=%{x}<br>F1 Score=%{y}<extra></extra>",
         "legendgroup": "B-ORG",
         "marker": {
          "color": "#ab63fa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "B-ORG",
         "orientation": "v",
         "showlegend": true,
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.331218
         ],
         "xaxis": "x",
         "y": [
          0.785796
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Tag=I-ORG<br>Token-Type Ratio=%{x}<br>F1 Score=%{y}<extra></extra>",
         "legendgroup": "I-ORG",
         "marker": {
          "color": "#FFA15A",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "I-ORG",
         "orientation": "v",
         "showlegend": true,
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.359641
         ],
         "xaxis": "x",
         "y": [
          0.775895
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Tag=B-MISC<br>Token-Type Ratio=%{x}<br>F1 Score=%{y}<extra></extra>",
         "legendgroup": "B-MISC",
         "marker": {
          "color": "#19d3f3",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "B-MISC",
         "orientation": "v",
         "showlegend": true,
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.386261
         ],
         "xaxis": "x",
         "y": [
          0.736597
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Tag=I-LOC<br>Token-Type Ratio=%{x}<br>F1 Score=%{y}<extra></extra>",
         "legendgroup": "I-LOC",
         "marker": {
          "color": "#FF6692",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "I-LOC",
         "orientation": "v",
         "showlegend": true,
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.27619
         ],
         "xaxis": "x",
         "y": [
          0.816568
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Tag=I-MISC<br>Token-Type Ratio=%{x}<br>F1 Score=%{y}<extra></extra>",
         "legendgroup": "I-MISC",
         "marker": {
          "color": "#B6E880",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "I-MISC",
         "orientation": "v",
         "showlegend": true,
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.586667
         ],
         "xaxis": "x",
         "y": [
          0.584
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Tag"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Scatter Plot of F1 Score vs. Ratio"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Token-Type Ratio"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "F1 Score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Create a scatter plot\n",
    "fig = px.scatter(combined_df, x='Ratio', y='F1', color='Tag', size_max=60, \n",
    "                 title=\"Scatter Plot of F1 Score vs. Ratio\",\n",
    "                 labels={\"Ratio\": \"Token-Type Ratio\", \"F1\": \"F1 Score\"})\n",
    "\n",
    "# Improve plot aesthetics by adding the entity tags as labels\n",
    "fig.update_traces(textposition='top center')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>types</th>\n",
       "      <th>ratio</th>\n",
       "      <th>NE Proportions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>125102.0</td>\n",
       "      <td>29252.0</td>\n",
       "      <td>0.233825</td>\n",
       "      <td>949.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>111921.0</td>\n",
       "      <td>25931.0</td>\n",
       "      <td>0.231690</td>\n",
       "      <td>849.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total NEs</th>\n",
       "      <td>13181.0</td>\n",
       "      <td>4069.0</td>\n",
       "      <td>0.308702</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-LOC</th>\n",
       "      <td>3776.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>0.239672</td>\n",
       "      <td>28.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-PERS</th>\n",
       "      <td>2721.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>0.400221</td>\n",
       "      <td>20.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PERS</th>\n",
       "      <td>2205.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>0.503401</td>\n",
       "      <td>16.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-ORG</th>\n",
       "      <td>1576.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0.331218</td>\n",
       "      <td>11.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-ORG</th>\n",
       "      <td>1115.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>0.359641</td>\n",
       "      <td>8.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MISC</th>\n",
       "      <td>888.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.386261</td>\n",
       "      <td>6.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-LOC</th>\n",
       "      <td>525.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-MISC</th>\n",
       "      <td>375.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count    types     ratio  NE Proportions\n",
       "tag                                                   \n",
       "Total      125102.0  29252.0  0.233825          949.11\n",
       "O          111921.0  25931.0  0.231690          849.11\n",
       "Total NEs   13181.0   4069.0  0.308702          100.00\n",
       "B-LOC        3776.0    905.0  0.239672           28.65\n",
       "B-PERS       2721.0   1089.0  0.400221           20.64\n",
       "I-PERS       2205.0   1110.0  0.503401           16.73\n",
       "B-ORG        1576.0    522.0  0.331218           11.96\n",
       "I-ORG        1115.0    401.0  0.359641            8.46\n",
       "B-MISC        888.0    343.0  0.386261            6.74\n",
       "I-LOC         525.0    145.0  0.276190            3.98\n",
       "I-MISC        375.0    220.0  0.586667            2.85"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_distribution_df.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>types</th>\n",
       "      <th>ratio</th>\n",
       "      <th>NE Proportions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>125102.0</td>\n",
       "      <td>29252.0</td>\n",
       "      <td>0.233825</td>\n",
       "      <td>949.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>111921.0</td>\n",
       "      <td>25931.0</td>\n",
       "      <td>0.231690</td>\n",
       "      <td>849.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total NEs</th>\n",
       "      <td>13181.0</td>\n",
       "      <td>4069.0</td>\n",
       "      <td>0.308702</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-LOC</th>\n",
       "      <td>3776.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>0.239672</td>\n",
       "      <td>28.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-PERS</th>\n",
       "      <td>2721.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>0.400221</td>\n",
       "      <td>20.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PERS</th>\n",
       "      <td>2205.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>0.503401</td>\n",
       "      <td>16.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-ORG</th>\n",
       "      <td>1576.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0.331218</td>\n",
       "      <td>11.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-ORG</th>\n",
       "      <td>1115.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>0.359641</td>\n",
       "      <td>8.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MISC</th>\n",
       "      <td>888.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.386261</td>\n",
       "      <td>6.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-LOC</th>\n",
       "      <td>525.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-MISC</th>\n",
       "      <td>375.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count    types     ratio  NE Proportions\n",
       "tag                                                   \n",
       "Total      125102.0  29252.0  0.233825          949.11\n",
       "O          111921.0  25931.0  0.231690          849.11\n",
       "Total NEs   13181.0   4069.0  0.308702          100.00\n",
       "B-LOC        3776.0    905.0  0.239672           28.65\n",
       "B-PERS       2721.0   1089.0  0.400221           20.64\n",
       "I-PERS       2205.0   1110.0  0.503401           16.73\n",
       "B-ORG        1576.0    522.0  0.331218           11.96\n",
       "I-ORG        1115.0    401.0  0.359641            8.46\n",
       "B-MISC        888.0    343.0  0.386261            6.74\n",
       "I-LOC         525.0    145.0  0.276190            3.98\n",
       "I-MISC        375.0    220.0  0.586667            2.85"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_distribution_df.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variability(df):\n",
    "\timport pandas as pd\n",
    "\n",
    "\t# Assuming df is already defined and structured with 'tag' and 'word' columns\n",
    "\n",
    "\t# Calculate counts and types\n",
    "\tcounts = df['tag'].value_counts().sort_index()\n",
    "\ttypes = df.groupby('tag')['word'].nunique()\n",
    "\tratios = types / counts\n",
    "\n",
    "\t# Create the distribution DataFrame\n",
    "\ttoken_distribution_df = pd.DataFrame({\n",
    "\t\t'count': counts,\n",
    "\t\t'types': types,\n",
    "\t\t'ratio': ratios\n",
    "\t})\n",
    "\n",
    "\t# Calculate total tokens and unique tags\n",
    "\ttotal_tokens = df['tag'].count()\n",
    "\tunique_tags = df['tag'].nunique()\n",
    "\n",
    "\t# Calculate total tokens and unique NE tags (not 'O')\n",
    "\ttotal_ne_tokens = df[df['tag'] != \"O\"]['tag'].count()\n",
    "\tunique_ne_tags = df[df['tag'] != \"O\"]['tag'].nunique()\n",
    "\n",
    "\t# Adding totals to the DataFrame\n",
    "\ttoken_distribution_df.loc['Total'] = [total_tokens, unique_tags, unique_tags / total_tokens]\n",
    "\ttoken_distribution_df.loc['Total NEs'] = [total_ne_tokens, unique_ne_tags, unique_ne_tags / total_ne_tokens]\n",
    "\n",
    "\n",
    "\ttoken_distribution_df['NE Proportions'] = (\n",
    "\t\ttoken_distribution_df['count'] / total_ne_tokens\n",
    "\t)\n",
    "\ttoken_distribution_df['NE Proportions'] = token_distribution_df[\n",
    "\t\t'NE Proportions'\n",
    "\t].apply(lambda x: round(x * 100, 2))\n",
    "\n",
    "\t# This displays the DataFrame to see the result\n",
    "\treturn token_distribution_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "B-LOC       905\n",
       "B-MISC      343\n",
       "B-ORG       522\n",
       "B-PERS     1089\n",
       "I-LOC       145\n",
       "I-MISC      220\n",
       "I-ORG       401\n",
       "I-PERS     1110\n",
       "O         25931\n",
       "Name: word, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>types</th>\n",
       "      <th>ratio</th>\n",
       "      <th>NE Proportions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B-LOC</th>\n",
       "      <td>3776.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>0.239672</td>\n",
       "      <td>28.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MISC</th>\n",
       "      <td>888.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.386261</td>\n",
       "      <td>6.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-ORG</th>\n",
       "      <td>1576.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0.331218</td>\n",
       "      <td>11.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-PERS</th>\n",
       "      <td>2721.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>0.400221</td>\n",
       "      <td>20.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-LOC</th>\n",
       "      <td>525.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-MISC</th>\n",
       "      <td>375.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-ORG</th>\n",
       "      <td>1115.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>0.359641</td>\n",
       "      <td>8.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PERS</th>\n",
       "      <td>2205.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>0.503401</td>\n",
       "      <td>16.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>111921.0</td>\n",
       "      <td>25931.0</td>\n",
       "      <td>0.231690</td>\n",
       "      <td>849.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>125102.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>949.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total NEs</th>\n",
       "      <td>13181.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count    types     ratio  NE Proportions\n",
       "tag                                                   \n",
       "B-LOC        3776.0    905.0  0.239672           28.65\n",
       "B-MISC        888.0    343.0  0.386261            6.74\n",
       "B-ORG        1576.0    522.0  0.331218           11.96\n",
       "B-PERS       2721.0   1089.0  0.400221           20.64\n",
       "I-LOC         525.0    145.0  0.276190            3.98\n",
       "I-MISC        375.0    220.0  0.586667            2.85\n",
       "I-ORG        1115.0    401.0  0.359641            8.46\n",
       "I-PERS       2205.0   1110.0  0.503401           16.73\n",
       "O          111921.0  25931.0  0.231690          849.11\n",
       "Total      125102.0      9.0  0.000072          949.11\n",
       "Total NEs   13181.0      8.0  0.000607          100.00"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_variability(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dash import Dash, dcc, html, Output, Input, State\n",
    "app = Dash(__name__, suppress_callback_exceptions=True)\n",
    "\n",
    "app_config = config_manager.app_config\n",
    "server = app.server  # Flask server instance for caching\n",
    "variants_data = None\n",
    "\n",
    "data_manager = DataManager(config_manager, server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 00:00:30 - WARNING - Resolved path does not exist, checking alternative paths: /Users/ay227/Desktop/Final-Year/Thesis-Experiments/Online-Dashboard-Phase/deformer-dashboard/notebooks/My Drive\n",
      "2024-11-19 00:00:30 - INFO - Found Google Drive directory for account ahmed.younes.sam@gmail.com: /Users/ay227/Library/CloudStorage/GoogleDrive-ahmed.younes.sam@gmail.com\n",
      "2024-11-19 00:00:30 - INFO - Loading Dashboard Data from  /Users/ay227/Library/CloudStorage/GoogleDrive-ahmed.younes.sam@gmail.com/My Drive/Final Year Experiments/Thesis-Experiments/Experiments/DashboardTest-v0/ANERCorp_CamelLab_arabertv02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9f98581c8541b4abcaa65a37885736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 00:00:33 - WARNING - Resolved path does not exist, checking alternative paths: /Users/ay227/Desktop/Final-Year/Thesis-Experiments/Online-Dashboard-Phase/deformer-dashboard/notebooks/My Drive\n",
      "2024-11-19 00:00:33 - INFO - Found Google Drive directory for account ahmed.younes.sam@gmail.com: /Users/ay227/Library/CloudStorage/GoogleDrive-ahmed.younes.sam@gmail.com\n",
      "2024-11-19 00:00:33 - INFO - Loading Dashboard Data from  /Users/ay227/Library/CloudStorage/GoogleDrive-ahmed.younes.sam@gmail.com/My Drive/Final Year Experiments/Thesis-Experiments/Experiments/DashboardTest-v0/conll2003_bert\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90a76a4aecd4e87ab95a042bf615e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 00:00:39 - WARNING - File does not exist: /Users/ay227/Library/CloudStorage/GoogleDrive-ahmed.younes.sam@gmail.com/My Drive/Final Year Experiments/Thesis-Experiments/Experiments/DashboardTest-v0/conll2003_bert/extractions/results/token_report.json\n",
      "2024-11-19 00:00:39 - WARNING - File does not exist: /Users/ay227/Library/CloudStorage/GoogleDrive-ahmed.younes.sam@gmail.com/My Drive/Final Year Experiments/Thesis-Experiments/Experiments/DashboardTest-v0/conll2003_bert/extractions/results/entity_report.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ANERCorp_CamelLab_arabertv02': DashboardData(analysis_data=       Sentence Ids  Token Positions     Words    Tokens Word Pieces  \\\n",
       " 0                 0                0     [CLS]     [CLS]       [CLS]   \n",
       " 1                 0                1  الصالحية  الصالحية    الصالحية   \n",
       " 2                 0                2    المفرق    المفرق      المفرق   \n",
       " 3                 0                3         -         -           -   \n",
       " 4                 0                4       غيث       غيث         غيث   \n",
       " ...             ...              ...       ...       ...         ...   \n",
       " 29706           960               10    للوليد     ##ليد  للو, ##ليد   \n",
       " 29707           960               11        بن        بن          بن   \n",
       " 29708           960               12      طلال      طلال        طلال   \n",
       " 29709           960               13         .         .           .   \n",
       " 29710           960               14     [SEP]     [SEP]       [SEP]   \n",
       " \n",
       "       Core Tokens True Labels Token Selector Id Pred Labels  Agreements  ...  \\\n",
       " 0           [CLS]       [CLS]       [CLS]@#0@#0       [CLS]        True  ...   \n",
       " 1        الصالحية       B-LOC    الصالحية@#1@#0       B-LOC        True  ...   \n",
       " 2          المفرق       B-LOC      المفرق@#2@#0       B-LOC        True  ...   \n",
       " 3               -           O           -@#3@#0           O        True  ...   \n",
       " 4             غيث      B-PERS         غيث@#4@#0      B-PERS        True  ...   \n",
       " ...           ...         ...               ...         ...         ...  ...   \n",
       " 29706     IGNORED     IGNORED  IGNORED@#10@#960     IGNORED        True  ...   \n",
       " 29707          بن      I-PERS       بن@#11@#960      I-PERS        True  ...   \n",
       " 29708        طلال      I-PERS     طلال@#12@#960      I-PERS        True  ...   \n",
       " 29709           .           O        .@#13@#960           O        True  ...   \n",
       " 29710       [SEP]       [SEP]    [SEP]@#14@#960       [SEP]        True  ...   \n",
       " \n",
       "        Prediction Max Entropy  Token Confidence  Variability    Pre X  \\\n",
       " 0                      3.1699            0.9999       0.3142   3.2159   \n",
       " 1                      3.1699            0.5035       0.2038   1.4666   \n",
       " 2                      3.1699            0.9719       0.3044   2.7272   \n",
       " 3                      3.1699            0.9998       0.3142   3.4185   \n",
       " 4                      3.1699            0.9858       0.3093   2.5611   \n",
       " ...                       ...               ...          ...      ...   \n",
       " 29706                  3.1699            0.9937       0.3120   3.2931   \n",
       " 29707                  3.1699            0.9705       0.3039   3.2259   \n",
       " 29708                  3.1699            0.9920       0.3115   3.2207   \n",
       " 29709                  3.1699            0.9999       0.3142  -1.4333   \n",
       " 29710                  3.1699            0.9418       0.2938  13.7063   \n",
       " \n",
       "          Pre Y Consistency Ratio  Inconsistency Ratio  \\\n",
       " 0       0.2505          0.000000             0.000000   \n",
       " 1       5.6270          0.000000             0.000000   \n",
       " 2       7.5411          0.000000             1.000000   \n",
       " 3       4.2370          1.000000             0.000000   \n",
       " 4       7.4964          0.000000             0.000000   \n",
       " ...        ...               ...                  ...   \n",
       " 29706   9.5442          0.000000             0.000000   \n",
       " 29707   9.4135          0.903509             0.096491   \n",
       " 29708   9.6970          0.500000             0.500000   \n",
       " 29709   1.3079          1.000000             0.000000   \n",
       " 29710  10.4078          0.000000             0.000000   \n",
       " \n",
       "        Normalized Token Entropy Normalized Word Entropy  \\\n",
       " 0                     -1.000000               -1.000000   \n",
       " 1                     -1.000000               -1.000000   \n",
       " 2                      0.000000                0.000000   \n",
       " 3                      0.000000                0.000000   \n",
       " 4                     -1.000000               -1.000000   \n",
       " ...                         ...                     ...   \n",
       " 29706                 -1.000000               -1.000000   \n",
       " 29707                  0.250269                0.250269   \n",
       " 29708                  1.000000                1.000000   \n",
       " 29709                  0.000000                0.000000   \n",
       " 29710                 -1.000000               -1.000000   \n",
       " \n",
       "       Normalized Prediction Entropy  \n",
       " 0                          0.000473  \n",
       " 1                          0.357109  \n",
       " 2                          0.076122  \n",
       " 3                          0.000820  \n",
       " 4                          0.042273  \n",
       " ...                             ...  \n",
       " 29706                      0.022335  \n",
       " 29707                      0.072400  \n",
       " 29708                      0.026625  \n",
       " 29709                      0.000442  \n",
       " 29710                      0.143916  \n",
       " \n",
       " [29711 rows x 57 columns], train_data=        Sentence Ids  Token Positions          X          Y  Labels    Losses  \\\n",
       " 0                  0                0   9.446189  19.382036    -100  0.000000   \n",
       " 1                  0                1  13.791077  -3.709414       5  0.006694   \n",
       " 2                  0                2  12.713058  12.945978       0  0.000059   \n",
       " 3                  0                3  11.556602  11.655669    -100  0.000000   \n",
       " 4                  0                4   9.195292  14.356680       0  0.000398   \n",
       " ...              ...              ...        ...        ...     ...       ...   \n",
       " 147077          4148               28  10.635909   3.877772       0  0.000046   \n",
       " 147078          4148               29   8.651112   3.159802       0  0.000044   \n",
       " 147079          4148               30   8.473076   3.941707       0  0.000104   \n",
       " 147080          4148               31  -0.578020  15.568364       0  0.000043   \n",
       " 147081          4148               32  18.218866  -5.174151    -100  0.000000   \n",
       " \n",
       "         Token Ids        Global Id True Labels  \n",
       " 0               2       2_0_0_-100     IGNORED  \n",
       " 1           19876      19876_0_1_5       B-LOC  \n",
       " 2              14         14_0_2_0           O  \n",
       " 3             120     120_0_3_-100     IGNORED  \n",
       " 4             113        113_0_4_0           O  \n",
       " ...           ...              ...         ...  \n",
       " 147077       1259   1259_4148_28_0           O  \n",
       " 147078       4537   4537_4148_29_0           O  \n",
       " 147079      10776  10776_4148_30_0           O  \n",
       " 147080         20     20_4148_31_0           O  \n",
       " 147081          3   3_4148_32_-100     IGNORED  \n",
       " \n",
       " [147082 rows x 9 columns], kmeans_results=     K  Homogeneity  Completeness  V Measure\n",
       " 0  k=3       0.6574        0.3904     0.4899\n",
       " 1  k=4       0.6948        0.4378     0.5371\n",
       " 2  k=9       0.7487        0.2878     0.4158, results=   Precision  Recall      F1    Loss    Type  True Score  Pred Score\n",
       " 0     0.8435  0.8121  0.8275  0.1542  Entity      0.6064      0.6497\n",
       " 1     0.8646  0.7977  0.8227  0.1542   Token      0.6064      0.6497, entity_report=        Tag  Precision    Recall        F1  Support\n",
       " 0       LOC   0.889204  0.926036  0.907246      676\n",
       " 1      MISC   0.712195  0.600823  0.651786      243\n",
       " 2       ORG   0.760181  0.732026  0.745838      459\n",
       " 3      PERS   0.880756  0.824309  0.851598      905\n",
       " 4     micro   0.843494  0.812089  0.827494     2283\n",
       " 5     macro   0.810584  0.770799  0.789117     2283\n",
       " 6  weighted   0.841074  0.812089  0.825545     2283, token_report=               Tag  Precision    Recall        F1  Support\n",
       " 0            B-LOC   0.903272  0.950599  0.926331      668\n",
       " 1           B-MISC   0.814433  0.672340  0.736597      235\n",
       " 2            B-ORG   0.810875  0.762222  0.785796      450\n",
       " 3           B-PERS   0.890346  0.870629  0.880377      858\n",
       " 4            I-LOC   0.802326  0.831325  0.816568       83\n",
       " 5           I-MISC   0.858823  0.442424  0.584000      165\n",
       " 6            I-ORG   0.804688  0.749091  0.775895      275\n",
       " 7           I-PERS   0.910798  0.907956  0.909375      641\n",
       " 8                O   0.985895  0.992737  0.989304    21616\n",
       " 9   accuracy/micro   0.971230  0.971230  0.971230    24991\n",
       " 10           macro   0.864606  0.797703  0.822694    24991\n",
       " 11        weighted   0.970274  0.971230  0.970192    24991, entity_confusion_data=     True Entity Pred Entity\n",
       " 0            LOC         LOC\n",
       " 1            LOC         LOC\n",
       " 2           PERS        PERS\n",
       " 3           PERS        PERS\n",
       " 4            LOC         LOC\n",
       " ...          ...         ...\n",
       " 2622        PERS        PERS\n",
       " 2623        MISC        MISC\n",
       " 2624        PERS        PERS\n",
       " 2625        PERS        PERS\n",
       " 2626        PERS        PERS\n",
       " \n",
       " [2627 rows x 2 columns], centroids_avg_similarity_matrix=  NER_Label  Centroid_0  Centroid_1  Centroid_2  Centroid_3  Centroid_4  \\\n",
       " 0     B-LOC    0.000159    0.110372    0.778067    0.238323    0.102824   \n",
       " 1    B-MISC    0.161146    0.276571    0.216935    0.239016    0.138915   \n",
       " 2     B-ORG    0.117952    0.198506    0.279765    0.265838    0.108693   \n",
       " 3    B-PERS    0.105312    0.220289    0.217902    0.147642    0.404442   \n",
       " 4     I-LOC   -0.052538    0.070811    0.417726    0.449961    0.154726   \n",
       " 5    I-MISC    0.151626    0.290172    0.177181    0.440383    0.214565   \n",
       " 6     I-ORG    0.097389    0.190633    0.144026    0.652162    0.236228   \n",
       " 7    I-PERS   -0.058109    0.132747    0.115143    0.310455    0.810527   \n",
       " 8         O    0.763198    0.841878    0.079293    0.194419    0.050664   \n",
       " \n",
       "    Centroid_5  Centroid_6  Centroid_7  Centroid_8  \n",
       " 0    0.105067    0.327364    0.069935    0.213443  \n",
       " 1    0.284259    0.467925    0.232873    0.235491  \n",
       " 2    0.223994    0.658015    0.169506    0.320092  \n",
       " 3    0.179764    0.375379    0.172710    0.786350  \n",
       " 4    0.042193    0.148059    0.025864    0.109649  \n",
       " 5    0.266436    0.255834    0.244708    0.140011  \n",
       " 6    0.190476    0.297658    0.162862    0.113194  \n",
       " 7    0.035190    0.161739    0.061255    0.426182  \n",
       " 8    0.836385    0.235145    0.856317    0.185435  , attention_weights_similarity_heatmap=                                                data  \\\n",
       " 0  [{'coloraxis': 'coloraxis', 'name': '0', 'z': ...   \n",
       " \n",
       "                                               layout  \n",
       " 0  {'template': {'data': {'barpolar': [{'marker':...  , attention_weights_similarity_matrix=array([[0.99985043, 0.99985491, 0.99984048, 0.9998638 , 0.99984272,\n",
       "         0.99985368, 0.99983957, 0.99986179, 0.99985418, 0.9998463 ,\n",
       "         0.99984583, 0.9998297 ],\n",
       "        [0.99984999, 0.9998481 , 0.99983555, 0.9998418 , 0.99984073,\n",
       "         0.99983812, 0.99983663, 0.9998457 , 0.99984184, 0.9998402 ,\n",
       "         0.99983968, 0.99983907],\n",
       "        [0.99984576, 0.99984427, 0.99983585, 0.99984545, 0.99983683,\n",
       "         0.99983681, 0.9998374 , 0.99985395, 0.99984058, 0.99983743,\n",
       "         0.99984185, 0.99983746],\n",
       "        [0.99987574, 0.99987806, 0.99987043, 0.99987492, 0.99987264,\n",
       "         0.99988057, 0.99987154, 0.99987631, 0.99988046, 0.99987404,\n",
       "         0.99987458, 0.9998702 ],\n",
       "        [0.99985626, 0.99986006, 0.99984564, 0.9998525 , 0.99985143,\n",
       "         0.99984769, 0.99984982, 0.99985605, 0.99985166, 0.9998496 ,\n",
       "         0.99984847, 0.9998487 ],\n",
       "        [0.99987014, 0.99986876, 0.99985356, 0.99986212, 0.99986298,\n",
       "         0.9998605 , 0.999859  , 0.99986443, 0.99986072, 0.99985986,\n",
       "         0.99985957, 0.99985823],\n",
       "        [0.99988448, 0.99988749, 0.99987149, 0.9998792 , 0.99987835,\n",
       "         0.99988593, 0.99987644, 0.99988193, 0.99988007, 0.99987947,\n",
       "         0.99987801, 0.99987743],\n",
       "        [0.99986023, 0.99985942, 0.99984376, 0.99984664, 0.99985375,\n",
       "         0.9998493 , 0.99984819, 0.99985394, 0.99985298, 0.99984792,\n",
       "         0.99984808, 0.99984714],\n",
       "        [0.99985273, 0.99985776, 0.99984055, 0.99984288, 0.99984673,\n",
       "         0.99984607, 0.99984495, 0.99985004, 0.99985122, 0.99984849,\n",
       "         0.99984445, 0.99984508],\n",
       "        [0.99987459, 0.99987509, 0.99986218, 0.99986901, 0.9998682 ,\n",
       "         0.99987145, 0.99987012, 0.99987332, 0.99987118, 0.99986902,\n",
       "         0.99986894, 0.99986862],\n",
       "        [0.99985984, 0.99985965, 0.99985293, 0.99985407, 0.99985479,\n",
       "         0.99985882, 0.99986079, 0.99985916, 0.99986204, 0.99986192,\n",
       "         0.99985728, 0.99985579],\n",
       "        [0.99988279, 0.99988332, 0.99987157, 0.99987393, 0.99987817,\n",
       "         0.99987992, 0.99988356, 0.9998824 , 0.99988366, 0.99988175,\n",
       "         0.9998802 , 0.99987837]]), attention_similarity_heatmap=                                                data  \\\n",
       " 0  [{'coloraxis': 'coloraxis', 'name': '0', 'z': ...   \n",
       " \n",
       "                                               layout  \n",
       " 0  {'template': {'data': {'barpolar': [{'marker':...  , attention_similarity_matrix=array([[0.99986648, 0.9966952 , 0.99860119, 0.99998992, 0.99800887,\n",
       "         0.99901466, 0.99788082, 0.99695247, 0.99805348, 0.99815053,\n",
       "         0.9977269 , 0.99808007],\n",
       "        [0.97577252, 0.98099651, 0.9888171 , 0.99686549, 0.99791769,\n",
       "         0.99406816, 0.99780185, 0.98454665, 0.99101431, 0.99308986,\n",
       "         0.9836597 , 0.97807556],\n",
       "        [0.99214519, 0.98240346, 0.9944721 , 0.97599752, 0.99058271,\n",
       "         0.96117443, 0.9950746 , 0.97887396, 0.98032732, 0.99118058,\n",
       "         0.98117481, 0.96982719],\n",
       "        [0.99961323, 0.99762053, 0.94177362, 0.94868995, 0.97310458,\n",
       "         0.97449027, 0.96828292, 0.9751897 , 0.975905  , 0.94243248,\n",
       "         0.97767571, 0.98640166],\n",
       "        [0.94985303, 0.96596976, 0.94609946, 0.96959513, 0.9598639 ,\n",
       "         0.98035952, 0.95122868, 0.96495381, 0.95060498, 0.96218903,\n",
       "         0.93666776, 0.97283731],\n",
       "        [0.96052356, 0.90670016, 0.95180952, 0.95174888, 0.9560535 ,\n",
       "         0.9729397 , 0.94910909, 0.94621873, 0.97063378, 0.95950999,\n",
       "         0.92510013, 0.96913113],\n",
       "        [0.88526424, 0.88243722, 0.9674858 , 0.9588392 , 0.88719972,\n",
       "         0.95720757, 0.93768054, 0.94025236, 0.93438945, 0.95234245,\n",
       "         0.94138772, 0.95432926],\n",
       "        [0.95100794, 0.94717807, 0.92577517, 0.90826391, 0.91249978,\n",
       "         0.93308018, 0.95955525, 0.94398185, 0.88476319, 0.94966536,\n",
       "         0.96055011, 0.94795708],\n",
       "        [0.91623544, 0.93987344, 0.9326963 , 0.83378596, 0.95235388,\n",
       "         0.98790562, 0.89313118, 0.79094253, 0.9012141 , 0.87019206,\n",
       "         0.90893692, 0.93325105],\n",
       "        [0.75465674, 0.97338332, 0.91566299, 0.94264487, 0.88207969,\n",
       "         0.76145924, 0.8820001 , 0.90129685, 0.93881698, 0.92472057,\n",
       "         0.84468754, 0.97662532],\n",
       "        [0.84285481, 0.9433445 , 0.99074068, 0.96978346, 0.93254214,\n",
       "         0.98942883, 0.82054437, 0.89377329, 0.89825307, 0.62678108,\n",
       "         0.94612181, 0.84995791],\n",
       "        [0.97799638, 0.9854097 , 0.98276825, 0.97772921, 0.9784754 ,\n",
       "         0.76919532, 0.98188955, 0.98334463, 0.7713172 , 0.97303129,\n",
       "         0.74536981, 0.87397374]])),\n",
       " 'conll2003_bert': DashboardData(analysis_data=       Sentence Ids  Token Positions    Words   Tokens         Word Pieces  \\\n",
       " 0                 0                0    [CLS]    [CLS]               [CLS]   \n",
       " 1                 0                1   SOCCER        S  S, ##OC, ##CE, ##R   \n",
       " 2                 0                2   SOCCER     ##OC  S, ##OC, ##CE, ##R   \n",
       " 3                 0                3   SOCCER     ##CE  S, ##OC, ##CE, ##R   \n",
       " 4                 0                4   SOCCER      ##R  S, ##OC, ##CE, ##R   \n",
       " ...             ...              ...      ...      ...                 ...   \n",
       " 70362          3452               39  brother  brother             brother   \n",
       " 70363          3452               40        ,        ,                   ,   \n",
       " 70364          3452               41    Bobby    Bobby               Bobby   \n",
       " 70365          3452               42        .        .                   .   \n",
       " 70366          3452               43    [SEP]    [SEP]               [SEP]   \n",
       " \n",
       "       Core Tokens True Labels  Token Selector Id Pred Labels  Agreements  ...  \\\n",
       " 0           [CLS]       [CLS]        [CLS]@#0@#0       [CLS]        True  ...   \n",
       " 1               S           O            S@#1@#0           O        True  ...   \n",
       " 2         IGNORED     IGNORED      IGNORED@#2@#0     IGNORED        True  ...   \n",
       " 3         IGNORED     IGNORED      IGNORED@#3@#0     IGNORED        True  ...   \n",
       " 4         IGNORED     IGNORED      IGNORED@#4@#0     IGNORED        True  ...   \n",
       " ...           ...         ...                ...         ...         ...  ...   \n",
       " 70362     brother           O  brother@#39@#3452           O        True  ...   \n",
       " 70363           ,           O        ,@#40@#3452           O        True  ...   \n",
       " 70364       Bobby       B-PER    Bobby@#41@#3452       B-PER        True  ...   \n",
       " 70365           .           O        .@#42@#3452           O        True  ...   \n",
       " 70366       [SEP]       [SEP]    [SEP]@#43@#3452       [SEP]        True  ...   \n",
       " \n",
       "        Prediction Max Entropy  Token Confidence  Variability    Pre X  \\\n",
       " 0                      3.1699            0.9989       0.3139  12.7496   \n",
       " 1                      3.1699            0.9999       0.3142  10.5721   \n",
       " 2                      3.1699            0.9993       0.3140   1.7940   \n",
       " 3                      3.1699            0.9952       0.3126  -2.4401   \n",
       " 4                      3.1699            0.9998       0.3142   6.4735   \n",
       " ...                       ...               ...          ...      ...   \n",
       " 70362                  3.1699            1.0000       0.3143   3.5682   \n",
       " 70363                  3.1699            1.0000       0.3143  15.0348   \n",
       " 70364                  3.1699            0.9994       0.3141   8.6971   \n",
       " 70365                  3.1699            1.0000       0.3143  -7.8484   \n",
       " 70366                  3.1699            0.9944       0.3123  -7.8839   \n",
       " \n",
       "          Pre Y Consistency Ratio  Inconsistency Ratio  \\\n",
       " 0      12.2885          0.000000             0.000000   \n",
       " 1      -2.9716          0.449393             0.550607   \n",
       " 2     -11.0997          0.000000             0.000000   \n",
       " 3      -4.4242          0.000000             0.000000   \n",
       " 4      -6.9634          0.000000             0.000000   \n",
       " ...        ...               ...                  ...   \n",
       " 70362   1.2847          1.000000             0.000000   \n",
       " 70363  -3.2029          0.997942             0.002058   \n",
       " 70364  -4.6001          1.000000             0.000000   \n",
       " 70365   2.3203          0.998185             0.001815   \n",
       " 70366   2.3142          0.000000             0.000000   \n",
       " \n",
       "        Normalized Token Entropy Normalized Word Entropy  \\\n",
       " 0                     -1.000000               -1.000000   \n",
       " 1                      0.754156                0.754156   \n",
       " 2                     -1.000000               -1.000000   \n",
       " 3                     -1.000000               -1.000000   \n",
       " 4                     -1.000000               -1.000000   \n",
       " ...                         ...                     ...   \n",
       " 70362                  0.000000                0.000000   \n",
       " 70363                  0.010121                0.010121   \n",
       " 70364                  0.000000                0.000000   \n",
       " 70365                  0.009690                0.009690   \n",
       " 70366                 -1.000000               -1.000000   \n",
       " \n",
       "       Normalized Prediction Entropy  \n",
       " 0                          0.004827  \n",
       " 1                          0.000379  \n",
       " 2                          0.003123  \n",
       " 3                          0.018234  \n",
       " 4                          0.001199  \n",
       " ...                             ...  \n",
       " 70362                      0.000189  \n",
       " 70363                      0.000158  \n",
       " 70364                      0.002776  \n",
       " 70365                      0.000158  \n",
       " 70366                      0.020348  \n",
       " \n",
       " [70367 rows x 57 columns], train_data=        Sentence Ids  Token Positions          X          Y  Labels    Losses  \\\n",
       " 0                  0                0   4.764799  -8.054308    -100  0.000000   \n",
       " 1                  0                1  -6.748017   5.602378       3  0.000353   \n",
       " 2                  0                2   0.758872   2.301976       0  0.000028   \n",
       " 3                  0                3  -1.787818  -9.239143       7  0.000467   \n",
       " 4                  0                4   1.128666   2.905388       0  0.000028   \n",
       " ...              ...              ...        ...        ...     ...       ...   \n",
       " 300672         14040                1  -7.254314   5.220507       3  0.000205   \n",
       " 300673         14040                2  -9.996812  -1.560116       0  0.000023   \n",
       " 300674         14040                3  -7.251644   5.241036       3  0.000212   \n",
       " 300675         14040                4 -10.050966  -1.459142       0  0.000022   \n",
       " 300676         14040                5   2.786764  15.792655    -100  0.000000   \n",
       " \n",
       "         Token Ids         Global Id True Labels  \n",
       " 0             101      101_0_0_-100     IGNORED  \n",
       " 1            7270        7270_0_1_3       B-ORG  \n",
       " 2           22961       22961_0_2_0           O  \n",
       " 3            1528        1528_0_3_7      B-MISC  \n",
       " 4            1840        1840_0_4_0           O  \n",
       " ...           ...               ...         ...  \n",
       " 300672      17057   17057_14040_1_3       B-ORG  \n",
       " 300673        122     122_14040_2_0           O  \n",
       " 300674       4617    4617_14040_3_3       B-ORG  \n",
       " 300675        123     123_14040_4_0           O  \n",
       " 300676        102  102_14040_5_-100     IGNORED  \n",
       " \n",
       " [300677 rows x 9 columns], kmeans_results=     K  Homogeneity  Completeness  V Measure\n",
       " 0  k=3       0.8136        0.7785     0.7957\n",
       " 1  k=4       0.6957        0.7339     0.7143\n",
       " 2  k=9       0.8852        0.7759     0.8269, results=   Precision  Recall      F1    Loss    Type  True Score  Pred Score\n",
       " 0     0.9043  0.9182  0.9112  0.1434  Entity      0.8694      0.8955\n",
       " 1     0.8951  0.9157  0.9050  0.1434   Token      0.8694      0.8955, entity_report=None, token_report=None, entity_confusion_data=     True Entity Pred Entity\n",
       " 0            LOC         PER\n",
       " 1              O           O\n",
       " 2              O         PER\n",
       " 3            PER         LOC\n",
       " 4              O           O\n",
       " ...          ...         ...\n",
       " 6192         ORG         ORG\n",
       " 6193         LOC         LOC\n",
       " 6194        MISC           O\n",
       " 6195           O        MISC\n",
       " 6196         PER         PER\n",
       " \n",
       " [6197 rows x 2 columns], centroids_avg_similarity_matrix=  NER_Label  Centroid_0  Centroid_1  Centroid_2  Centroid_3  Centroid_4  \\\n",
       " 0     B-LOC   -0.057194   -0.043105    0.075758   -0.111149    0.065242   \n",
       " 1    B-MISC    0.026084    0.058824    0.023692   -0.188499    0.038958   \n",
       " 2     B-ORG   -0.018843    0.055847    0.862862   -0.034486    0.116450   \n",
       " 3     B-PER   -0.042328    0.021124    0.127866   -0.208938    0.883016   \n",
       " 4     I-LOC   -0.005234   -0.061703   -0.235045    0.063070   -0.123568   \n",
       " 5    I-MISC   -0.025662    0.001543   -0.216025    0.068369   -0.169908   \n",
       " 6     I-ORG    0.042792    0.058185   -0.034477    0.868990   -0.202326   \n",
       " 7     I-PER   -0.030851   -0.127170   -0.178200   -0.015860    0.047371   \n",
       " 8         O    0.960073    0.863047   -0.025999    0.036744   -0.047219   \n",
       " \n",
       "    Centroid_5  Centroid_6  Centroid_7  Centroid_8  \n",
       " 0   -0.060930   -0.121941    0.021203    0.854913  \n",
       " 1   -0.106985    0.721324   -0.139671   -0.058776  \n",
       " 2   -0.167609   -0.059115   -0.250251    0.073515  \n",
       " 3    0.043638   -0.030927   -0.130684    0.071263  \n",
       " 4    0.045587   -0.144351    0.813560    0.025915  \n",
       " 5   -0.057141    0.270897    0.027002   -0.184260  \n",
       " 6   -0.016499   -0.199816    0.048790   -0.113365  \n",
       " 7    0.938068   -0.144888    0.051803   -0.062435  \n",
       " 8   -0.034262   -0.012009   -0.021915   -0.067686  , attention_weights_similarity_heatmap=                                                data  \\\n",
       " 0  [{'coloraxis': 'coloraxis', 'name': '0', 'z': ...   \n",
       " \n",
       "                                               layout  \n",
       " 0  {'template': {'data': {'barpolar': [{'marker':...  , attention_weights_similarity_matrix=array([[0.9985279 , 0.9985664 , 0.99855676, 0.99853633, 0.99857797,\n",
       "         0.9986076 , 0.99853178, 0.99863511, 0.99855474, 0.99856706,\n",
       "         0.99853985, 0.99857795],\n",
       "        [0.99879132, 0.99878674, 0.99879619, 0.99877834, 0.99884412,\n",
       "         0.99886935, 0.99879202, 0.9989181 , 0.99881713, 0.998762  ,\n",
       "         0.99881396, 0.99881276],\n",
       "        [0.99900976, 0.9989578 , 0.99901246, 0.99898973, 0.99904057,\n",
       "         0.99904928, 0.99901259, 0.9990505 , 0.99903868, 0.99897163,\n",
       "         0.99901967, 0.99901883],\n",
       "        [0.99900164, 0.99897562, 0.99900279, 0.99898612, 0.99903164,\n",
       "         0.9990071 , 0.99900648, 0.99903786, 0.99901297, 0.9989845 ,\n",
       "         0.99900207, 0.99899863],\n",
       "        [0.9990335 , 0.9990134 , 0.99903076, 0.99901392, 0.99905038,\n",
       "         0.99904733, 0.99904541, 0.99907686, 0.99904278, 0.99902916,\n",
       "         0.99903364, 0.99903109],\n",
       "        [0.99906121, 0.99906594, 0.9990448 , 0.99903885, 0.99909648,\n",
       "         0.9990675 , 0.99906695, 0.99909908, 0.99904844, 0.99907347,\n",
       "         0.99906058, 0.99905845],\n",
       "        [0.99904906, 0.99903366, 0.99901869, 0.9990247 , 0.99904497,\n",
       "         0.99903229, 0.99904187, 0.99907212, 0.99902431, 0.999024  ,\n",
       "         0.99903352, 0.99903079],\n",
       "        [0.99900908, 0.99903673, 0.99902534, 0.99901628, 0.9990364 ,\n",
       "         0.9990337 , 0.9990356 , 0.99904615, 0.9990088 , 0.99899307,\n",
       "         0.9990171 , 0.99903006],\n",
       "        [0.99912875, 0.9991608 , 0.99914254, 0.99912834, 0.99916654,\n",
       "         0.99915699, 0.99918906, 0.99916902, 0.99912289, 0.99914506,\n",
       "         0.99915777, 0.99916038],\n",
       "        [0.99926418, 0.99925771, 0.99924722, 0.9992584 , 0.99929245,\n",
       "         0.9992709 , 0.99925685, 0.99926692, 0.9992415 , 0.9992755 ,\n",
       "         0.99928527, 0.99928245],\n",
       "        [0.99938614, 0.99938545, 0.99939421, 0.99938449, 0.99941366,\n",
       "         0.99937293, 0.99939411, 0.99938852, 0.9993884 , 0.99940462,\n",
       "         0.99940655, 0.99941164],\n",
       "        [0.99945043, 0.99945355, 0.99943499, 0.99943753, 0.99945683,\n",
       "         0.99943901, 0.99944382, 0.99943713, 0.99945491, 0.99945539,\n",
       "         0.99946616, 0.99946221]]), attention_similarity_heatmap=                                                data  \\\n",
       " 0  [{'coloraxis': 'coloraxis', 'name': '0', 'z': ...   \n",
       " \n",
       "                                               layout  \n",
       " 0  {'template': {'data': {'barpolar': [{'marker':...  , attention_similarity_matrix=array([[0.96622194, 0.91649526, 0.98078069, 0.97170165, 0.98192725,\n",
       "         0.94059137, 0.98101486, 0.97354677, 0.98299081, 0.98458529,\n",
       "         0.97183117, 0.98551212],\n",
       "        [0.9155131 , 0.95052134, 0.96468241, 0.9243355 , 0.94781898,\n",
       "         0.93405361, 0.93259284, 0.9660278 , 0.95976176, 0.9625945 ,\n",
       "         0.97201509, 0.99303646],\n",
       "        [0.95138778, 0.93604357, 0.92548266, 0.99549879, 0.9328807 ,\n",
       "         0.9041832 , 0.90804665, 0.9561366 , 0.8990121 , 0.93438508,\n",
       "         0.95136602, 0.9084689 ],\n",
       "        [0.86108768, 0.93635957, 0.94301917, 0.91261015, 0.94143015,\n",
       "         0.91410184, 0.87001431, 0.91570199, 0.76524741, 0.9450571 ,\n",
       "         0.88044566, 0.99452642],\n",
       "        [0.85291248, 0.88726389, 0.91766554, 0.95780142, 0.94431172,\n",
       "         0.90075895, 0.97657718, 0.96913061, 0.93054592, 0.9384918 ,\n",
       "         0.85870402, 0.95729258],\n",
       "        [0.90769426, 0.97605882, 0.96848901, 0.96651403, 0.91902228,\n",
       "         0.95157087, 0.89690605, 0.91836394, 0.91234904, 0.93559951,\n",
       "         0.93821545, 0.98124713],\n",
       "        [0.89520352, 0.87110171, 0.90898989, 0.94275427, 0.95408847,\n",
       "         0.8687692 , 0.96768639, 0.90089978, 0.94221531, 0.91553149,\n",
       "         0.88165593, 0.87046749],\n",
       "        [0.83200636, 0.8829421 , 0.93505081, 0.84386919, 0.82886986,\n",
       "         0.88183304, 0.90245297, 0.88500974, 0.89599569, 0.96565268,\n",
       "         0.87025803, 0.88980512],\n",
       "        [0.83615112, 0.92646664, 0.67664213, 0.90106022, 0.95068678,\n",
       "         0.86016316, 0.78599621, 0.79919136, 0.84871818, 0.85909074,\n",
       "         0.87484121, 0.82268614],\n",
       "        [0.83008937, 0.62911284, 0.64000089, 0.71435354, 0.84866058,\n",
       "         0.66852532, 0.82166497, 0.79420136, 0.70688476, 0.89450096,\n",
       "         0.70827325, 0.8000891 ],\n",
       "        [0.69676367, 0.61348078, 0.72368352, 0.89723282, 0.8144622 ,\n",
       "         0.86173018, 0.6434729 , 0.59941183, 0.79907111, 0.82155365,\n",
       "         0.69300939, 0.81594268],\n",
       "        [0.90567732, 0.72986877, 0.62098815, 0.65345114, 0.3936852 ,\n",
       "         0.86827108, 0.8373561 , 0.89124562, 0.59544648, 0.65482999,\n",
       "         0.86309041, 0.63969274]]))}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_manager.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(data_manager.variants_data['ANERCorp_CamelLab_arabertv02'].attention_similarity_matrix, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_manager.variants_data['ANERCorp_CamelLab_arabertv02'].analysis_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True Labels\n",
       "O          21616\n",
       "IGNORED     2798\n",
       "[CLS]        961\n",
       "[SEP]        961\n",
       "B-PERS       858\n",
       "B-LOC        668\n",
       "I-PERS       641\n",
       "B-ORG        450\n",
       "I-ORG        275\n",
       "B-MISC       235\n",
       "I-MISC       165\n",
       "I-LOC         83\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['True Labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.889204</td>\n",
       "      <td>0.926036</td>\n",
       "      <td>0.907246</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.712195</td>\n",
       "      <td>0.600823</td>\n",
       "      <td>0.651786</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.732026</td>\n",
       "      <td>0.745838</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PERS</td>\n",
       "      <td>0.880756</td>\n",
       "      <td>0.824309</td>\n",
       "      <td>0.851598</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>micro</td>\n",
       "      <td>0.843494</td>\n",
       "      <td>0.812089</td>\n",
       "      <td>0.827494</td>\n",
       "      <td>2283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>macro</td>\n",
       "      <td>0.810584</td>\n",
       "      <td>0.770799</td>\n",
       "      <td>0.789117</td>\n",
       "      <td>2283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted</td>\n",
       "      <td>0.841074</td>\n",
       "      <td>0.812089</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>2283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Tag  Precision    Recall        F1  Support\n",
       "0       LOC   0.889204  0.926036  0.907246      676\n",
       "1      MISC   0.712195  0.600823  0.651786      243\n",
       "2       ORG   0.760181  0.732026  0.745838      459\n",
       "3      PERS   0.880756  0.824309  0.851598      905\n",
       "4     micro   0.843494  0.812089  0.827494     2283\n",
       "5     macro   0.810584  0.770799  0.789117     2283\n",
       "6  weighted   0.841074  0.812089  0.825545     2283"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_manager.variants_data['ANERCorp_CamelLab_arabertv02'].entity_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "confs = data_manager.variants_data['ANERCorp_CamelLab_arabertv02'].entity_confusion_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pred Entity\n",
       "LOC     626\n",
       "O        42\n",
       "MISC      4\n",
       "ORG       3\n",
       "PERS      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs[confs['True Entity'] == 'LOC']['Pred Entity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df = data_manager.variants_data['ANERCorp_CamelLab_arabertv02'].train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence Ids</th>\n",
       "      <th>Token Positions</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Token Ids</th>\n",
       "      <th>Global Id</th>\n",
       "      <th>True Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.446189</td>\n",
       "      <td>19.382036</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2_0_0_-100</td>\n",
       "      <td>IGNORED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.791077</td>\n",
       "      <td>-3.709414</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006694</td>\n",
       "      <td>19876</td>\n",
       "      <td>19876_0_1_5</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12.713058</td>\n",
       "      <td>12.945978</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>14</td>\n",
       "      <td>14_0_2_0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11.556602</td>\n",
       "      <td>11.655669</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120</td>\n",
       "      <td>120_0_3_-100</td>\n",
       "      <td>IGNORED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9.195292</td>\n",
       "      <td>14.356680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>113</td>\n",
       "      <td>113_0_4_0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147077</th>\n",
       "      <td>4148</td>\n",
       "      <td>28</td>\n",
       "      <td>10.635909</td>\n",
       "      <td>3.877772</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>1259</td>\n",
       "      <td>1259_4148_28_0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147078</th>\n",
       "      <td>4148</td>\n",
       "      <td>29</td>\n",
       "      <td>8.651112</td>\n",
       "      <td>3.159802</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>4537</td>\n",
       "      <td>4537_4148_29_0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147079</th>\n",
       "      <td>4148</td>\n",
       "      <td>30</td>\n",
       "      <td>8.473076</td>\n",
       "      <td>3.941707</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>10776</td>\n",
       "      <td>10776_4148_30_0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147080</th>\n",
       "      <td>4148</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.578020</td>\n",
       "      <td>15.568364</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>20</td>\n",
       "      <td>20_4148_31_0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147081</th>\n",
       "      <td>4148</td>\n",
       "      <td>32</td>\n",
       "      <td>18.218866</td>\n",
       "      <td>-5.174151</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3_4148_32_-100</td>\n",
       "      <td>IGNORED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147082 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence Ids  Token Positions          X          Y  Labels    Losses  \\\n",
       "0                  0                0   9.446189  19.382036    -100  0.000000   \n",
       "1                  0                1  13.791077  -3.709414       5  0.006694   \n",
       "2                  0                2  12.713058  12.945978       0  0.000059   \n",
       "3                  0                3  11.556602  11.655669    -100  0.000000   \n",
       "4                  0                4   9.195292  14.356680       0  0.000398   \n",
       "...              ...              ...        ...        ...     ...       ...   \n",
       "147077          4148               28  10.635909   3.877772       0  0.000046   \n",
       "147078          4148               29   8.651112   3.159802       0  0.000044   \n",
       "147079          4148               30   8.473076   3.941707       0  0.000104   \n",
       "147080          4148               31  -0.578020  15.568364       0  0.000043   \n",
       "147081          4148               32  18.218866  -5.174151    -100  0.000000   \n",
       "\n",
       "        Token Ids        Global Id True Labels  \n",
       "0               2       2_0_0_-100     IGNORED  \n",
       "1           19876      19876_0_1_5       B-LOC  \n",
       "2              14         14_0_2_0           O  \n",
       "3             120     120_0_3_-100     IGNORED  \n",
       "4             113        113_0_4_0           O  \n",
       "...           ...              ...         ...  \n",
       "147077       1259   1259_4148_28_0           O  \n",
       "147078       4537   4537_4148_29_0           O  \n",
       "147079      10776  10776_4148_30_0           O  \n",
       "147080         20     20_4148_31_0           O  \n",
       "147081          3   3_4148_32_-100     IGNORED  \n",
       "\n",
       "[147082 rows x 9 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence Ids</th>\n",
       "      <th>Token Positions</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Token Ids</th>\n",
       "      <th>Global Id</th>\n",
       "      <th>True Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.446189</td>\n",
       "      <td>19.382036</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2_0_0_-100</td>\n",
       "      <td>IGNORED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.791077</td>\n",
       "      <td>-3.709414</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006694</td>\n",
       "      <td>19876</td>\n",
       "      <td>19876_0_1_5</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12.713058</td>\n",
       "      <td>12.945978</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>14</td>\n",
       "      <td>14_0_2_0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11.556602</td>\n",
       "      <td>11.655669</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120</td>\n",
       "      <td>120_0_3_-100</td>\n",
       "      <td>IGNORED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9.195292</td>\n",
       "      <td>14.356680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>113</td>\n",
       "      <td>113_0_4_0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147077</th>\n",
       "      <td>4148</td>\n",
       "      <td>28</td>\n",
       "      <td>10.635909</td>\n",
       "      <td>3.877772</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>1259</td>\n",
       "      <td>1259_4148_28_0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147078</th>\n",
       "      <td>4148</td>\n",
       "      <td>29</td>\n",
       "      <td>8.651112</td>\n",
       "      <td>3.159802</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>4537</td>\n",
       "      <td>4537_4148_29_0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147079</th>\n",
       "      <td>4148</td>\n",
       "      <td>30</td>\n",
       "      <td>8.473076</td>\n",
       "      <td>3.941707</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>10776</td>\n",
       "      <td>10776_4148_30_0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147080</th>\n",
       "      <td>4148</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.578020</td>\n",
       "      <td>15.568364</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>20</td>\n",
       "      <td>20_4148_31_0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147081</th>\n",
       "      <td>4148</td>\n",
       "      <td>32</td>\n",
       "      <td>18.218866</td>\n",
       "      <td>-5.174151</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3_4148_32_-100</td>\n",
       "      <td>IGNORED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147082 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence Ids  Token Positions          X          Y  Labels    Losses  \\\n",
       "0                  0                0   9.446189  19.382036    -100  0.000000   \n",
       "1                  0                1  13.791077  -3.709414       5  0.006694   \n",
       "2                  0                2  12.713058  12.945978       0  0.000059   \n",
       "3                  0                3  11.556602  11.655669    -100  0.000000   \n",
       "4                  0                4   9.195292  14.356680       0  0.000398   \n",
       "...              ...              ...        ...        ...     ...       ...   \n",
       "147077          4148               28  10.635909   3.877772       0  0.000046   \n",
       "147078          4148               29   8.651112   3.159802       0  0.000044   \n",
       "147079          4148               30   8.473076   3.941707       0  0.000104   \n",
       "147080          4148               31  -0.578020  15.568364       0  0.000043   \n",
       "147081          4148               32  18.218866  -5.174151    -100  0.000000   \n",
       "\n",
       "        Token Ids        Global Id True Labels  \n",
       "0               2       2_0_0_-100     IGNORED  \n",
       "1           19876      19876_0_1_5       B-LOC  \n",
       "2              14         14_0_2_0           O  \n",
       "3             120     120_0_3_-100     IGNORED  \n",
       "4             113        113_0_4_0           O  \n",
       "...           ...              ...         ...  \n",
       "147077       1259   1259_4148_28_0           O  \n",
       "147078       4537   4537_4148_29_0           O  \n",
       "147079      10776  10776_4148_30_0           O  \n",
       "147080         20     20_4148_31_0           O  \n",
       "147081          3   3_4148_32_-100     IGNORED  \n",
       "\n",
       "[147082 rows x 9 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arabert.preprocess import ArabertPreprocessor\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ay227/Desktop/Final-Year/Thesis-Experiments/Online-Dashboard-Phase/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning:\n",
      "\n",
      "`clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['-', '-']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'aubmindlab/bert-base-arabertv02'\n",
    "pre = ArabertPreprocessor(model_name)\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "tok.tokenize(pre.preprocess('--'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 'True Labels'\n",
    "word_col = 'Token Ids'\n",
    "DATA = tr_df[tr_df['Labels'] != -100]\n",
    "counts = DATA[label_col].value_counts().sort_index()\n",
    "types = DATA.groupby(label_col)[\n",
    "\tword_col\n",
    "].nunique()\n",
    "ratios = types / counts\n",
    "\n",
    "token_distribution_df = pd.DataFrame(\n",
    "\t{\n",
    "\t\t'count': counts,\n",
    "\t\t'types': types,\n",
    "\t\t'ratio': ratios,\n",
    "\t}\n",
    ")\n",
    "\n",
    "totals = DATA[word_col].agg([\"size\", \"nunique\"]).tolist()\n",
    "ne_totals = (\n",
    "\tDATA[DATA[label_col] != \"O\"][word_col]\n",
    "\t.agg([\"size\", \"nunique\"])\n",
    "\t.tolist()\n",
    ")\n",
    "\n",
    "token_distribution_df.loc[\"Total\"] = totals + [totals[1] / totals[0]]\n",
    "token_distribution_df.loc[\"Total NEs\"] = ne_totals + [\n",
    "\tne_totals[1] / ne_totals[0]\n",
    "]\n",
    "\n",
    "token_distribution_df['NE Proportions'] = (\n",
    "\t\ttoken_distribution_df['count'] / ne_totals[0]\n",
    "\t)\n",
    "token_distribution_df['NE Proportions'] = token_distribution_df[\n",
    "\t'NE Proportions'\n",
    "].apply(lambda x: round(x * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>types</th>\n",
       "      <th>ratio</th>\n",
       "      <th>NE Proportions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>124659.0</td>\n",
       "      <td>23010.0</td>\n",
       "      <td>0.184584</td>\n",
       "      <td>946.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>111488.0</td>\n",
       "      <td>20911.0</td>\n",
       "      <td>0.187563</td>\n",
       "      <td>846.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total NEs</th>\n",
       "      <td>13171.0</td>\n",
       "      <td>3445.0</td>\n",
       "      <td>0.261559</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-LOC</th>\n",
       "      <td>3772.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>0.228261</td>\n",
       "      <td>28.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-PERS</th>\n",
       "      <td>2719.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>0.368886</td>\n",
       "      <td>20.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PERS</th>\n",
       "      <td>2202.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>0.456403</td>\n",
       "      <td>16.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-ORG</th>\n",
       "      <td>1576.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>0.321701</td>\n",
       "      <td>11.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-ORG</th>\n",
       "      <td>1115.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>0.350673</td>\n",
       "      <td>8.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MISC</th>\n",
       "      <td>887.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>0.375423</td>\n",
       "      <td>6.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-LOC</th>\n",
       "      <td>525.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.268571</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-MISC</th>\n",
       "      <td>375.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count    types     ratio  NE Proportions\n",
       "True Labels                                             \n",
       "Total        124659.0  23010.0  0.184584          946.47\n",
       "O            111488.0  20911.0  0.187563          846.47\n",
       "Total NEs     13171.0   3445.0  0.261559          100.00\n",
       "B-LOC          3772.0    861.0  0.228261           28.64\n",
       "B-PERS         2719.0   1003.0  0.368886           20.64\n",
       "I-PERS         2202.0   1005.0  0.456403           16.72\n",
       "B-ORG          1576.0    507.0  0.321701           11.97\n",
       "I-ORG          1115.0    391.0  0.350673            8.47\n",
       "B-MISC          887.0    333.0  0.375423            6.73\n",
       "I-LOC           525.0    141.0  0.268571            3.99\n",
       "I-MISC          375.0    217.0  0.578667            2.85"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_distribution_df.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>types</th>\n",
       "      <th>ratio</th>\n",
       "      <th>NE Proportions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>24991.0</td>\n",
       "      <td>8455.0</td>\n",
       "      <td>0.338322</td>\n",
       "      <td>740.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>21616.0</td>\n",
       "      <td>7278.0</td>\n",
       "      <td>0.336695</td>\n",
       "      <td>640.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total NEs</th>\n",
       "      <td>3375.0</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0.438519</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-PERS</th>\n",
       "      <td>858.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.566434</td>\n",
       "      <td>25.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-LOC</th>\n",
       "      <td>668.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.395210</td>\n",
       "      <td>19.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PERS</th>\n",
       "      <td>641.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.624025</td>\n",
       "      <td>18.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-ORG</th>\n",
       "      <td>450.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>13.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-ORG</th>\n",
       "      <td>275.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.549091</td>\n",
       "      <td>8.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MISC</th>\n",
       "      <td>235.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-MISC</th>\n",
       "      <td>165.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-LOC</th>\n",
       "      <td>83.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.409639</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count   types     ratio  NE Proportions\n",
       "True Labels                                           \n",
       "Total        24991.0  8455.0  0.338322          740.47\n",
       "O            21616.0  7278.0  0.336695          640.47\n",
       "Total NEs     3375.0  1480.0  0.438519          100.00\n",
       "B-PERS         858.0   486.0  0.566434           25.42\n",
       "B-LOC          668.0   264.0  0.395210           19.79\n",
       "I-PERS         641.0   400.0  0.624025           18.99\n",
       "B-ORG          450.0   205.0  0.455556           13.33\n",
       "I-ORG          275.0   151.0  0.549091            8.15\n",
       "B-MISC         235.0   120.0  0.510638            6.96\n",
       "I-MISC         165.0   111.0  0.672727            4.89\n",
       "I-LOC           83.0    34.0  0.409639            2.46"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_distribution_df.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    29711.000000\n",
       "mean        -0.177495\n",
       "std          0.515464\n",
       "min         -1.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000\n",
       "Name: Normalized Token Entropy, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Normalized Token Entropy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24991.000000\n",
       "mean         0.606392\n",
       "std          0.208912\n",
       "min         -0.737800\n",
       "25%          0.572700\n",
       "50%          0.677900\n",
       "75%          0.720700\n",
       "max          0.782200\n",
       "Name: True Silhouette Score, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['True Silhouette Score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def classify_error(true_label, pred_label):\n",
    "    # If both are the same, it's correct (no error)\n",
    "    if true_label == pred_label:\n",
    "        return \"No Errors\"\n",
    "    \n",
    "    # Handle cases where one or both labels are 'O'\n",
    "    if true_label == 'O' and pred_label != 'O':\n",
    "        return \"Chunk\"  # False entity predicted\n",
    "    if true_label != 'O' and pred_label == 'O':\n",
    "        return \"Entity and Chunk\"  # Missed entity and chunk boundary\n",
    "    \n",
    "    # Extract entity types without position tags (like \"B-\", \"I-\")\n",
    "    true_entity = true_label.split(\"-\")[-1] if \"-\" in true_label else true_label\n",
    "    pred_entity = pred_label.split(\"-\")[-1] if \"-\" in pred_label else pred_label\n",
    "\n",
    "    # If entity types are different (e.g., LOC vs. PER)\n",
    "    if true_entity != pred_entity:\n",
    "        # If both entity type and position (B- vs I-) are wrong\n",
    "        return \"Entity and Chunk\" if true_label[0] != pred_label[0] else \"Entity\"\n",
    "\n",
    "    # If entity types are the same but position tags (B- vs I-) are wrong\n",
    "    return \"Chunk\"\n",
    "\n",
    "\n",
    "# Apply the error classification\n",
    "df['Modified Error Type'] = df.apply(lambda row: classify_error(row['True Labels'], row['Pred Labels']), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token Max Entropy</th>\n",
       "      <th>Local Token Entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29698</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29699</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29702</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29704</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29709</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16035 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Token Max Entropy  Local Token Entropy\n",
       "2                    0.0                  0.0\n",
       "3                    0.0                  0.0\n",
       "8                    0.0                  0.0\n",
       "9                    0.0                  0.0\n",
       "10                   0.0                  0.0\n",
       "...                  ...                  ...\n",
       "29698                0.0                  0.0\n",
       "29699                0.0                  0.0\n",
       "29702                0.0                  0.0\n",
       "29704                0.0                  0.0\n",
       "29709                0.0                  0.0\n",
       "\n",
       "[16035 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['Token Max Entropy'] == 0)][['Token Max Entropy', 'Local Token Entropy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence Ids', 'Token Positions', 'Words', 'Tokens', 'Word Pieces',\n",
       "       'Core Tokens', 'True Labels', 'Token Selector Id', 'Pred Labels',\n",
       "       'Agreements', 'X', 'Y', 'Labels', 'Losses', 'Token Ids', 'Global Id',\n",
       "       'True Token Score', 'Pred Token Score', 'K=3', 'Boundary Clusters',\n",
       "       'K=4', 'Entity Clusters', 'K=9', 'Token Clusters', 'Consistency Count',\n",
       "       'Inconsistency Count', 'Total Train Occurrences', 'Local Token Entropy',\n",
       "       'Token Max Entropy', 'Dataset Token Entropy', 'Local Word Entropy',\n",
       "       'Word Max Entropy', 'Dataset Word Entropy', 'Tokenization Rate',\n",
       "       'TR Entity', 'PR Entity', 'Error Type', 'O Confidence',\n",
       "       'B-PERS Confidence', 'I-PERS Confidence', 'B-ORG Confidence',\n",
       "       'I-ORG Confidence', 'B-LOC Confidence', 'I-LOC Confidence',\n",
       "       'B-MISC Confidence', 'I-MISC Confidence', 'Prediction Entropy',\n",
       "       'Prediction Max Entropy', 'Token Confidence', 'Variability', 'Pre X',\n",
       "       'Pre Y', 'Consistency Ratio', 'Inconsistency Ratio',\n",
       "       'Normalized Token Entropy', 'Normalized Word Entropy',\n",
       "       'Normalized Prediction Entropy', 'Modified Error Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Local Token Entropy'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    29711\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Modified Error Type'] == df['Error Type']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modified Error Type</th>\n",
       "      <th>Error Type</th>\n",
       "      <th>True Labels</th>\n",
       "      <th>Pred Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8532</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23544</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6008</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7471</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12039</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24486</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25603</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24637</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23651</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17140</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10089</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19488</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18968</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Entity</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12189</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Entity</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>I-PERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19158</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Entity</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5094</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27371</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11823</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27345</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10803</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17295</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25071</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7678</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19373</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Entity</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13750</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26359</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24424</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21166</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Entity</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20948</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8356</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16241</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5742</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Entity</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12736</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10063</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7965</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Entity</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24925</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19242</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6260</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Entity</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8686</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13751</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4194</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21068</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Entity</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19265</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18938</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952</th>\n",
       "      <td>Entity and Chunk</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Modified Error Type Error Type True Labels Pred Labels\n",
       "8532     Entity and Chunk      Chunk      B-PERS           O\n",
       "23544    Entity and Chunk      Chunk      B-PERS           O\n",
       "6008     Entity and Chunk      Chunk      B-MISC           O\n",
       "1403     Entity and Chunk      Chunk      B-MISC           O\n",
       "7471     Entity and Chunk      Chunk       B-ORG           O\n",
       "12039    Entity and Chunk      Chunk       I-ORG           O\n",
       "24486    Entity and Chunk      Chunk      I-MISC           O\n",
       "25603    Entity and Chunk      Chunk      I-MISC           O\n",
       "24637    Entity and Chunk      Chunk       I-ORG           O\n",
       "23651    Entity and Chunk      Chunk      B-PERS           O\n",
       "17140    Entity and Chunk      Chunk       B-ORG           O\n",
       "1400     Entity and Chunk      Chunk      B-MISC           O\n",
       "2015     Entity and Chunk      Chunk      B-PERS           O\n",
       "10089    Entity and Chunk      Chunk       I-ORG           O\n",
       "19488    Entity and Chunk      Chunk      B-MISC           O\n",
       "18968    Entity and Chunk     Entity      I-MISC       B-LOC\n",
       "12189    Entity and Chunk      Chunk       I-ORG           O\n",
       "6036     Entity and Chunk     Entity      B-MISC      I-PERS\n",
       "19158    Entity and Chunk     Entity      I-MISC       B-LOC\n",
       "5094     Entity and Chunk      Chunk       B-ORG           O\n",
       "27371    Entity and Chunk      Chunk       B-ORG           O\n",
       "11823    Entity and Chunk      Chunk      I-PERS           O\n",
       "27345    Entity and Chunk      Chunk      B-PERS           O\n",
       "10803    Entity and Chunk      Chunk      I-PERS           O\n",
       "17295    Entity and Chunk      Chunk      B-MISC           O\n",
       "25071    Entity and Chunk      Chunk       B-ORG           O\n",
       "7678     Entity and Chunk      Chunk       B-ORG           O\n",
       "19373    Entity and Chunk     Entity      I-MISC       B-LOC\n",
       "13750    Entity and Chunk      Chunk       I-LOC           O\n",
       "26359    Entity and Chunk      Chunk      B-MISC           O\n",
       "24424    Entity and Chunk      Chunk      B-PERS           O\n",
       "21166    Entity and Chunk     Entity       B-LOC       I-ORG\n",
       "20948    Entity and Chunk      Chunk       B-ORG           O\n",
       "8356     Entity and Chunk      Chunk       B-ORG           O\n",
       "16241    Entity and Chunk      Chunk      B-MISC           O\n",
       "5742     Entity and Chunk     Entity      I-MISC       B-LOC\n",
       "12736    Entity and Chunk      Chunk       B-LOC           O\n",
       "10063    Entity and Chunk      Chunk       B-LOC           O\n",
       "7965     Entity and Chunk     Entity      I-MISC       B-LOC\n",
       "24925    Entity and Chunk      Chunk      B-MISC           O\n",
       "50       Entity and Chunk      Chunk      B-PERS           O\n",
       "19242    Entity and Chunk      Chunk      B-MISC           O\n",
       "6260     Entity and Chunk     Entity      B-PERS       I-ORG\n",
       "8686     Entity and Chunk      Chunk      B-PERS           O\n",
       "13751    Entity and Chunk      Chunk      B-MISC           O\n",
       "4194     Entity and Chunk      Chunk       B-ORG           O\n",
       "21068    Entity and Chunk     Entity       I-ORG       B-LOC\n",
       "19265    Entity and Chunk      Chunk      B-MISC           O\n",
       "18938    Entity and Chunk      Chunk       B-ORG           O\n",
       "9952     Entity and Chunk      Chunk       I-ORG           O"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Modified Error Type'] == \"Entity and Chunk\"][['Modified Error Type', \"Error Type\", \"True Labels\", \"Pred Labels\"]].sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence Ids', 'Token Positions', 'Words', 'Tokens', 'Word Pieces',\n",
       "       'Core Tokens', 'True Labels', 'Token Selector Id', 'Pred Labels',\n",
       "       'Agreements', 'X', 'Y', 'Labels', 'Losses', 'Token Ids', 'Global Id',\n",
       "       'True Token Score', 'Pred Token Score', 'K=3', 'Boundary Clusters',\n",
       "       'K=4', 'Entity Clusters', 'K=9', 'Token Clusters', 'Consistency Count',\n",
       "       'Inconsistency Count', 'Total Train Occurrences', 'Local Token Entropy',\n",
       "       'Token Max Entropy', 'Dataset Token Entropy', 'Local Word Entropy',\n",
       "       'Word Max Entropy', 'Dataset Word Entropy', 'Tokenization Rate',\n",
       "       'TR Entity', 'PR Entity', 'Error Type', 'O Confidence',\n",
       "       'B-PERS Confidence', 'I-PERS Confidence', 'B-ORG Confidence',\n",
       "       'I-ORG Confidence', 'B-LOC Confidence', 'I-LOC Confidence',\n",
       "       'B-MISC Confidence', 'I-MISC Confidence', 'Prediction Entropy',\n",
       "       'Prediction Max Entropy', 'Token Confidence', 'Variability', 'Pre X',\n",
       "       'Pre Y', 'Consistency Ratio', 'Inconsistency Ratio',\n",
       "       'Normalized Token Entropy', 'Normalized Word Entropy',\n",
       "       'Normalized Prediction Entropy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred Labels</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Token Confidence</th>\n",
       "      <th>B-PERS Confidence</th>\n",
       "      <th>O Confidence</th>\n",
       "      <th>B-LOC Confidence</th>\n",
       "      <th>B-ORG Confidence</th>\n",
       "      <th>Prediction Entropy</th>\n",
       "      <th>Variability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>O</td>\n",
       "      <td>7.6469</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.3138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>B-PERS</td>\n",
       "      <td>8.1570</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.3136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>O</td>\n",
       "      <td>10.0408</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.3141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>I-LOC</td>\n",
       "      <td>6.7695</td>\n",
       "      <td>0.9886</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.3103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>O</td>\n",
       "      <td>11.8740</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.3142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29010</th>\n",
       "      <td>I-PERS</td>\n",
       "      <td>5.0672</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.1329</td>\n",
       "      <td>0.3094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29068</th>\n",
       "      <td>O</td>\n",
       "      <td>9.4033</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.3137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29142</th>\n",
       "      <td>O</td>\n",
       "      <td>7.2562</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.3138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29413</th>\n",
       "      <td>I-PERS</td>\n",
       "      <td>5.9066</td>\n",
       "      <td>0.9935</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.3120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29604</th>\n",
       "      <td>I-PERS</td>\n",
       "      <td>5.7876</td>\n",
       "      <td>0.9909</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.3111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pred Labels   Losses  Token Confidence  B-PERS Confidence  O Confidence  \\\n",
       "50              O   7.6469            0.9986             0.0005        0.9986   \n",
       "379        B-PERS   8.1570            0.9981             0.9981        0.0009   \n",
       "415             O  10.0408            0.9995             0.0001        0.9995   \n",
       "762         I-LOC   6.7695            0.9886             0.0007        0.0006   \n",
       "816             O  11.8740            0.9999             0.0000        0.9999   \n",
       "...           ...      ...               ...                ...           ...   \n",
       "29010      I-PERS   5.0672            0.9862             0.0023        0.0063   \n",
       "29068           O   9.4033            0.9983             0.0007        0.9983   \n",
       "29142           O   7.2562            0.9986             0.0000        0.9986   \n",
       "29413      I-PERS   5.9066            0.9935             0.0027        0.0008   \n",
       "29604      I-PERS   5.7876            0.9909             0.0031        0.0010   \n",
       "\n",
       "       B-LOC Confidence  B-ORG Confidence  Prediction Entropy  Variability  \n",
       "50               0.0001            0.0003              0.0196       0.3138  \n",
       "379              0.0002            0.0003              0.0242       0.3136  \n",
       "415              0.0000            0.0001              0.0068       0.3141  \n",
       "762              0.0048            0.0011              0.1154       0.3103  \n",
       "816              0.0000            0.0000              0.0010       0.3142  \n",
       "...                 ...               ...                 ...          ...  \n",
       "29010            0.0002            0.0002              0.1329       0.3094  \n",
       "29068            0.0001            0.0001              0.0222       0.3137  \n",
       "29142            0.0003            0.0001              0.0185       0.3138  \n",
       "29413            0.0002            0.0002              0.0706       0.3120  \n",
       "29604            0.0002            0.0002              0.0938       0.3111  \n",
       "\n",
       "[301 rows x 9 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Losses']>5][['Pred Labels', 'Losses', 'Token Confidence', 'B-PERS Confidence', 'O Confidence', 'B-LOC Confidence', 'B-ORG Confidence', 'Prediction Entropy', 'Variability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variability</th>\n",
       "      <th>Normalized Prediction Entropy</th>\n",
       "      <th>Prediction Entropy</th>\n",
       "      <th>B-PERS Confidence</th>\n",
       "      <th>B-LOC Confidence</th>\n",
       "      <th>B-ORG Confidence</th>\n",
       "      <th>B-MISC Confidence</th>\n",
       "      <th>O Confidence</th>\n",
       "      <th>I-PERS Confidence</th>\n",
       "      <th>I-LOC Confidence</th>\n",
       "      <th>I-ORG Confidence</th>\n",
       "      <th>I-MISC Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.2287</td>\n",
       "      <td>0.354869</td>\n",
       "      <td>1.1249</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.7347</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>0.2038</td>\n",
       "      <td>0.446607</td>\n",
       "      <td>1.4157</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.1719</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.1468</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>0.2343</td>\n",
       "      <td>0.305372</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4493</th>\n",
       "      <td>0.2178</td>\n",
       "      <td>0.444115</td>\n",
       "      <td>1.4078</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0959</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6138</th>\n",
       "      <td>0.2206</td>\n",
       "      <td>0.329632</td>\n",
       "      <td>1.0449</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.6732</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.3094</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6167</th>\n",
       "      <td>0.2237</td>\n",
       "      <td>0.355595</td>\n",
       "      <td>1.1272</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6336</th>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.327960</td>\n",
       "      <td>1.0396</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.7302</td>\n",
       "      <td>0.2395</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8844</th>\n",
       "      <td>0.2277</td>\n",
       "      <td>0.385123</td>\n",
       "      <td>1.2208</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.7332</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10147</th>\n",
       "      <td>0.2199</td>\n",
       "      <td>0.330988</td>\n",
       "      <td>1.0492</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.6712</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.3089</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10148</th>\n",
       "      <td>0.2445</td>\n",
       "      <td>0.311903</td>\n",
       "      <td>0.9887</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.7899</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11351</th>\n",
       "      <td>0.2312</td>\n",
       "      <td>0.429162</td>\n",
       "      <td>1.3604</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.7606</td>\n",
       "      <td>0.0739</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11420</th>\n",
       "      <td>0.2320</td>\n",
       "      <td>0.420550</td>\n",
       "      <td>1.3331</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.7624</td>\n",
       "      <td>0.0458</td>\n",
       "      <td>0.0648</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12844</th>\n",
       "      <td>0.2131</td>\n",
       "      <td>0.336288</td>\n",
       "      <td>1.0660</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.6196</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.3685</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13225</th>\n",
       "      <td>0.2485</td>\n",
       "      <td>0.253793</td>\n",
       "      <td>0.8045</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.7916</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.2008</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14497</th>\n",
       "      <td>0.2313</td>\n",
       "      <td>0.358529</td>\n",
       "      <td>1.1365</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.7416</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.2046</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>0.2101</td>\n",
       "      <td>0.391968</td>\n",
       "      <td>1.2425</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.6347</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.3241</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16033</th>\n",
       "      <td>0.2121</td>\n",
       "      <td>0.381905</td>\n",
       "      <td>1.2106</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.6505</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.3026</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17100</th>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.426417</td>\n",
       "      <td>1.3517</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.7001</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.1942</td>\n",
       "      <td>0.0089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18261</th>\n",
       "      <td>0.1948</td>\n",
       "      <td>0.473043</td>\n",
       "      <td>1.4995</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.6252</td>\n",
       "      <td>0.1497</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18265</th>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.479984</td>\n",
       "      <td>1.5215</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.7197</td>\n",
       "      <td>0.1054</td>\n",
       "      <td>0.0606</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18949</th>\n",
       "      <td>0.2132</td>\n",
       "      <td>0.483738</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.7062</td>\n",
       "      <td>0.0803</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18968</th>\n",
       "      <td>0.2278</td>\n",
       "      <td>0.421086</td>\n",
       "      <td>1.3348</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.7485</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0483</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19164</th>\n",
       "      <td>0.1996</td>\n",
       "      <td>0.505442</td>\n",
       "      <td>1.6022</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23105</th>\n",
       "      <td>0.2399</td>\n",
       "      <td>0.295877</td>\n",
       "      <td>0.9379</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.7638</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26303</th>\n",
       "      <td>0.2348</td>\n",
       "      <td>0.395659</td>\n",
       "      <td>1.2542</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.7676</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Variability  Normalized Prediction Entropy  Prediction Entropy  \\\n",
       "35          0.2287                       0.354869              1.1249   \n",
       "4313        0.2038                       0.446607              1.4157   \n",
       "4448        0.2343                       0.305372              0.9680   \n",
       "4493        0.2178                       0.444115              1.4078   \n",
       "6138        0.2206                       0.329632              1.0449   \n",
       "6167        0.2237                       0.355595              1.1272   \n",
       "6336        0.2309                       0.327960              1.0396   \n",
       "8844        0.2277                       0.385123              1.2208   \n",
       "10147       0.2199                       0.330988              1.0492   \n",
       "10148       0.2445                       0.311903              0.9887   \n",
       "11351       0.2312                       0.429162              1.3604   \n",
       "11420       0.2320                       0.420550              1.3331   \n",
       "12844       0.2131                       0.336288              1.0660   \n",
       "13225       0.2485                       0.253793              0.8045   \n",
       "14497       0.2313                       0.358529              1.1365   \n",
       "15172       0.2101                       0.391968              1.2425   \n",
       "16033       0.2121                       0.381905              1.2106   \n",
       "17100       0.2164                       0.426417              1.3517   \n",
       "18261       0.1948                       0.473043              1.4995   \n",
       "18265       0.2174                       0.479984              1.5215   \n",
       "18949       0.2132                       0.483738              1.5334   \n",
       "18968       0.2278                       0.421086              1.3348   \n",
       "19164       0.1996                       0.505442              1.6022   \n",
       "23105       0.2399                       0.295877              0.9379   \n",
       "26303       0.2348                       0.395659              1.2542   \n",
       "\n",
       "       B-PERS Confidence  B-LOC Confidence  B-ORG Confidence  \\\n",
       "35                0.0011            0.7347            0.0019   \n",
       "4313              0.0014            0.6587            0.0050   \n",
       "4448              0.0016            0.7400            0.0011   \n",
       "4493              0.0067            0.7153            0.0387   \n",
       "6138              0.0024            0.6732            0.0096   \n",
       "6167              0.0104            0.7039            0.0202   \n",
       "6336              0.0099            0.7302            0.2395   \n",
       "8844              0.0123            0.7332            0.1978   \n",
       "10147             0.0007            0.6712            0.0148   \n",
       "10148             0.0006            0.7899            0.0096   \n",
       "11351             0.0067            0.7606            0.0739   \n",
       "11420             0.0076            0.7624            0.0458   \n",
       "12844             0.0011            0.6196            0.0020   \n",
       "13225             0.0013            0.7916            0.0011   \n",
       "14497             0.0029            0.7416            0.0094   \n",
       "15172             0.0062            0.6347            0.0057   \n",
       "16033             0.0020            0.6505            0.0037   \n",
       "17100             0.0019            0.7001            0.0118   \n",
       "18261             0.0103            0.6252            0.1497   \n",
       "18265             0.0099            0.7197            0.1054   \n",
       "18949             0.0052            0.7062            0.0803   \n",
       "18968             0.0017            0.7485            0.0034   \n",
       "19164             0.0020            0.6587            0.0038   \n",
       "23105             0.0021            0.7638            0.0024   \n",
       "26303             0.0053            0.7676            0.0163   \n",
       "\n",
       "       B-MISC Confidence  O Confidence  I-PERS Confidence  I-LOC Confidence  \\\n",
       "35                0.0009        0.0553             0.0021            0.1978   \n",
       "4313              0.0054        0.1719             0.0015            0.1468   \n",
       "4448              0.0007        0.0140             0.0009            0.2390   \n",
       "4493              0.1250        0.0959             0.0013            0.0117   \n",
       "6138              0.0009        0.3094             0.0012            0.0026   \n",
       "6167              0.0023        0.2558             0.0022            0.0034   \n",
       "6336              0.0100        0.0074             0.0003            0.0011   \n",
       "8844              0.0122        0.0279             0.0056            0.0029   \n",
       "10147             0.0013        0.3089             0.0002            0.0020   \n",
       "10148             0.0006        0.1522             0.0007            0.0436   \n",
       "11351             0.0721        0.0495             0.0033            0.0142   \n",
       "11420             0.0648        0.0875             0.0017            0.0090   \n",
       "12844             0.0008        0.0036             0.0009            0.3685   \n",
       "13225             0.0004        0.0023             0.0005            0.2008   \n",
       "14497             0.0026        0.0199             0.0012            0.2046   \n",
       "15172             0.0015        0.0092             0.0066            0.3241   \n",
       "16033             0.0010        0.0315             0.0007            0.3026   \n",
       "17100             0.0030        0.0655             0.0017            0.0129   \n",
       "18261             0.1979        0.0054             0.0011            0.0050   \n",
       "18265             0.0606        0.0016             0.0072            0.0535   \n",
       "18949             0.0908        0.0806             0.0039            0.0097   \n",
       "18968             0.0182        0.0731             0.0013            0.0483   \n",
       "19164             0.0584        0.1099             0.0021            0.0182   \n",
       "23105             0.0009        0.0140             0.0007            0.2137   \n",
       "26303             0.0030        0.0582             0.0071            0.1170   \n",
       "\n",
       "       I-ORG Confidence  I-MISC Confidence  \n",
       "35               0.0054             0.0008  \n",
       "4313             0.0074             0.0020  \n",
       "4448             0.0020             0.0007  \n",
       "4493             0.0038             0.0015  \n",
       "6138             0.0007             0.0002  \n",
       "6167             0.0013             0.0005  \n",
       "6336             0.0013             0.0002  \n",
       "8844             0.0041             0.0040  \n",
       "10147            0.0008             0.0001  \n",
       "10148            0.0023             0.0003  \n",
       "11351            0.0101             0.0096  \n",
       "11420            0.0074             0.0138  \n",
       "12844            0.0016             0.0019  \n",
       "13225            0.0014             0.0005  \n",
       "14497            0.0154             0.0025  \n",
       "15172            0.0079             0.0040  \n",
       "16033            0.0050             0.0030  \n",
       "17100            0.1942             0.0089  \n",
       "18261            0.0037             0.0016  \n",
       "18265            0.0218             0.0203  \n",
       "18949            0.0051             0.0182  \n",
       "18968            0.0055             0.0999  \n",
       "19164            0.0062             0.1406  \n",
       "23105            0.0016             0.0007  \n",
       "26303            0.0227             0.0027  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['B-LOC Confidence']>0.6)&(df['B-LOC Confidence']<0.8)][['Variability', 'Normalized Prediction Entropy', 'Prediction Entropy', 'B-PERS Confidence', 'B-LOC Confidence', 'B-ORG Confidence', 'B-MISC Confidence', 'O Confidence', 'I-PERS Confidence', 'I-LOC Confidence', 'I-ORG Confidence', 'I-MISC Confidence',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True Labels\n",
       "B-LOC     -0.121848\n",
       "B-MISC    -0.214932\n",
       "B-ORG     -0.139246\n",
       "B-PERS    -0.238405\n",
       "I-LOC     -0.048953\n",
       "I-MISC    -0.137872\n",
       "I-ORG     -0.214284\n",
       "I-PERS    -0.211615\n",
       "IGNORED   -0.998909\n",
       "O         -0.067060\n",
       "[CLS]     -1.000000\n",
       "[SEP]     -1.000000\n",
       "Name: Dataset Token Entropy, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('True Labels')['Dataset Token Entropy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Losses</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>True Labels</th>\n",
       "      <th>Consistency Count</th>\n",
       "      <th>Inconsistency Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0.0056</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>0.0114</td>\n",
       "      <td>بن</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>8</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.0182</td>\n",
       "      <td>بن</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>8</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4905</th>\n",
       "      <td>0.0011</td>\n",
       "      <td>بن</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7459</th>\n",
       "      <td>0.0043</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7505</th>\n",
       "      <td>0.0049</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7684</th>\n",
       "      <td>0.0077</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696</th>\n",
       "      <td>0.1508</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7809</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7900</th>\n",
       "      <td>0.0065</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9594</th>\n",
       "      <td>0.0040</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15584</th>\n",
       "      <td>0.0054</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15718</th>\n",
       "      <td>0.0042</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15739</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>بن</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>8</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18825</th>\n",
       "      <td>0.0151</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19453</th>\n",
       "      <td>0.0066</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22099</th>\n",
       "      <td>0.0080</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22140</th>\n",
       "      <td>0.0043</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22168</th>\n",
       "      <td>0.0046</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22310</th>\n",
       "      <td>0.0080</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22312</th>\n",
       "      <td>0.0064</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22354</th>\n",
       "      <td>0.0049</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22366</th>\n",
       "      <td>0.0052</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23815</th>\n",
       "      <td>0.0035</td>\n",
       "      <td>بن</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>8</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23879</th>\n",
       "      <td>0.0239</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23937</th>\n",
       "      <td>0.0089</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23980</th>\n",
       "      <td>0.0028</td>\n",
       "      <td>بن</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>8</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24016</th>\n",
       "      <td>0.0058</td>\n",
       "      <td>بن</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>8</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29228</th>\n",
       "      <td>0.0054</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29230</th>\n",
       "      <td>0.0056</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29391</th>\n",
       "      <td>0.0056</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29412</th>\n",
       "      <td>0.0057</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29539</th>\n",
       "      <td>3.6711</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29582</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29603</th>\n",
       "      <td>0.0052</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29707</th>\n",
       "      <td>0.0300</td>\n",
       "      <td>بن</td>\n",
       "      <td>I-PERS</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Losses Tokens True Labels  Consistency Count  Inconsistency Count\n",
       "683    0.0056     بن      I-PERS                103                   11\n",
       "845    0.0114     بن      B-PERS                  8                  106\n",
       "860    0.0182     بن      B-PERS                  8                  106\n",
       "4905   0.0011     بن           O                  1                  113\n",
       "7459   0.0043     بن      I-PERS                103                   11\n",
       "7505   0.0049     بن      I-PERS                103                   11\n",
       "7665   0.0050     بن      I-PERS                103                   11\n",
       "7684   0.0077     بن      I-PERS                103                   11\n",
       "7696   0.1508     بن      I-PERS                103                   11\n",
       "7809   0.0115     بن      I-PERS                103                   11\n",
       "7900   0.0065     بن      I-PERS                103                   11\n",
       "9594   0.0040     بن      I-PERS                103                   11\n",
       "15584  0.0054     بن      I-PERS                103                   11\n",
       "15718  0.0042     بن      I-PERS                103                   11\n",
       "15739  0.0104     بن      B-PERS                  8                  106\n",
       "18825  0.0151     بن      I-PERS                103                   11\n",
       "19453  0.0066     بن      I-PERS                103                   11\n",
       "22099  0.0080     بن      I-PERS                103                   11\n",
       "22140  0.0043     بن      I-PERS                103                   11\n",
       "22168  0.0046     بن      I-PERS                103                   11\n",
       "22310  0.0080     بن      I-PERS                103                   11\n",
       "22312  0.0064     بن      I-PERS                103                   11\n",
       "22354  0.0049     بن      I-PERS                103                   11\n",
       "22366  0.0052     بن      I-PERS                103                   11\n",
       "23815  0.0035     بن      B-PERS                  8                  106\n",
       "23879  0.0239     بن      I-PERS                103                   11\n",
       "23937  0.0089     بن      I-PERS                103                   11\n",
       "23980  0.0028     بن      B-PERS                  8                  106\n",
       "24016  0.0058     بن      B-PERS                  8                  106\n",
       "29228  0.0054     بن      I-PERS                103                   11\n",
       "29230  0.0056     بن      I-PERS                103                   11\n",
       "29391  0.0056     بن      I-PERS                103                   11\n",
       "29412  0.0057     بن      I-PERS                103                   11\n",
       "29539  3.6711     بن      I-PERS                103                   11\n",
       "29582  0.0104     بن      I-PERS                103                   11\n",
       "29603  0.0052     بن      I-PERS                103                   11\n",
       "29707  0.0300     بن      I-PERS                103                   11"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Tokens'] == 'بن'][['Losses', 'Tokens', 'True Labels', 'Consistency Count', 'Inconsistency Count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence Ids', 'Token Positions', 'Words', 'Tokens', 'Word Pieces',\n",
       "       'Core Tokens', 'True Labels', 'Token Selector Id', 'Pred Labels',\n",
       "       'Agreements', 'X', 'Y', 'Labels', 'Losses', 'Token Ids', 'Global Id',\n",
       "       'True Token Score', 'Pred Token Score', 'K=3', 'Boundary Clusters',\n",
       "       'K=4', 'Entity Clusters', 'K=9', 'Token Clusters', 'Consistency Count',\n",
       "       'Inconsistency Count', 'Total Train Occurrences', 'Local Token Entropy',\n",
       "       'Token Max Entropy', 'Dataset Token Entropy', 'Local Word Entropy',\n",
       "       'Word Max Entropy', 'Dataset Word Entropy', 'Tokenization Rate',\n",
       "       'TR Entity', 'PR Entity', 'Error Type', 'O Confidence',\n",
       "       'B-PERS Confidence', 'I-PERS Confidence', 'B-ORG Confidence',\n",
       "       'I-ORG Confidence', 'B-LOC Confidence', 'I-LOC Confidence',\n",
       "       'B-MISC Confidence', 'I-MISC Confidence', 'Prediction Entropy',\n",
       "       'Prediction Max Entropy', 'Token Confidence', 'Variability', 'Pre X',\n",
       "       'Pre Y', 'Consistency Ratio', 'Inconsistency Ratio',\n",
       "       'Normalized Token Entropy', 'Normalized Word Entropy',\n",
       "       'Normalized Prediction Entropy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             [CLS]\n",
       "1          الصالحية\n",
       "2            المفرق\n",
       "3                 -\n",
       "4               غيث\n",
       "            ...    \n",
       "29706    للو, ##ليد\n",
       "29707            بن\n",
       "29708          طلال\n",
       "29709             .\n",
       "29710         [SEP]\n",
       "Name: Word Pieces, Length: 29711, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Word Pieces'].apply(\n",
    "                lambda x: ', '.join(x) if isinstance(x, list) else x\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Raw Entropy  Max Entropy  Normalized Entropy\n",
      "0          0.0            0               0.000\n",
      "1         -1.0           -1              -1.000\n",
      "2          5.0           10               0.500\n",
      "3          2.5            4               0.625\n",
      "4          3.0            0                 inf\n",
      "5          7.0            0                 inf\n"
     ]
    }
   ],
   "source": [
    "# Example DataFrame\n",
    "data = {\n",
    "    'Raw Entropy': [0, -1, 5, 2.5, 3, 7],\n",
    "    'Max Entropy': [0, -1, 10, 4, 0, 0]  # Including zero and non-zero cases\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply the function\n",
    "df['Normalized Entropy'] = normalized_entropy(df, 'Raw Entropy', 'Max Entropy')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Inconsistency Ratio'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Local Token Entropy\n",
       "False    16035\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Token Max Entropy']==0]['Local Token Entropy'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
