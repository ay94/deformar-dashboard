{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "# This appends the directory one level up (the root of your project) to the sys.path.\n",
    "# Modify the path depending on the location of modules you want to import.\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "\n",
    "from config.config_managers import DashboardConfigManager\n",
    "from dataManager import DataManager\n",
    "from dash import Dash\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PER', 1, 2), ('LOC', 4, 5)]\n",
      "[[(0, PER, 1, 3), (0, LOC, 4, 6)]]\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics.sequence_labeling import get_entities\n",
    "from seqeval.scheme import IOB2, Entities\n",
    "true_labels = [\"O\", \"B-PER\", \"I-PER\", \"O\", \"B-LOC\", \"I-LOC\"]\\\n",
    "\n",
    "entities = get_entities(true_labels)\n",
    "print(entities)\n",
    "\n",
    "strict_entities = Entities([true_labels], IOB2)\n",
    "print(strict_entities.entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualization(ABC):\n",
    "    def __init__(self, data, mappings):\n",
    "        self.data = data\n",
    "        self.tag_mapping = mappings['tag_mapping']\n",
    "        self.dataset_mapping = mappings['dataset_mapping']\n",
    "\n",
    "    @abstractmethod\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def visualize(self):\n",
    "        pass\n",
    "\n",
    "    def replace_mappings(self, data):\n",
    "        data['Tag'] = data['Tag'].replace(self.tag_mapping)\n",
    "        data['Model'] = data['Model'].replace(self.dataset_mapping)\n",
    "        return data\n",
    "    \n",
    "    def process_entity_confusion(self, entity_confusion, o_error):\n",
    "        \"\"\"\n",
    "        Processes the entity confusion matrix into high-level error categories\n",
    "        and a separate DataFrame for entity and exclusion errors.\n",
    "        \n",
    "        Parameters:\n",
    "            entity_confusion (dict): A dictionary representing entity confusion components.\n",
    "            \n",
    "        Returns:\n",
    "            renamed_df (DataFrame): High-level error categories (Entity, Boundary, Entity and Boundary, Exclusion).\n",
    "            entity_errors (DataFrame): DataFrame containing Entity Errors and Exclusion Errors only.\n",
    "        \"\"\"\n",
    "        # Step 1: Create DataFrame\n",
    "        df = pd.DataFrame(entity_confusion).fillna(0).astype(int).T\n",
    "\n",
    "        # Step 2: Rename columns into high-level categories\n",
    "        errors = df.copy()\n",
    "        errors[o_error] = errors.pop('O')  # Rename 'O' to 'Exclusion'\n",
    "        errors['Entity'] = errors.drop(columns=['Boundary', 'Entity and Boundary', o_error], errors='ignore').sum(axis=1)\n",
    "        errors = errors[['Entity', 'Boundary', 'Entity and Boundary', o_error]]\n",
    "\n",
    "        # Step 3: Create a separate DataFrame for Entity and Exclusion only\n",
    "        entity_errors = df.drop(columns=['Boundary', 'Entity and Boundary', 'O'], errors='ignore')\n",
    "\n",
    "        return errors, entity_errors\n",
    "\n",
    "\n",
    "\n",
    "mappings = {\n",
    "    'tag_mapping': {'PERS': 'PER'},\n",
    "    'dataset_mapping': {'ANERCorp_CamelLab_arabertv02': 'AraBERTv02', 'conll2003_bert': 'BERT'}\n",
    "}\n",
    "\n",
    "class ReportBarChart(Visualization):\n",
    "    def prepare_data(self):\n",
    "        report_data = []\n",
    "        for model_name, data_content in self.data.items():\n",
    "            entity_report = data_content.entity_non_strict_report\n",
    "            entity_strict_report = data_content.entity_strict_report\n",
    "            entity_report['Model'] = model_name\n",
    "            entity_report['Scheme'] = 'IOB1'\n",
    "            entity_strict_report['Model'] = model_name\n",
    "            entity_strict_report['Scheme'] = 'IOB2'\n",
    "            report_data.append(pd.concat([\n",
    "                entity_report, \n",
    "                entity_strict_report\n",
    "            ]))\n",
    "        report_df = pd.concat(report_data)\n",
    "        report_df = report_df[~report_df['Tag'].isin(['micro', 'macro', 'weighted'])]\n",
    "        \n",
    "        return self.replace_mappings(report_df)\n",
    "\n",
    "    def visualize(self):\n",
    "        entity_report_data = self.prepare_data()\n",
    "        melted_df = entity_report_data.melt(id_vars=[\"Tag\", \"Support\", \"Model\", \"Scheme\"], \n",
    "                        value_vars=[\"Precision\", \"Recall\"], \n",
    "                        var_name=\"Metric\", value_name=\"Value\")\n",
    "        melted_df['Value'] = melted_df['Value'].round(3)\n",
    "        fig = px.bar(melted_df, x=\"Tag\", y=\"Value\",\n",
    "                    facet_row=\"Scheme\", facet_col=\"Model\",\n",
    "                    title=\"Breakdown of Precision and Recall Scores by Entity Span, Categorized by Model and Tagging Scheme\",\n",
    "                    labels={\"Value\": \"Score\", 'Tag': 'Entity'},\n",
    "                    color=\"Metric\", barmode=\"group\",\n",
    "                    template=\"plotly_white\",\n",
    "                    facet_row_spacing=0.15,  # Adjust to a higher value for more space\n",
    "                    facet_col_spacing=0.1,  # Adjust to a higher value for more space\n",
    "                    text='Value',  # Display the Value on top of each bar\n",
    "                    )\n",
    "\n",
    "        fig.show()\n",
    "    \n",
    "    def visualize_f1(self):\n",
    "        entity_report_data = self.prepare_data()\n",
    "        entity_report_data['F1'] = entity_report_data['F1'].round(3)\n",
    "        fig = px.bar(entity_report_data, x=\"Tag\", y=\"F1\", color=\"Model\",\n",
    "                    facet_col=\"Scheme\",\n",
    "                    title=\"Breakdown of F1 Score Per Model and Scheme\",\n",
    "                    labels={\"Scale\": \"Scaled Counts\"},\n",
    "                    barmode='group',\n",
    "                    template=\"plotly_white\",\n",
    "                    # facet_row_spacing=0.1,  # Adjusted spacing\n",
    "                    facet_col_spacing=0.08,\n",
    "                    text='F1',  # Display the actual Count on top of each bar\n",
    "                    )\n",
    "                \n",
    "        fig.show()\n",
    "        \n",
    "    def visualize_support(self):\n",
    "        entity_report_data = self.prepare_data()\n",
    "        fig = px.bar(entity_report_data, x=\"Tag\", y=\"Support\", color=\"Model\",\n",
    "                    facet_col=\"Scheme\",\n",
    "                    title=\"Breakdown of the Number of Examples Per Model and Scheme\",\n",
    "                    labels={\"Scale\": \"Scaled Counts\"},\n",
    "                    barmode='group',\n",
    "                    template=\"plotly_white\",\n",
    "                    # facet_row_spacing=0.1,  # Adjusted spacing\n",
    "                    facet_col_spacing=0.08,\n",
    "                    text='Support',  # Display the actual Count on top of each bar\n",
    "                    )\n",
    "                \n",
    "        fig.show()\n",
    "        \n",
    "\n",
    "class ConfusionBarChart(Visualization):\n",
    "    def prepare_data(self):\n",
    "        matrix_data = []\n",
    "        for data_name, data_content in self.data.items():\n",
    "            entity_matrix = pd.DataFrame(data_content.entity_non_strict_confusion_data['confusion_matrix']).T \n",
    "            entity_strict_matrix = pd.DataFrame(data_content.entity_strict_confusion_data['confusion_matrix']).T\n",
    "            entity_matrix['Model'] = data_name\n",
    "            entity_matrix['Scheme'] = 'IOB1'\n",
    "            entity_strict_matrix['Model'] = data_name\n",
    "            entity_strict_matrix['Scheme'] = 'IOB2'\n",
    "            matrix_data.append(pd.concat([\n",
    "\t\t\t\tentity_matrix, \n",
    "\t\t\t\tentity_strict_matrix\n",
    "\t\t\t]))\n",
    "        matrix_df = pd.concat(matrix_data)\n",
    "        matrix_df.reset_index(inplace=True)\n",
    "        matrix_df.rename(columns={'index': 'Tag'}, inplace=True)\n",
    "        matrix_data = self.replace_mappings(matrix_df)\n",
    "        \n",
    "        grouped = matrix_data.groupby(['Tag', 'Model', 'Scheme']).sum()\n",
    "        grouped['Total'] = grouped['TP'] + grouped['FP'] + grouped['FN']\n",
    "        \n",
    "        matrix_data = matrix_data.merge(grouped['Total'], on=['Tag', 'Model', 'Scheme'], how='left')\n",
    "        \n",
    "        matrix_data['TP_Count'] = matrix_data['TP']\n",
    "        matrix_data['FP_Count'] = matrix_data['FP']\n",
    "        matrix_data['FN_Count'] = matrix_data['FN']\n",
    "        \n",
    "        matrix_data['TP'] = matrix_data['TP'] / matrix_data['Total']\n",
    "        matrix_data['FP'] = matrix_data['FP'] / matrix_data['Total']\n",
    "        matrix_data['FN'] = matrix_data['FN'] / matrix_data['Total']\n",
    "        \n",
    "        confusion_scaled_df = matrix_data.melt(id_vars=[\"Tag\", \"Model\", \"Scheme\"], value_vars=[\"TP\", \"FP\", \"FN\"], var_name=\"Metric\", value_name=\"Scale\")\n",
    "        confusion_count_df = matrix_data.melt(id_vars=[\"Tag\", \"Model\", \"Scheme\"], value_vars=[\"TP_Count\", \"FP_Count\", \"FN_Count\"], var_name=\"Metric\", value_name=\"Count\")\n",
    "        confusion_count_df['Metric'] = confusion_count_df['Metric'].str.replace('_Count', '')\n",
    "        confusion_data = confusion_scaled_df.merge(confusion_count_df, on=[\"Tag\", \"Model\", \"Scheme\", \"Metric\"])\n",
    "        return confusion_data\n",
    "\n",
    "    def visualize(self):\n",
    "        confusion_df = self.prepare_data()\n",
    "        \n",
    "        confusion_df['Tag'] = pd.Categorical(confusion_df['Tag'], categories=[\"LOC\", \"MISC\", \"ORG\", \"PER\"], ordered=True)\n",
    "        print(confusion_df)\n",
    "        fig = px.bar(confusion_df, x=\"Tag\", y=\"Scale\", color=\"Metric\",\n",
    "            facet_row=\"Scheme\", facet_col=\"Model\",\n",
    "            title=\"Breakdown of Confusion Matrix Components: by Entity Span, Categorized by Model and Tagging Scheme\",\n",
    "            labels={\"Scale\": \"Scaled Counts\"},\n",
    "            barmode='group',\n",
    "            template=\"plotly_white\",\n",
    "            facet_row_spacing=0.1,  # Adjusted spacing\n",
    "            facet_col_spacing=0.08,\n",
    "            text='Count',  # Display the actual Count on top of each bar\n",
    "            category_orders={\"Tag\": [\"LOC\", \"MISC\", \"ORG\", \"PER\"]}  # Enforce the order in the plot\n",
    "\n",
    "            )\n",
    "        \n",
    "        fig.show()\n",
    "\n",
    "class ConfusionHeatmap(Visualization):\n",
    "    def prepare_data(self):\n",
    "        matrix_data = []\n",
    "        for data_name, data_content in self.data.items():\n",
    "            entity_matrix = pd.DataFrame(data_content.entity_non_strict_confusion_data['confusion_matrix']).T \n",
    "            entity_strict_matrix = pd.DataFrame(data_content.entity_strict_confusion_data['confusion_matrix']).T\n",
    "            entity_matrix['Model'] = data_name\n",
    "            entity_matrix['Scheme'] = 'IOB1'\n",
    "            entity_strict_matrix['Model'] = data_name\n",
    "            entity_strict_matrix['Scheme'] = 'IOB2'\n",
    "            matrix_data.append(pd.concat([\n",
    "\t\t\t\tentity_matrix, \n",
    "\t\t\t\tentity_strict_matrix\n",
    "\t\t\t]))\n",
    "        matrix_df = pd.concat(matrix_data)\n",
    "        matrix_df.reset_index(inplace=True)\n",
    "        matrix_df.rename(columns={'index': 'Tag'}, inplace=True)\n",
    "        return self.replace_mappings(matrix_df)\n",
    "\n",
    "    def visualize(self):\n",
    "        matrix_df = self.prepare_data()\n",
    "        confusion_df = matrix_df.melt(id_vars=['Tag', 'Model', 'Scheme'], value_vars=['FP', 'FN'], \n",
    "                            var_name='Metric', value_name='Count')\n",
    "        \n",
    "        unique_schemes = confusion_df['Scheme'].unique()\n",
    "        unique_datasets = confusion_df['Model'].unique()\n",
    "        \n",
    "        fig = make_subplots(rows=len(unique_schemes), cols=len(unique_datasets),\n",
    "                            subplot_titles=[f\"{dataset} - {scheme}\" for scheme in unique_schemes for dataset in unique_datasets],\n",
    "                            shared_yaxes=True, horizontal_spacing=0.02, vertical_spacing=0.1)\n",
    "        \n",
    "        max_value = confusion_df['Count'].max()\n",
    "        \n",
    "        for idx, scheme in enumerate(unique_schemes):\n",
    "            for jdx, dataset in enumerate(unique_datasets):\n",
    "                filtered_data = confusion_df[(confusion_df['Scheme'] == scheme) & (confusion_df['Model'] == dataset)]\n",
    "                heatmap_data = filtered_data.pivot_table(index='Metric', columns='Tag', values='Count', fill_value=0)\n",
    "                text_data = filtered_data.pivot_table(index='Metric', columns='Tag', values='Count', fill_value=0).astype(int)\n",
    "\n",
    "                \n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Heatmap(\n",
    "                        z=heatmap_data,\n",
    "                        x=heatmap_data.columns,\n",
    "                        y=heatmap_data.index,\n",
    "                        colorscale='RdBu_r',\n",
    "                        coloraxis=\"coloraxis\",  # Use a unified color axis\n",
    "                        text=text_data,  # Add text annotations\n",
    "                        texttemplate=\"%{text}\",  # Use the text values directly\n",
    "                        hovertemplate=\"Metric: %{y}<br>Tag: %{x}<br>Count: %{text}<extra></extra>\",\n",
    "                    ),\n",
    "                    row=idx + 1, col=jdx + 1\n",
    "                )\n",
    "                \n",
    "        fig.update_layout(\n",
    "            coloraxis=dict(colorscale='RdBu_r', cmin=0, cmax=max_value, colorbar=dict(title=\"Counts\")),\n",
    "            title_text=\"Confusion Matrix Heatmap Categorized by Dataset and Tagging Scheme\",\n",
    "            template=\"plotly_white\",\n",
    "            height=600, width=700,\n",
    "        )\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ErrorTypeHeatmap(Visualization):\n",
    "    def prepare_data(self, component):\n",
    "        matrix_data = []\n",
    "        o_error = \"Inclusion\" if component == 'false_positives' else \"Exclusion\"\n",
    "        # Step 1: Collect general error data\n",
    "        for data_name, data_content in self.data.items():\n",
    "            for scheme, entity_confusion in [('IOB1', data_content.entity_non_strict_confusion_data), \n",
    "                                             ('IOB2', data_content.entity_strict_confusion_data)]:\n",
    "                # Process general errors (Entity, Boundary, Entity+Boundary, Exclusion)\n",
    "                error_types, _ = self.process_entity_confusion(entity_confusion[component], o_error)\n",
    "\n",
    "                # Annotate with Model and Scheme\n",
    "                error_types['Model'] = data_name\n",
    "                error_types['Scheme'] = scheme\n",
    "                matrix_data.append(error_types)\n",
    "        \n",
    "        # Step 2: Combine and process data\n",
    "        matrix_df = pd.concat(matrix_data)\n",
    "        matrix_df.reset_index(inplace=True)\n",
    "        matrix_df.rename(columns={'index': 'Tag'}, inplace=True)\n",
    "        matrix_df = self.replace_mappings(matrix_df)\n",
    "        \n",
    "        # Step 3: Melt raw counts for visualization\n",
    "        melted_df = matrix_df.melt(\n",
    "            id_vars=['Tag', 'Model', 'Scheme'],\n",
    "            value_vars=['Entity', 'Boundary', 'Entity and Boundary', o_error],\n",
    "            var_name=\"Error Type\",\n",
    "            value_name=\"Raw Count\"\n",
    "        )\n",
    "        return melted_df\n",
    "\n",
    "    def visualize(self, component):\n",
    "        general_errors_df = self.prepare_data(component)\n",
    "        \n",
    "        title_component = \"False Positives\" if component == 'false_positives' else \"False Negatives\"\n",
    "        \n",
    "        # Step 4: Create heatmap for raw errors\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=[f\"{scheme} - {model}\" for scheme in general_errors_df['Scheme'].unique() \n",
    "                            for model in general_errors_df['Model'].unique()],\n",
    "            shared_xaxes=True, shared_yaxes=True, horizontal_spacing=0.05, vertical_spacing=0.1\n",
    "        )\n",
    "        \n",
    "        unique_schemes = general_errors_df['Scheme'].unique()\n",
    "        unique_models = general_errors_df['Model'].unique()\n",
    "        \n",
    "        for i, scheme in enumerate(unique_schemes):\n",
    "            for j, model in enumerate(unique_models):\n",
    "                filtered_data = general_errors_df[(general_errors_df['Scheme'] == scheme) &\n",
    "                                                  (general_errors_df['Model'] == model)]\n",
    "                \n",
    "                pivot_data = filtered_data.pivot(index='Error Type', columns='Tag', values='Raw Count')\n",
    "                print(pivot_data)\n",
    "                fig.add_trace(\n",
    "                    go.Heatmap(\n",
    "                        z=pivot_data.values,\n",
    "                        x=pivot_data.columns,\n",
    "                        y=pivot_data.index,\n",
    "                        coloraxis=\"coloraxis\",\n",
    "                        text=pivot_data.values,\n",
    "                        texttemplate=\"%{text}\",\n",
    "                        hovertemplate=\"Tag: %{x}<br>Error Type: %{y}<br>Count: %{text}<extra></extra>\"\n",
    "                    ),\n",
    "                    row=i + 1, col=j + 1\n",
    "                )\n",
    "       \n",
    "        fig.update_layout(\n",
    "            coloraxis=dict(colorscale='RdBu_r', colorbar=dict(title=\"Error Count\")),\n",
    "            title_text=f\"{title_component} Error Type Heatmap: by Entity Span, Categorized by Model and Tagging Scheme\",\n",
    "            template=\"plotly_white\",\n",
    "            height=600, width=1000,\n",
    "        )\n",
    "        fig.show()\n",
    "    \n",
    "    def visualize_table(self, component):\n",
    "        \"\"\"\n",
    "        Generates tables showing raw counts and percentages for each error type, \n",
    "        categorized by Scheme and Model.\n",
    "        \"\"\"\n",
    "        # Step 1: Prepare the data\n",
    "        errors_type = self.prepare_data(component)\n",
    "        \n",
    "        # Aggregate totals for error types\n",
    "        pivot_data = errors_type.groupby([\"Error Type\", \"Scheme\", \"Model\"], as_index=False).agg(\n",
    "            Total_Count=(\"Raw Count\", \"sum\")\n",
    "        )\n",
    "\n",
    "        # Step 2: Calculate percentages across all errors within each Scheme and Model\n",
    "        pivot_data['Percentage'] = (\n",
    "            pivot_data.groupby(['Scheme', 'Model'])['Total_Count']\n",
    "            .transform(lambda x: (x / x.sum()) * 100)  # Use transform to maintain row alignment\n",
    "        )\n",
    "        pivot_data['Percentage'] = pivot_data['Percentage'].round(2)  # Round percentages for display\n",
    "\n",
    "        # Step 3: Print tables for each Scheme and Model\n",
    "        unique_schemes = pivot_data['Scheme'].unique()\n",
    "        unique_models = pivot_data['Model'].unique()\n",
    "\n",
    "        for scheme in unique_schemes:\n",
    "            for model in unique_models:\n",
    "                print(f\"\\n### Table for Scheme: {scheme}, Model: {model} ###\\n\")\n",
    "                filtered_data = pivot_data[\n",
    "                    (pivot_data['Scheme'] == scheme) & \n",
    "                    (pivot_data['Model'] == model)\n",
    "                ].copy()\n",
    "                display_df = filtered_data[['Error Type', 'Total_Count', 'Percentage']].copy()\n",
    "                display_df.rename(\n",
    "                    columns={\"Error Type\": \"Error Type\", \"Total_Count\": \"Raw Count\", \"Percentage\": \"Percentage (%)\"},\n",
    "                    inplace=True\n",
    "                )\n",
    "                print(display_df.to_string(index=False))  # Display as a clean table\n",
    "                \n",
    "\n",
    "class EntityErrorsHeatmap(Visualization):\n",
    "    def prepare_data(self, component):\n",
    "        matrix_data = []\n",
    "        o_error = \"Inclusion\" if component == 'false_positives' else \"Exclusion\"\n",
    "        # Step 1: Collect general error data\n",
    "        for data_name, data_content in self.data.items():\n",
    "            for scheme, entity_confusion in [('IOB1', data_content.entity_non_strict_confusion_data), \n",
    "                                             ('IOB2', data_content.entity_strict_confusion_data)]:\n",
    "                # Process general errors (Entity, Boundary, Entity+Boundary, Exclusion)\n",
    "                _, entity_errors = self.process_entity_confusion(entity_confusion[component], o_error)\n",
    "\n",
    "                # Annotate with Model and Scheme\n",
    "                entity_errors['Model'] = data_name\n",
    "                entity_errors['Scheme'] = scheme\n",
    "                entity_errors = entity_errors.rename(columns=self.tag_mapping)\n",
    "                matrix_data.append(entity_errors)\n",
    "        \n",
    "        # Step 2: Combine and process data\n",
    "        matrix_df = pd.concat(matrix_data)\n",
    "        matrix_df.reset_index(inplace=True)\n",
    "        matrix_df.rename(columns={'index': 'Tag'}, inplace=True)\n",
    "        matrix_df = self.replace_mappings(matrix_df)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Step 3: Melt raw counts for visualization\n",
    "        melted_df = melted_df = matrix_df.melt(\n",
    "            id_vars=['Tag', 'Model', 'Scheme'],\n",
    "            var_name=\"Error Type\",\n",
    "            value_name=\"Raw Count\"\n",
    "        )\n",
    "        return melted_df\n",
    "\n",
    "    def visualize(self, component):\n",
    "        entity_errors_df = self.prepare_data(component)\n",
    "        \n",
    "        title_component = \"False Positives\" if component == 'false_positives' else \"False Negatives\"\n",
    "        # Step 4: Create heatmap for raw errors\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=[f\"{scheme} - {model}\" for scheme in entity_errors_df['Scheme'].unique() \n",
    "                            for model in entity_errors_df['Model'].unique()],\n",
    "            shared_xaxes=True, shared_yaxes=True, horizontal_spacing=0.05, vertical_spacing=0.1\n",
    "        )\n",
    "        \n",
    "        unique_schemes = entity_errors_df['Scheme'].unique()\n",
    "        unique_models = entity_errors_df['Model'].unique()\n",
    "        \n",
    "        for i, scheme in enumerate(unique_schemes):\n",
    "            for j, model in enumerate(unique_models):\n",
    "                entity_errors = entity_errors_df[(entity_errors_df['Scheme'] == scheme) &\n",
    "                                                  (entity_errors_df['Model'] == model)]\n",
    "                \n",
    "                pivot_data = entity_errors.pivot(index='Error Type', columns='Tag', values='Raw Count')\n",
    "                print(pivot_data)\n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Heatmap(\n",
    "                        z=pivot_data.values,\n",
    "                        x=pivot_data.columns,\n",
    "                        y=pivot_data.index,\n",
    "                        coloraxis=\"coloraxis\",\n",
    "                        text=pivot_data.values,\n",
    "                        texttemplate=\"%{text}\",\n",
    "                        hovertemplate=\"Tag: %{x}<br>Error Type: %{y}<br>Count: %{text}<extra></extra>\"\n",
    "                    ),\n",
    "                    row=i + 1, col=j + 1\n",
    "                )\n",
    "                if i>0 or j>1:\n",
    "                    fig.update_xaxes(title_text=\"True Entity\", row=i + 1, col=j + 1)\n",
    "                fig.update_yaxes(title_text=\"Predicted Entity\", row=i + 1, col=j + 1)\n",
    "        \n",
    "        fig.update_layout(\n",
    "            coloraxis=dict(colorscale='RdBu_r', colorbar=dict(title=\"Error Count\")),\n",
    "            title_text=f\"{title_component} Entity Errors Heatmap: by Entity Span, Categorized by Model and Tagging Scheme\",\n",
    "            template=\"plotly_white\",\n",
    "            height=600, width=1000,\n",
    "        )\n",
    "        fig.show()\n",
    "    \n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict\n",
    "from seqeval.scheme import Entities, IOB2, IOB1\n",
    "from seqeval.metrics.sequence_labeling import get_entities\n",
    "pd.set_option(\"display.max_rows\", None)  # Display all rows\n",
    "\n",
    "\n",
    "class EntityErrorAnalyzer(ABC):\n",
    "    \"\"\"Abstract base class for entity analysis.\"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.y_true, self.y_pred = self.prepare_data(df)\n",
    "        self.true_entities = []\n",
    "        self.pred_entities = []\n",
    "\n",
    "    @abstractmethod\n",
    "    def extract_entities(self, y_data):\n",
    "        \"\"\"Extract entities based on the specific mode (strict or non-strict).\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def prepare_entities(self):\n",
    "        \"\"\"Prepare true and predicted entities for analysis.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def prepare_data(self, df):\n",
    "        core_data = df[df['Labels'] !=-100]\n",
    "        y_true = core_data.groupby('Sentence Ids')['True Labels'].apply(list).tolist()\n",
    "        y_pred = core_data.groupby('Sentence Ids')['Pred Labels'].apply(list).tolist()\n",
    "        return y_true, y_pred\n",
    "    \n",
    "    def compute_false_negatives(self, entity_type):\n",
    "        \"\"\"Compute false negatives for a specific entity type.\"\"\"\n",
    "        return set(\n",
    "            [e for e in self.true_entities if e[1] == entity_type]\n",
    "        ) - set([e for e in self.pred_entities if e[1] == entity_type])\n",
    "\n",
    "    def compute_false_positives(self, entity_type):\n",
    "        \"\"\"Compute false positives for a specific entity type.\"\"\"\n",
    "        return set(\n",
    "            [e for e in self.pred_entities if e[1] == entity_type]\n",
    "        ) - set([e for e in self.true_entities if e[1] == entity_type])\n",
    "\n",
    "    def analyze_sentence_errors(self, target_entities, comparison_entities):\n",
    "        \"\"\"Analyze errors and return sentence IDs by error type.\"\"\"\n",
    "        error_sentences = defaultdict(set)  # Dictionary to hold sentence IDs for each error type\n",
    "        non_o_errors = set()\n",
    "        indexed_entities = defaultdict(list)\n",
    "\n",
    "        # Index comparison entities by sentence\n",
    "        for entity in comparison_entities:\n",
    "            sen, entity_type, start, end = entity\n",
    "            indexed_entities[sen].append(entity)\n",
    "\n",
    "        # First pass: entity errors\n",
    "        for target_entity in target_entities:\n",
    "            t_sen, t_type, t_start, t_end = target_entity\n",
    "\n",
    "            for comp_entity in indexed_entities[t_sen]:\n",
    "                c_type, c_start, c_end = comp_entity[1:]\n",
    "\n",
    "                if (\n",
    "                    t_start == c_start\n",
    "                    and t_end == c_end\n",
    "                    and t_type != c_type\n",
    "                    and target_entity not in non_o_errors\n",
    "                ):\n",
    "                    non_o_errors.add(target_entity)\n",
    "                    error_sentences[\"Entity\"].add(target_entity)\n",
    "\n",
    "        # Second pass: boundary errors\n",
    "        for target_entity in target_entities - non_o_errors:\n",
    "            t_sen, t_type, t_start, t_end = target_entity\n",
    "\n",
    "            for comp_entity in indexed_entities[t_sen]:\n",
    "                c_sen, c_type, c_start, c_end = comp_entity\n",
    "\n",
    "                if (\n",
    "                    t_type == c_type\n",
    "                    and (t_start <= c_start <= t_end or t_start <= c_end <= t_end)\n",
    "                    and target_entity not in non_o_errors\n",
    "                ):\n",
    "                    non_o_errors.add(target_entity)\n",
    "                    error_sentences[\"Boundary\"].add(target_entity)\n",
    "\n",
    "        # Third pass: combined entity and boundary errors\n",
    "        for target_entity in target_entities - non_o_errors:\n",
    "            t_sen, t_type, t_start, t_end = target_entity\n",
    "\n",
    "            for comp_entity in indexed_entities[t_sen]:\n",
    "                c_sen, c_type, c_start, c_end = comp_entity\n",
    "\n",
    "                if (\n",
    "                    c_type != t_type\n",
    "                    and (t_start <= c_start <= t_end or t_start <= c_end <= t_end)\n",
    "                    and target_entity not in non_o_errors\n",
    "                ):\n",
    "                    non_o_errors.add(target_entity)\n",
    "                    error_sentences[\"Entity and Boundary\"].add(target_entity)\n",
    "                    # print(t_sen, t_start, t_end, c_sen, c_start, c_end)\n",
    "                    # print(f' ({t_start} <= {c_start} <= {t_end} or {t_start} <= {c_end} <= {t_end})')\n",
    "                    \n",
    "\n",
    "        # Remaining unmatched errors are \"O errors\"\n",
    "        for target_entity in target_entities - non_o_errors:\n",
    "            t_sen, t_type, t_start, t_end = target_entity\n",
    "            error_sentences[\"O\"].add(target_entity)\n",
    "\n",
    "        return {error_type: list(s_ids) for error_type, s_ids in error_sentences.items()}\n",
    "\n",
    "\n",
    "    def analyze_component(self, error_type, entity_type=None):\n",
    "        \n",
    "        \"\"\"Analyze errors (FP or FN) for a specific or all entity types.\"\"\"\n",
    "        self.prepare_entities()\n",
    "        error_analysis = {}\n",
    "        entity_types = (\n",
    "            [entity_type]\n",
    "            if entity_type\n",
    "            else set(e[1] for e in self.true_entities + self.pred_entities)\n",
    "        )\n",
    "\n",
    "        for etype in entity_types:\n",
    "            if error_type == \"false_negatives\":\n",
    "                target_entities = self.compute_false_negatives(etype)\n",
    "            elif error_type == \"false_positives\":\n",
    "                target_entities = self.compute_false_positives(etype)\n",
    "            else:\n",
    "                raise ValueError(\"Error type must be 'false_negative' or 'false_positive'.\")\n",
    "\n",
    "            error_analysis[etype] = self.analyze_sentence_errors(\n",
    "                target_entities, self.pred_entities if error_type == \"false_negatives\" else self.true_entities\n",
    "            )\n",
    "\n",
    "        return error_analysis\n",
    "    \n",
    "    def analyze_errors(self):\n",
    "        self.prepare_entities()\n",
    "        \"\"\"Analyze both false positives and false negatives.\"\"\"\n",
    "        error_components = {\"false_positives\": defaultdict(set), \"false_negatives\": defaultdict(set)}\n",
    "\n",
    "        for error_component in error_components.keys():\n",
    "            results = self.analyze_component(error_component)\n",
    "            for entity_type, errors in results.items():\n",
    "                for error_type, sentences in errors.items():\n",
    "                    error_components[error_component][error_type].update(sentences)\n",
    "\n",
    "        # Convert sets to lists for consistency\n",
    "        return {k: {etype: set(ids) for etype, ids in v.items()} for k, v in error_components.items()}\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "class StrictEntityAnalyzer(EntityErrorAnalyzer):\n",
    "    \"\"\"Analyzer for strict entity processing.\"\"\"\n",
    "\n",
    "    def extract_entities(self, y_data):\n",
    "        \"\"\"Extract entities in strict mode.\"\"\"\n",
    "        entities = Entities(y_data, IOB2, False)\n",
    "        return self.adjust_end_index(entities)\n",
    "\n",
    "    def prepare_entities(self):\n",
    "        \"\"\"Prepare true and predicted entities for strict mode.\"\"\"\n",
    "        self.true_entities = self.flatten_entities(self.extract_entities(self.y_true))\n",
    "        self.pred_entities = self.flatten_entities(self.extract_entities(self.y_pred))\n",
    "\n",
    "    def print_sentence(self, sen_id):\n",
    "        \"\"\"Print entities for a specific sentence ID.\"\"\"\n",
    "        true_entities = self.extract_entities(self.y_true).entities\n",
    "        pred_entities = self.extract_entities(self.y_pred).entities\n",
    "        print(f\"True: {true_entities[sen_id]}\")\n",
    "        print(f\"Pred: {pred_entities[sen_id]}\")\n",
    "        error = set(pred_entities[sen_id]) - set(true_entities[sen_id])\n",
    "        print(f\"Error in Pred: {error}\")\n",
    "        core_data = self.df[self.df['Labels'] !=-100]\n",
    "        sentence_data = core_data[core_data['Sentence Ids']  == sen_id].copy()\n",
    "        print(sentence_data[['Words', 'Sentence Ids', 'True Labels', 'Pred Labels', 'Strict True Entities', 'Strict Pred Entities', 'True Entities', 'Pred Entities']].head(60).to_string())\n",
    "\n",
    "    @staticmethod\n",
    "    def flatten_entities(entities):\n",
    "        \"\"\"Flatten strict entities into tuples.\"\"\"\n",
    "        return [e for sen in entities.entities for e in sen]\n",
    "    \n",
    "    @staticmethod\n",
    "    def adjust_end_index(entities):\n",
    "        \"\"\"Adjust the end index for IOB2 entities to make them inclusive.\"\"\"\n",
    "        adjusted_entities = []\n",
    "        for sentence_entities in entities.entities:  # Iterate through sentences\n",
    "            adjusted_sentence = []\n",
    "            for entity in sentence_entities:  # Iterate through entities in each sentence\n",
    "                sentence_id, entity_type, start, end = entity.to_tuple()\n",
    "                # Adjust end index\n",
    "                adjusted_sentence.append((sentence_id, entity_type, start, end - 1))\n",
    "            adjusted_entities.append(adjusted_sentence)\n",
    "        entities.entities = adjusted_entities  # Replace with adjusted entities\n",
    "        return entities\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class NonStrictEntityAnalyzer(EntityErrorAnalyzer):\n",
    "    \"\"\"Analyzer for non-strict entity processing.\"\"\"\n",
    "\n",
    "    def extract_entities(self, y_data):\n",
    "        \"\"\"Extract entities in non-strict mode.\"\"\"\n",
    "        return [\n",
    "            [(sen_id,) + entity for entity in get_entities(sen)]\n",
    "            for sen_id, sen in enumerate(y_data)\n",
    "        ]\n",
    "\n",
    "    def prepare_entities(self):\n",
    "        \"\"\"Prepare true and predicted entities for non-strict mode.\"\"\"\n",
    "        self.true_entities = self.flatten_entities(self.extract_entities(self.y_true))\n",
    "        self.pred_entities = self.flatten_entities(self.extract_entities(self.y_pred))\n",
    "\n",
    "    def print_sentence(self, sen_id):\n",
    "        \"\"\"Print entities for a specific sentence ID.\"\"\"\n",
    "        true_entities = self.extract_entities(self.y_true)\n",
    "        pred_entities = self.extract_entities(self.y_pred)\n",
    "        print(f\"True: {true_entities[sen_id]}\")\n",
    "        print(f\"Pred: {pred_entities[sen_id]}\")\n",
    "        error = set(pred_entities[sen_id]) - set(true_entities[sen_id])\n",
    "        print(f\"Error in Pred: {error}\")\n",
    "        core_data = self.df[self.df['Labels'] !=-100]\n",
    "        sentence_data = core_data[core_data['Sentence Ids']  == sen_id].copy()\n",
    "        print(sentence_data[['Words', 'Sentence Ids', 'True Labels', 'Pred Labels', 'Strict True Entities', 'Strict Pred Entities', 'True Entities', 'Pred Entities']].head(60).to_string())\n",
    "        \n",
    "    @staticmethod\n",
    "    def flatten_entities(entities):\n",
    "        \"\"\"Flatten non-strict entities into tuples.\"\"\"\n",
    "        return [e for sen in entities for e in sen]\n",
    "\n",
    "class ErrorAnalysisManager:\n",
    "    \"\"\"Manages all error analysis workflows and stores results.\"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        Initialize the manager with the dataset.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The dataset containing y_true and y_pred.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.strict_analyzer = StrictEntityAnalyzer(df)\n",
    "        self.non_strict_analyzer = NonStrictEntityAnalyzer(df)\n",
    "        self.results = {\n",
    "            \"IOB2\": {\"false_negatives\": None, \"false_positives\": None, \"errors\": None},\n",
    "            \"IOB\": {\"false_negatives\": None, \"false_positives\": None, \"errors\": None},\n",
    "        }\n",
    "\n",
    "    def run_workflows(self):\n",
    "        \"\"\"Run all error analysis workflows.\"\"\"\n",
    "        self.results[\"IOB2\"][\"false_negatives\"] = self.strict_analyzer.analyze_component(\"false_negatives\")\n",
    "        self.results[\"IOB2\"][\"false_positives\"] = self.strict_analyzer.analyze_component(\"false_positives\")\n",
    "        self.results[\"IOB2\"][\"errors\"] = self.strict_analyzer.analyze_errors()\n",
    "\n",
    "        self.results[\"IOB\"][\"false_negatives\"] = self.non_strict_analyzer.analyze_component(\"false_negatives\")\n",
    "        self.results[\"IOB\"][\"false_positives\"] = self.non_strict_analyzer.analyze_component(\"false_positives\")\n",
    "        self.results[\"IOB\"][\"errors\"] = self.non_strict_analyzer.analyze_errors()\n",
    "\n",
    "    def get_results(self):\n",
    "        \"\"\"Get the results of all workflows.\"\"\"\n",
    "        return self.results\n",
    "\n",
    "class SchemeComparator:\n",
    "    \"\"\"Facilitator for comparing annotation schemes.\"\"\"\n",
    "\n",
    "    def __init__(self, results):\n",
    "        \"\"\"\n",
    "        Initialize the comparator with results from error analysis.\n",
    "\n",
    "        Args:\n",
    "            results (dict): Results from the manager's workflows, structured by scheme.\n",
    "        \"\"\"\n",
    "        self.results = results\n",
    "\n",
    "    def compare_component(self, component, entity_type):\n",
    "        \"\"\"\n",
    "        Compare all error types for a specific entity across schemes.\n",
    "\n",
    "        Args:\n",
    "            entity_type (str): The entity type to compare (e.g., \"MISC\").\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary with set operation results for all error types.\n",
    "        \"\"\"\n",
    "        schemes = list(self.results.keys())\n",
    "        if len(schemes) != 2:\n",
    "            raise ValueError(\"Comparator requires exactly two schemes for comparison.\")\n",
    "\n",
    "        scheme_1, scheme_2 = schemes\n",
    "        component_1 = self.results[scheme_1][component]\n",
    "        component_2 = self.results[scheme_2][component]\n",
    "\n",
    "        results = {}\n",
    "        entity_1 = component_1.get(entity_type, {})\n",
    "        entity_2 = component_2.get(entity_type, {})\n",
    "\n",
    "        # Compare all error types under the given entity\n",
    "        all_error_types = set(entity_1.keys()).union(set(entity_2.keys()))\n",
    "        for error_type in all_error_types:\n",
    "            set_1 = set(entity_1.get(error_type, []))\n",
    "            set_2 = set(entity_2.get(error_type, []))\n",
    "\n",
    "            results[error_type] = {\n",
    "                \"overlap\": set_1 & set_2,\n",
    "                f\"{scheme_1} Only\": set_1 - set_2,\n",
    "                f\"{scheme_2} Only\": set_2 - set_1,\n",
    "            }\n",
    "\n",
    "        return results\n",
    "\n",
    "    def compare_errors(self, component, error_type):\n",
    "        \"\"\"\n",
    "        Compare errors across all entities and error types for both schemes.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary with set operation results for all error types.\n",
    "        \"\"\"\n",
    "        schemes = list(self.results.keys())\n",
    "        if len(schemes) != 2:\n",
    "            raise ValueError(\"Comparator requires exactly two schemes for comparison.\")\n",
    "\n",
    "        schemes_map = {'scheme_1': 'IOB', 'scheme_2': 'IOB2'}\n",
    "        errors_1 = self.results[schemes_map['scheme_1']][\"errors\"][component]\n",
    "        errors_2 = self.results[schemes_map['scheme_2']][\"errors\"][component]\n",
    "\n",
    "       \n",
    "       \n",
    "        comparison_result = ComparisonResult.from_lists(errors_1, errors_2, error_type, schemes_map)\n",
    "\n",
    "        return comparison_result.to_dict()\n",
    "\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Set\n",
    "\n",
    "@dataclass\n",
    "class ComparisonResult:\n",
    "    \"\"\"Dataclass to store comparison results.\"\"\"\n",
    "    scheme_1_name: str\n",
    "    scheme_2_name: str\n",
    "    set_1_errors: Set[int] = field(default=set)\n",
    "    set_2_errors: Set[int] = field(default=set)\n",
    "    overlap: Set[int] = field(default_factory=set)\n",
    "    scheme_1_only: Set[int] = field(default_factory=set)\n",
    "    scheme_2_only: Set[int] = field(default_factory=set)\n",
    "\n",
    "    @staticmethod\n",
    "    def from_lists(errors_1: Dict, errors_2: Dict, error_type: str, schemes_map: Dict) -> \"ComparisonResult\":\n",
    "        \"\"\"\n",
    "        Create a ComparisonResult from two lists.\n",
    "\n",
    "        Args:\n",
    "            lst_1: List of values from scheme 1.\n",
    "            lst_2: List of values from scheme 2.\n",
    "\n",
    "        Returns:\n",
    "            ComparisonResult: Dataclass containing the comparison and statistics.\n",
    "        \"\"\"\n",
    "        set_1 = set(errors_1.get(error_type, []))\n",
    "        \n",
    "        set_2 = set(errors_2.get(error_type, []))\n",
    "        \n",
    "        sentence_lst_1 = [error[0] for error in errors_1.get(error_type, [])]\n",
    "        sentence_lst_2 = [error[0] for error in errors_2.get(error_type, [])]\n",
    "        sentence_set_1 = set(sentence_lst_1)\n",
    "        sentence_set_2 = set(sentence_lst_2)\n",
    "        \n",
    "        overlap = sentence_set_1 & sentence_set_2\n",
    "        scheme_1_only = sentence_set_1 - sentence_set_2\n",
    "        scheme_2_only = sentence_set_2 - sentence_set_1\n",
    "\n",
    "        return ComparisonResult(\n",
    "            scheme_1_name=schemes_map['scheme_1'],\n",
    "            scheme_2_name=schemes_map['scheme_2'],\n",
    "            set_1_errors= set_1,\n",
    "            set_2_errors= set_2,\n",
    "            overlap=overlap,\n",
    "            scheme_1_only=scheme_1_only,\n",
    "            scheme_2_only=scheme_2_only,\n",
    "        )\n",
    "        \n",
    "    def to_dict(self) -> Dict[str, Dict[str, Set[int]]]:\n",
    "        \"\"\"R\"Overlap\": self.overlap, comparison results as a dictionary.\"\"\"\n",
    "        return {\n",
    "            f\"{self.scheme_1_name} Errors\": self.set_1_errors,\n",
    "            f\"{self.scheme_2_name} Errors\": self.set_2_errors,\n",
    "            \"Overlap\": self.overlap,\n",
    "            f\"{self.scheme_1_name} Only Errors\": self.scheme_1_only,\n",
    "            f\"{self.scheme_2_name} Only Errors\": self.scheme_2_only,\n",
    "        }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 04:20:48 - WARNING - Resolved path does not exist, checking alternative paths: /Users/ahmed/Desktop/Dashboard/deformer-dashboard/notebooks/analysis/My Drive\n",
      "2025-05-12 04:20:48 - INFO - Found Google Drive directory for account ahmed.younes.sam@gmail.com: /Users/ahmed/Library/CloudStorage/GoogleDrive-ahmed.younes.sam@gmail.com\n",
      "2025-05-12 04:20:48 - INFO - Loading Dashboard Data from  /Users/ahmed/Library/CloudStorage/GoogleDrive-ahmed.younes.sam@gmail.com/My Drive/Final Year Experiments/Thesis-Experiments/Experiments/BaseLineExperiment/ANERCorp_CamelLab_arabertv02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e9e13cdb804cd881beff1577b11e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 04:20:51 - WARNING - Resolved path does not exist, checking alternative paths: /Users/ahmed/Desktop/Dashboard/deformer-dashboard/notebooks/analysis/My Drive\n",
      "2025-05-12 04:20:51 - INFO - Found Google Drive directory for account ahmed.younes.sam@gmail.com: /Users/ahmed/Library/CloudStorage/GoogleDrive-ahmed.younes.sam@gmail.com\n",
      "2025-05-12 04:20:51 - WARNING - Resolved path does not exist, checking alternative paths: /Users/ahmed/Desktop/Dashboard/deformer-dashboard/notebooks/analysis/My Drive\n",
      "2025-05-12 04:20:51 - INFO - Found Google Drive directory for account ahmed.younes.sam@gmail.com: /Users/ahmed/Library/CloudStorage/GoogleDrive-ahmed.younes.sam@gmail.com\n",
      "2025-05-12 04:20:52 - WARNING - Resolved path does not exist, checking alternative paths: /Users/ahmed/Desktop/Dashboard/deformer-dashboard/notebooks/analysis/My Drive\n",
      "2025-05-12 04:20:52 - INFO - Found Google Drive directory for account ahmed.younes.sam@gmail.com: /Users/ahmed/Library/CloudStorage/GoogleDrive-ahmed.younes.sam@gmail.com\n",
      "2025-05-12 04:20:52 - INFO - Loading Dashboard Data from  /Users/ahmed/Library/CloudStorage/GoogleDrive-ahmed.younes.sam@gmail.com/My Drive/Final Year Experiments/Thesis-Experiments/Experiments/BaseLineExperiment/conll2003_bert\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1cfbd621c5a4cf798abf0cd03434fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 04:20:56 - WARNING - Resolved path does not exist, checking alternative paths: /Users/ahmed/Desktop/Dashboard/deformer-dashboard/notebooks/analysis/My Drive\n",
      "2025-05-12 04:20:56 - INFO - Found Google Drive directory for account ahmed.younes.sam@gmail.com: /Users/ahmed/Library/CloudStorage/GoogleDrive-ahmed.younes.sam@gmail.com\n",
      "2025-05-12 04:20:56 - WARNING - Resolved path does not exist, checking alternative paths: /Users/ahmed/Desktop/Dashboard/deformer-dashboard/notebooks/analysis/My Drive\n",
      "2025-05-12 04:20:56 - INFO - Found Google Drive directory for account ahmed.younes.sam@gmail.com: /Users/ahmed/Library/CloudStorage/GoogleDrive-ahmed.younes.sam@gmail.com\n"
     ]
    }
   ],
   "source": [
    "# CONFIG_PATH = Path(\"/Users/ay227/Desktop/Final-Year/Thesis-Experiments/Online-Dashboard-Phase/dashboard-config.yaml\")\n",
    "CONFIG_PATH = Path(\"/Users/ahmed/Desktop/Dashboard/analysis-config.yaml\")\n",
    "\n",
    "config_manager = DashboardConfigManager(CONFIG_PATH)\n",
    "dev_config = config_manager.development_config    \n",
    "\n",
    "app = Dash(__name__, suppress_callback_exceptions=True)\n",
    "\n",
    "app_config = config_manager.app_config\n",
    "server = app.server  # Flask server instance for caching\n",
    "variants_data = None\n",
    "\n",
    "data_manager = DataManager(config_manager, server)\n",
    "dash_data = data_manager.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dash_data['ANERCorp_CamelLab_arabertv02'].entity_strict_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>0.9341</td>\n",
       "      <td>0.9129</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.7720</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>0.6963</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.7842</td>\n",
       "      <td>0.7511</td>\n",
       "      <td>0.7673</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PERS</td>\n",
       "      <td>0.8599</td>\n",
       "      <td>0.8438</td>\n",
       "      <td>0.8518</td>\n",
       "      <td>858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>micro</td>\n",
       "      <td>0.8476</td>\n",
       "      <td>0.8299</td>\n",
       "      <td>0.8387</td>\n",
       "      <td>2211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>macro</td>\n",
       "      <td>0.8272</td>\n",
       "      <td>0.7908</td>\n",
       "      <td>0.8071</td>\n",
       "      <td>2211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>0.8299</td>\n",
       "      <td>0.8365</td>\n",
       "      <td>2211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Tag  Precision  Recall      F1  Support\n",
       "0       LOC     0.8927  0.9341  0.9129      668\n",
       "1      MISC     0.7720  0.6340  0.6963      235\n",
       "2       ORG     0.7842  0.7511  0.7673      450\n",
       "3      PERS     0.8599  0.8438  0.8518      858\n",
       "4     micro     0.8476  0.8299  0.8387     2211\n",
       "5     macro     0.8272  0.7908  0.8071     2211\n",
       "6  weighted     0.8451  0.8299  0.8365     2211"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Support</th>\n",
       "      <th>Model</th>\n",
       "      <th>Scheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.8919</td>\n",
       "      <td>0.9275</td>\n",
       "      <td>0.9094</td>\n",
       "      <td>676</td>\n",
       "      <td>AraBERTv02</td>\n",
       "      <td>IOB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.7366</td>\n",
       "      <td>0.6214</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>243</td>\n",
       "      <td>AraBERTv02</td>\n",
       "      <td>IOB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.7630</td>\n",
       "      <td>0.7364</td>\n",
       "      <td>0.7494</td>\n",
       "      <td>459</td>\n",
       "      <td>AraBERTv02</td>\n",
       "      <td>IOB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.8835</td>\n",
       "      <td>0.8298</td>\n",
       "      <td>0.8558</td>\n",
       "      <td>905</td>\n",
       "      <td>AraBERTv02</td>\n",
       "      <td>IOB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>micro</td>\n",
       "      <td>0.8483</td>\n",
       "      <td>0.8178</td>\n",
       "      <td>0.8327</td>\n",
       "      <td>2283</td>\n",
       "      <td>AraBERTv02</td>\n",
       "      <td>IOB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>macro</td>\n",
       "      <td>0.8187</td>\n",
       "      <td>0.7788</td>\n",
       "      <td>0.7972</td>\n",
       "      <td>2283</td>\n",
       "      <td>AraBERTv02</td>\n",
       "      <td>IOB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted</td>\n",
       "      <td>0.8461</td>\n",
       "      <td>0.8178</td>\n",
       "      <td>0.8310</td>\n",
       "      <td>2283</td>\n",
       "      <td>AraBERTv02</td>\n",
       "      <td>IOB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>0.9341</td>\n",
       "      <td>0.9129</td>\n",
       "      <td>668</td>\n",
       "      <td>AraBERTv02</td>\n",
       "      <td>IOB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.7720</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>0.6963</td>\n",
       "      <td>235</td>\n",
       "      <td>AraBERTv02</td>\n",
       "      <td>IOB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.7842</td>\n",
       "      <td>0.7511</td>\n",
       "      <td>0.7673</td>\n",
       "      <td>450</td>\n",
       "      <td>AraBERTv02</td>\n",
       "      <td>IOB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.8599</td>\n",
       "      <td>0.8438</td>\n",
       "      <td>0.8518</td>\n",
       "      <td>858</td>\n",
       "      <td>AraBERTv02</td>\n",
       "      <td>IOB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>micro</td>\n",
       "      <td>0.8476</td>\n",
       "      <td>0.8299</td>\n",
       "      <td>0.8387</td>\n",
       "      <td>2211</td>\n",
       "      <td>AraBERTv02</td>\n",
       "      <td>IOB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>macro</td>\n",
       "      <td>0.8272</td>\n",
       "      <td>0.7908</td>\n",
       "      <td>0.8071</td>\n",
       "      <td>2211</td>\n",
       "      <td>AraBERTv02</td>\n",
       "      <td>IOB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>0.8299</td>\n",
       "      <td>0.8365</td>\n",
       "      <td>2211</td>\n",
       "      <td>AraBERTv02</td>\n",
       "      <td>IOB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.9206</td>\n",
       "      <td>0.9317</td>\n",
       "      <td>0.9261</td>\n",
       "      <td>1668</td>\n",
       "      <td>BERT</td>\n",
       "      <td>IOB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.7907</td>\n",
       "      <td>0.8234</td>\n",
       "      <td>0.8067</td>\n",
       "      <td>702</td>\n",
       "      <td>BERT</td>\n",
       "      <td>IOB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.8886</td>\n",
       "      <td>0.9073</td>\n",
       "      <td>0.8978</td>\n",
       "      <td>1661</td>\n",
       "      <td>BERT</td>\n",
       "      <td>IOB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>1617</td>\n",
       "      <td>BERT</td>\n",
       "      <td>IOB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>micro</td>\n",
       "      <td>0.9058</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>5648</td>\n",
       "      <td>BERT</td>\n",
       "      <td>IOB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>macro</td>\n",
       "      <td>0.8901</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.8978</td>\n",
       "      <td>5648</td>\n",
       "      <td>BERT</td>\n",
       "      <td>IOB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted</td>\n",
       "      <td>0.9064</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9128</td>\n",
       "      <td>5648</td>\n",
       "      <td>BERT</td>\n",
       "      <td>IOB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.9234</td>\n",
       "      <td>0.9317</td>\n",
       "      <td>0.9275</td>\n",
       "      <td>1668</td>\n",
       "      <td>BERT</td>\n",
       "      <td>IOB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.8099</td>\n",
       "      <td>0.8191</td>\n",
       "      <td>0.8144</td>\n",
       "      <td>702</td>\n",
       "      <td>BERT</td>\n",
       "      <td>IOB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.8974</td>\n",
       "      <td>0.9061</td>\n",
       "      <td>0.9017</td>\n",
       "      <td>1661</td>\n",
       "      <td>BERT</td>\n",
       "      <td>IOB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>1617</td>\n",
       "      <td>BERT</td>\n",
       "      <td>IOB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>micro</td>\n",
       "      <td>0.9126</td>\n",
       "      <td>0.9184</td>\n",
       "      <td>0.9155</td>\n",
       "      <td>5648</td>\n",
       "      <td>BERT</td>\n",
       "      <td>IOB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>macro</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.9043</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>5648</td>\n",
       "      <td>BERT</td>\n",
       "      <td>IOB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>0.9184</td>\n",
       "      <td>0.9155</td>\n",
       "      <td>5648</td>\n",
       "      <td>BERT</td>\n",
       "      <td>IOB2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Tag  Precision  Recall      F1  Support       Model Scheme\n",
       "0       LOC     0.8919  0.9275  0.9094      676  AraBERTv02   IOB1\n",
       "1      MISC     0.7366  0.6214  0.6741      243  AraBERTv02   IOB1\n",
       "2       ORG     0.7630  0.7364  0.7494      459  AraBERTv02   IOB1\n",
       "3       PER     0.8835  0.8298  0.8558      905  AraBERTv02   IOB1\n",
       "4     micro     0.8483  0.8178  0.8327     2283  AraBERTv02   IOB1\n",
       "5     macro     0.8187  0.7788  0.7972     2283  AraBERTv02   IOB1\n",
       "6  weighted     0.8461  0.8178  0.8310     2283  AraBERTv02   IOB1\n",
       "0       LOC     0.8927  0.9341  0.9129      668  AraBERTv02   IOB2\n",
       "1      MISC     0.7720  0.6340  0.6963      235  AraBERTv02   IOB2\n",
       "2       ORG     0.7842  0.7511  0.7673      450  AraBERTv02   IOB2\n",
       "3       PER     0.8599  0.8438  0.8518      858  AraBERTv02   IOB2\n",
       "4     micro     0.8476  0.8299  0.8387     2211  AraBERTv02   IOB2\n",
       "5     macro     0.8272  0.7908  0.8071     2211  AraBERTv02   IOB2\n",
       "6  weighted     0.8451  0.8299  0.8365     2211  AraBERTv02   IOB2\n",
       "0       LOC     0.9206  0.9317  0.9261     1668        BERT   IOB1\n",
       "1      MISC     0.7907  0.8234  0.8067      702        BERT   IOB1\n",
       "2       ORG     0.8886  0.9073  0.8978     1661        BERT   IOB1\n",
       "3       PER     0.9604  0.9604  0.9604     1617        BERT   IOB1\n",
       "4     micro     0.9058  0.9193  0.9125     5648        BERT   IOB1\n",
       "5     macro     0.8901  0.9057  0.8978     5648        BERT   IOB1\n",
       "6  weighted     0.9064  0.9193  0.9128     5648        BERT   IOB1\n",
       "0       LOC     0.9234  0.9317  0.9275     1668        BERT   IOB2\n",
       "1      MISC     0.8099  0.8191  0.8144      702        BERT   IOB2\n",
       "2       ORG     0.8974  0.9061  0.9017     1661        BERT   IOB2\n",
       "3       PER     0.9622  0.9604  0.9613     1617        BERT   IOB2\n",
       "4     micro     0.9126  0.9184  0.9155     5648        BERT   IOB2\n",
       "5     macro     0.8982  0.9043  0.9012     5648        BERT   IOB2\n",
       "6  weighted     0.9127  0.9184  0.9155     5648        BERT   IOB2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_data = []\n",
    "for data_name, data_content in dash_data.items():\n",
    "\tentity_report = data_content.entity_non_strict_report\n",
    "\tentity_strict_report = data_content.entity_strict_report\n",
    "\tentity_report['Model'] = data_name\n",
    "\tentity_report['Scheme'] = 'IOB1'\n",
    "\tentity_strict_report['Model'] = data_name\n",
    "\tentity_strict_report['Scheme'] = 'IOB2'\n",
    "\treport_data.append(pd.concat([\n",
    "\t\tentity_report, \n",
    "\t\tentity_strict_report\n",
    "\t]))\n",
    "report_df = pd.concat(report_data)\n",
    "# report_df = report_df[~report_df['Tag'].isin(['micro', 'macro', 'weighted'])]    \n",
    "tag_mapping = {\n",
    "    'PERS': 'PER'\n",
    "}\n",
    "\n",
    "dataset_mapping = {\n",
    "    'ANERCorp_CamelLab_arabertv02': 'AraBERTv02',\n",
    "    'conll2003_bert': 'BERT'\n",
    "}\n",
    "\n",
    "report_df['Tag'] = report_df['Tag'].replace(tag_mapping)\n",
    "report_df['Model'] = report_df['Model'].replace(dataset_mapping)\n",
    "report_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.703898379325449"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(243+459+905) / (243+459+905+676)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Model=AraBERTv02<br>Scheme=IOB1<br>Tag=%{x}<br>F1=%{text}<extra></extra>",
         "legendgroup": "AraBERTv02",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "AraBERTv02",
         "offsetgroup": "AraBERTv02",
         "orientation": "v",
         "showlegend": true,
         "text": [
          0.909,
          0.674,
          0.749,
          0.856
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "LOC",
          "MISC",
          "ORG",
          "PER"
         ],
         "xaxis": "x",
         "y": [
          0.909,
          0.674,
          0.749,
          0.856
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Model=AraBERTv02<br>Scheme=IOB2<br>Tag=%{x}<br>F1=%{text}<extra></extra>",
         "legendgroup": "AraBERTv02",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "AraBERTv02",
         "offsetgroup": "AraBERTv02",
         "orientation": "v",
         "showlegend": false,
         "text": [
          0.913,
          0.696,
          0.767,
          0.852
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "LOC",
          "MISC",
          "ORG",
          "PER"
         ],
         "xaxis": "x2",
         "y": [
          0.913,
          0.696,
          0.767,
          0.852
         ],
         "yaxis": "y2"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Model=BERT<br>Scheme=IOB1<br>Tag=%{x}<br>F1=%{text}<extra></extra>",
         "legendgroup": "BERT",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "BERT",
         "offsetgroup": "BERT",
         "orientation": "v",
         "showlegend": true,
         "text": [
          0.926,
          0.807,
          0.898,
          0.96
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "LOC",
          "MISC",
          "ORG",
          "PER"
         ],
         "xaxis": "x",
         "y": [
          0.926,
          0.807,
          0.898,
          0.96
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Model=BERT<br>Scheme=IOB2<br>Tag=%{x}<br>F1=%{text}<extra></extra>",
         "legendgroup": "BERT",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "BERT",
         "offsetgroup": "BERT",
         "orientation": "v",
         "showlegend": false,
         "text": [
          0.928,
          0.814,
          0.902,
          0.961
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "LOC",
          "MISC",
          "ORG",
          "PER"
         ],
         "xaxis": "x2",
         "y": [
          0.928,
          0.814,
          0.902,
          0.961
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {},
          "showarrow": false,
          "text": "Scheme=IOB1",
          "x": 0.23,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {},
          "showarrow": false,
          "text": "Scheme=IOB2",
          "x": 0.77,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "barmode": "group",
        "legend": {
         "title": {
          "text": "Model"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Breakdown of F1 Score Per Model and Scheme"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.46
         ],
         "title": {
          "text": "Tag"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.54,
          1
         ],
         "matches": "x",
         "title": {
          "text": "Tag"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "F1"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix heatmap example\n",
    "report_bar = ReportBarChart(dash_data, mappings)\n",
    "report_bar.visualize_f1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix heatmap example\n",
    "report_bar = ReportBarChart(dash_data, mappings)\n",
    "report_bar.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_bar = ConfusionBarChart(dash_data, mappings)\n",
    "confusion_bar.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix heatmap example\n",
    "report_bar = ReportBarChart(dash_data, mappings)\n",
    "report_bar.visualize_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "colorscale": [
          [
           0,
           "rgb(5,48,97)"
          ],
          [
           0.1,
           "rgb(33,102,172)"
          ],
          [
           0.2,
           "rgb(67,147,195)"
          ],
          [
           0.3,
           "rgb(146,197,222)"
          ],
          [
           0.4,
           "rgb(209,229,240)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(253,219,199)"
          ],
          [
           0.7,
           "rgb(244,165,130)"
          ],
          [
           0.8,
           "rgb(214,96,77)"
          ],
          [
           0.9,
           "rgb(178,24,43)"
          ],
          [
           1,
           "rgb(103,0,31)"
          ]
         ],
         "hovertemplate": "Metric: %{y}<br>Tag: %{x}<br>Count: %{text}<extra></extra>",
         "text": [
          [
           49,
           92,
           121,
           154
          ],
          [
           76,
           54,
           105,
           99
          ]
         ],
         "texttemplate": "%{text}",
         "type": "heatmap",
         "x": [
          "LOC",
          "MISC",
          "ORG",
          "PER"
         ],
         "xaxis": "x",
         "y": [
          "FN",
          "FP"
         ],
         "yaxis": "y",
         "z": [
          [
           49,
           92,
           121,
           154
          ],
          [
           76,
           54,
           105,
           99
          ]
         ]
        },
        {
         "coloraxis": "coloraxis",
         "colorscale": [
          [
           0,
           "rgb(5,48,97)"
          ],
          [
           0.1,
           "rgb(33,102,172)"
          ],
          [
           0.2,
           "rgb(67,147,195)"
          ],
          [
           0.3,
           "rgb(146,197,222)"
          ],
          [
           0.4,
           "rgb(209,229,240)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(253,219,199)"
          ],
          [
           0.7,
           "rgb(244,165,130)"
          ],
          [
           0.8,
           "rgb(214,96,77)"
          ],
          [
           0.9,
           "rgb(178,24,43)"
          ],
          [
           1,
           "rgb(103,0,31)"
          ]
         ],
         "hovertemplate": "Metric: %{y}<br>Tag: %{x}<br>Count: %{text}<extra></extra>",
         "text": [
          [
           114,
           124,
           154,
           64
          ],
          [
           134,
           153,
           189,
           64
          ]
         ],
         "texttemplate": "%{text}",
         "type": "heatmap",
         "x": [
          "LOC",
          "MISC",
          "ORG",
          "PER"
         ],
         "xaxis": "x2",
         "y": [
          "FN",
          "FP"
         ],
         "yaxis": "y2",
         "z": [
          [
           114,
           124,
           154,
           64
          ],
          [
           134,
           153,
           189,
           64
          ]
         ]
        },
        {
         "coloraxis": "coloraxis",
         "colorscale": [
          [
           0,
           "rgb(5,48,97)"
          ],
          [
           0.1,
           "rgb(33,102,172)"
          ],
          [
           0.2,
           "rgb(67,147,195)"
          ],
          [
           0.3,
           "rgb(146,197,222)"
          ],
          [
           0.4,
           "rgb(209,229,240)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(253,219,199)"
          ],
          [
           0.7,
           "rgb(244,165,130)"
          ],
          [
           0.8,
           "rgb(214,96,77)"
          ],
          [
           0.9,
           "rgb(178,24,43)"
          ],
          [
           1,
           "rgb(103,0,31)"
          ]
         ],
         "hovertemplate": "Metric: %{y}<br>Tag: %{x}<br>Count: %{text}<extra></extra>",
         "text": [
          [
           44,
           86,
           112,
           134
          ],
          [
           75,
           44,
           93,
           118
          ]
         ],
         "texttemplate": "%{text}",
         "type": "heatmap",
         "x": [
          "LOC",
          "MISC",
          "ORG",
          "PER"
         ],
         "xaxis": "x3",
         "y": [
          "FN",
          "FP"
         ],
         "yaxis": "y3",
         "z": [
          [
           44,
           86,
           112,
           134
          ],
          [
           75,
           44,
           93,
           118
          ]
         ]
        },
        {
         "coloraxis": "coloraxis",
         "colorscale": [
          [
           0,
           "rgb(5,48,97)"
          ],
          [
           0.1,
           "rgb(33,102,172)"
          ],
          [
           0.2,
           "rgb(67,147,195)"
          ],
          [
           0.3,
           "rgb(146,197,222)"
          ],
          [
           0.4,
           "rgb(209,229,240)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(253,219,199)"
          ],
          [
           0.7,
           "rgb(244,165,130)"
          ],
          [
           0.8,
           "rgb(214,96,77)"
          ],
          [
           0.9,
           "rgb(178,24,43)"
          ],
          [
           1,
           "rgb(103,0,31)"
          ]
         ],
         "hovertemplate": "Metric: %{y}<br>Tag: %{x}<br>Count: %{text}<extra></extra>",
         "text": [
          [
           114,
           127,
           156,
           64
          ],
          [
           129,
           135,
           172,
           61
          ]
         ],
         "texttemplate": "%{text}",
         "type": "heatmap",
         "x": [
          "LOC",
          "MISC",
          "ORG",
          "PER"
         ],
         "xaxis": "x4",
         "y": [
          "FN",
          "FP"
         ],
         "yaxis": "y4",
         "z": [
          [
           114,
           127,
           156,
           64
          ],
          [
           129,
           135,
           172,
           61
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "AraBERTv02 - IOB1",
          "x": 0.245,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "BERT - IOB1",
          "x": 0.755,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "AraBERTv02 - IOB2",
          "x": 0.245,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.45,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "BERT - IOB2",
          "x": 0.755,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.45,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "coloraxis": {
         "cmax": 189,
         "cmin": 0,
         "colorbar": {
          "title": {
           "text": "Counts"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(5,48,97)"
          ],
          [
           0.1,
           "rgb(33,102,172)"
          ],
          [
           0.2,
           "rgb(67,147,195)"
          ],
          [
           0.3,
           "rgb(146,197,222)"
          ],
          [
           0.4,
           "rgb(209,229,240)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(253,219,199)"
          ],
          [
           0.7,
           "rgb(244,165,130)"
          ],
          [
           0.8,
           "rgb(214,96,77)"
          ],
          [
           0.9,
           "rgb(178,24,43)"
          ],
          [
           1,
           "rgb(103,0,31)"
          ]
         ]
        },
        "height": 600,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Confusion Matrix Heatmap Categorized by Dataset and Tagging Scheme"
        },
        "width": 700,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.49
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.51,
          1
         ]
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.49
         ]
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.51,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.55,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.45
         ]
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.45
         ],
         "matches": "y3",
         "showticklabels": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix heatmap example\n",
    "confusion_heatmap = ConfusionHeatmap(dash_data, mappings)\n",
    "confusion_heatmap.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "class ErrorTypeBarChart(Visualization):\n",
    "    def prepare_data(self):\n",
    "        matrix_data = []\n",
    "        error_components = [\"false_positives\", \"false_negatives\"]\n",
    "\n",
    "        for component in error_components:\n",
    "            o_error = \"Inclusion\" if component == 'false_positives' else \"Exclusion\"\n",
    "\n",
    "            for data_name, data_content in self.data.items():\n",
    "                for scheme, entity_confusion in [('IOB1', data_content.entity_non_strict_confusion_data), \n",
    "                                                ('IOB2', data_content.entity_strict_confusion_data)]:\n",
    "                    error_types, _ = self.process_entity_confusion(entity_confusion[component], o_error)\n",
    "\n",
    "                    #  Rename Inclusion/Exclusion to \"O Errors\"\n",
    "                    error_types.rename(columns={o_error: \"O Errors\"}, inplace=True)\n",
    "\n",
    "                    error_types['Model'] = data_name\n",
    "                    error_types['Scheme'] = scheme\n",
    "                    error_types['Component'] = \"False Positives\" if component == \"false_positives\" else \"False Negatives\"\n",
    "                    matrix_data.append(error_types)\n",
    "\n",
    "        # Combine into a single DataFrame\n",
    "        matrix_df = pd.concat(matrix_data)\n",
    "        matrix_df.reset_index(inplace=True)\n",
    "        matrix_df.rename(columns={'index': 'Tag'}, inplace=True)\n",
    "        matrix_df = self.replace_mappings(matrix_df)\n",
    "\n",
    "        # Melt for visualization\n",
    "        melted_df = matrix_df.melt(\n",
    "            id_vars=['Model', 'Scheme', 'Component'],\n",
    "            value_vars=['Entity', 'Boundary', 'Entity and Boundary', \"O Errors\"],\n",
    "            var_name=\"Error Type\",\n",
    "            value_name=\"Raw Count\"\n",
    "        )\n",
    "\n",
    "        # Aggregate totals for error types per Scheme & Model\n",
    "        pivot_data = melted_df.groupby([\"Error Type\", \"Scheme\", \"Model\", \"Component\"], as_index=False).agg(\n",
    "            Total_Count=(\"Raw Count\", \"sum\")\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Compute percentages per scheme/model\n",
    "        pivot_data['Percentage'] = (\n",
    "            pivot_data.groupby(['Scheme', 'Model', 'Component'])['Total_Count']\n",
    "            .transform(lambda x: (x / x.sum()) * 100)\n",
    "        )\n",
    "\n",
    "        pivot_data['Percentage'] = pivot_data['Percentage'].round(2)\n",
    "        \n",
    "\n",
    "        return pivot_data\n",
    "\n",
    "\n",
    "    def visualize(self):\n",
    "        \"\"\"\n",
    "        Generates a single bar chart with both False Positives & False Negatives.\n",
    "        \"\"\"\n",
    "        error_data = self.prepare_data()\n",
    "\n",
    "        #  Define consistent colors for False Positives & False Negatives\n",
    "        color_map = {\n",
    "            \"False Positives\": \"#E74C3C\",  # Red (FP)\n",
    "            \"False Negatives\": \"#00CC96\",  # Teal (FN)\n",
    "        }\n",
    "\n",
    "        # Create a bar chart with facet_row and facet_col\n",
    "        fig = px.bar(\n",
    "            error_data,\n",
    "            x=\"Error Type\",\n",
    "            y=\"Percentage\",\n",
    "            color=\"Component\",\n",
    "            text=\"Total_Count\",\n",
    "            facet_row=\"Scheme\",\n",
    "            facet_col=\"Model\",\n",
    "            barmode=\"group\",\n",
    "            title=\"Distribution of Error Types within False Positives and False Negatives Across Models and Annotation Schemes.\",\n",
    "            labels={\"Percentage\": \"Percentage (%)\", \"Total_Count\": \"Raw Count\"},\n",
    "            height=700,\n",
    "            width=1000,\n",
    "            color_discrete_map=color_map  # Assign colors to error types\n",
    "        )\n",
    "\n",
    "        # Update text position\n",
    "        fig.update_traces(textposition='auto')\n",
    "\n",
    "        # Adjust layout for better readability\n",
    "        fig.update_layout(\n",
    "            template=\"plotly_white\",\n",
    "            showlegend=True,\n",
    "            margin=dict(t=100, b=50, l=50, r=50)\n",
    "        )\n",
    "\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_bar_chart = ErrorTypeBarChart(dash_data, mappings)\n",
    "error_bar_chart.visualize()  # For False Positives\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_type_heatmap = ErrorTypeHeatmap(dash_data, mappings)\n",
    "error_type_heatmap.visualize_table('false_positives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_type_heatmap = ErrorTypeHeatmap(dash_data, mappings)\n",
    "error_type_heatmap.visualize('false_positives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_errors_heatmap = EntityErrorsHeatmap(dash_data, mappings) \n",
    "entity_errors_heatmap.visualize('false_positives')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_type_heatmap = ErrorTypeHeatmap(dash_data, mappings)\n",
    "error_type_heatmap.visualize_table('false_negatives')\n",
    "\n",
    "error_type_heatmap = ErrorTypeHeatmap(dash_data, mappings)\n",
    "error_type_heatmap.visualize('false_negatives')\n",
    "\n",
    "entity_errors_heatmap = EntityErrorsHeatmap(dash_data, mappings) \n",
    "entity_errors_heatmap.visualize('false_negatives')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dash_data['conll2003_bert'].analysis_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash_data['conll2003_bert'].token_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = ErrorAnalysisManager(df)\n",
    "manager.run_workflows()\n",
    "results = manager.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results['IOB2']['false_negatives']['LOC']['Boundary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator = SchemeComparator(results)\n",
    "component_comparison = comparator.compare_component(\"false_negatives\", \"LOC\")\n",
    "component_comparison\n",
    "overall_comparison = comparator.compare_errors('false_negatives', 'Entity and Boundary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.non_strict_analyzer.print_sentence(2068)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.strict_analyzer.print_sentence(2068)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_data = df[df['Labels']!=-100].copy()\n",
    "y_true = core_data.groupby('Sentence Ids')['True Labels'].apply(list).tolist()\n",
    "y_pred = core_data.groupby('Sentence Ids')['Pred Labels'].apply(list).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = 84\n",
    "print(get_entities(y_true[ids]))\n",
    "print(get_entities(y_pred[ids]))\n",
    "print('######')\n",
    "print(manager.strict_analyzer.adjust_end_index(Entities([y_true[ids]], IOB2, False)).entities)\n",
    "print(manager.strict_analyzer.adjust_end_index(Entities([y_pred[ids]], IOB2, False)).entities)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.strict_analyzer.adjust_end_index(Entities([y_true[ids]], IOB2, False)).entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict\n",
    "from seqeval.scheme import Entities, IOB2\n",
    "from seqeval.metrics.sequence_labeling import get_entities\n",
    "pd.set_option(\"display.max_rows\", None)  # Display all rows\n",
    "\n",
    "\n",
    "class EntityErrorAnalyzer(ABC):\n",
    "    \"\"\"Abstract base class for entity analysis.\"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.y_true, self.y_pred = self.prepare_data(df)\n",
    "        self.true_entities = []\n",
    "        self.pred_entities = []\n",
    "\n",
    "    @abstractmethod\n",
    "    def extract_entities(self, y_data):\n",
    "        \"\"\"Extract entities based on the specific mode (strict or non-strict).\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def prepare_entities(self):\n",
    "        \"\"\"Prepare true and predicted entities for analysis.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def prepare_data(self, df):\n",
    "        core_data = df[df['Labels'] !=-100]\n",
    "        y_true = core_data.groupby('Sentence Ids')['True Labels'].apply(list).tolist()\n",
    "        y_pred = core_data.groupby('Sentence Ids')['Pred Labels'].apply(list).tolist()\n",
    "        return y_true, y_pred\n",
    "    \n",
    "    def compute_false_negatives(self, entity_type):\n",
    "        \"\"\"Compute false negatives for a specific entity type.\"\"\"\n",
    "        return set(\n",
    "            [e for e in self.true_entities if e[1] == entity_type]\n",
    "        ) - set([e for e in self.pred_entities if e[1] == entity_type])\n",
    "\n",
    "    def compute_false_positives(self, entity_type):\n",
    "        \"\"\"Compute false positives for a specific entity type.\"\"\"\n",
    "        return set(\n",
    "            [e for e in self.pred_entities if e[1] == entity_type]\n",
    "        ) - set([e for e in self.true_entities if e[1] == entity_type])\n",
    "\n",
    "    def analyze_sentence_errors(self, target_entities, comparison_entities):\n",
    "        \"\"\"Analyze errors and return sentence IDs by error type.\"\"\"\n",
    "        error_sentences = defaultdict(set)  # Dictionary to hold sentence IDs for each error type\n",
    "        non_o_errors = set()\n",
    "        indexed_entities = defaultdict(list)\n",
    "\n",
    "        # Index comparison entities by sentence\n",
    "        for entity in comparison_entities:\n",
    "            sen, entity_type, start, end = entity\n",
    "            indexed_entities[sen].append(entity)\n",
    "\n",
    "        # First pass: entity errors\n",
    "        for target_entity in target_entities:\n",
    "            t_sen, t_type, t_start, t_end = target_entity\n",
    "\n",
    "            for comp_entity in indexed_entities[t_sen]:\n",
    "                c_type, c_start, c_end = comp_entity[1:]\n",
    "\n",
    "                if (\n",
    "                    t_start == c_start\n",
    "                    and t_end == c_end\n",
    "                    and t_type != c_type\n",
    "                    and target_entity not in non_o_errors\n",
    "                ):\n",
    "                    non_o_errors.add(target_entity)\n",
    "                    error_sentences[\"Entity\"].add(target_entity)\n",
    "\n",
    "        # Second pass: boundary errors\n",
    "        for target_entity in target_entities - non_o_errors:\n",
    "            t_sen, t_type, t_start, t_end = target_entity\n",
    "\n",
    "            for comp_entity in indexed_entities[t_sen]:\n",
    "                c_sen, c_type, c_start, c_end = comp_entity\n",
    "\n",
    "                if (\n",
    "                    t_type == c_type\n",
    "                    and (t_start <= c_start <= t_end or t_start <= c_end <= t_end)\n",
    "                    and target_entity not in non_o_errors\n",
    "                ):\n",
    "                    non_o_errors.add(target_entity)\n",
    "                    error_sentences[\"Boundary\"].add(target_entity)\n",
    "\n",
    "        # Third pass: combined entity and boundary errors\n",
    "        for target_entity in target_entities - non_o_errors:\n",
    "            t_sen, t_type, t_start, t_end = target_entity\n",
    "\n",
    "            for comp_entity in indexed_entities[t_sen]:\n",
    "                c_sen, c_type, c_start, c_end = comp_entity\n",
    "\n",
    "                if (\n",
    "                    c_type != t_type\n",
    "                    and (t_start <= c_start <= t_end or t_start <= c_end <= t_end)\n",
    "                    and target_entity not in non_o_errors\n",
    "                ):\n",
    "                    non_o_errors.add(target_entity)\n",
    "                    error_sentences[\"Entity and Boundary\"].add(target_entity)\n",
    "                    # print(t_sen, t_start, t_end, c_sen, c_start, c_end)\n",
    "                    # print(f' ({t_start} <= {c_start} <= {t_end} or {t_start} <= {c_end} <= {t_end})')\n",
    "                    \n",
    "\n",
    "        # Remaining unmatched errors are \"O errors\"\n",
    "        for target_entity in target_entities - non_o_errors:\n",
    "            t_sen, t_type, t_start, t_end = target_entity\n",
    "            error_sentences[\"O\"].add(target_entity)\n",
    "\n",
    "        return {error_type: list(s_ids) for error_type, s_ids in error_sentences.items()}\n",
    "\n",
    "\n",
    "    def analyze_component(self, error_type, entity_type=None):\n",
    "        \n",
    "        \"\"\"Analyze errors (FP or FN) for a specific or all entity types.\"\"\"\n",
    "        self.prepare_entities()\n",
    "        error_analysis = {}\n",
    "        entity_types = (\n",
    "            [entity_type]\n",
    "            if entity_type\n",
    "            else set(e[1] for e in self.true_entities + self.pred_entities)\n",
    "        )\n",
    "\n",
    "        for etype in entity_types:\n",
    "            if error_type == \"false_negatives\":\n",
    "                target_entities = self.compute_false_negatives(etype)\n",
    "            elif error_type == \"false_positives\":\n",
    "                target_entities = self.compute_false_positives(etype)\n",
    "            else:\n",
    "                raise ValueError(\"Error type must be 'false_negative' or 'false_positive'.\")\n",
    "\n",
    "            error_analysis[etype] = self.analyze_sentence_errors(\n",
    "                target_entities, self.pred_entities if error_type == \"false_negatives\" else self.true_entities\n",
    "            )\n",
    "\n",
    "        return error_analysis\n",
    "    def analyze_errors(self):\n",
    "        self.prepare_entities()\n",
    "        \"\"\"Analyze both false positives and false negatives.\"\"\"\n",
    "        error_components = {\"false_positives\": defaultdict(set), \"false_negatives\": defaultdict(set)}\n",
    "\n",
    "        for error_component in error_components.keys():\n",
    "            results = self.analyze_component(error_component)\n",
    "            for entity_type, errors in results.items():\n",
    "                for error_type, sentences in errors.items():\n",
    "                    error_components[error_component][error_type].update(sentences)\n",
    "\n",
    "        # Convert sets to lists for consistency\n",
    "        return {k: {etype: set(ids) for etype, ids in v.items()} for k, v in error_components.items()}\n",
    "    \n",
    "    \n",
    "\n",
    "class StrictEntityAnalyzer(EntityErrorAnalyzer):\n",
    "    \"\"\"Analyzer for strict entity processing.\"\"\"\n",
    "\n",
    "    def extract_entities(self, y_data):\n",
    "        \"\"\"Extract entities in strict mode.\"\"\"\n",
    "        return Entities(y_data, IOB2, False)\n",
    "\n",
    "    def prepare_entities(self):\n",
    "        \"\"\"Prepare true and predicted entities for strict mode.\"\"\"\n",
    "        self.true_entities = self.flatten_entities(self.extract_entities(self.y_true))\n",
    "        self.pred_entities = self.flatten_entities(self.extract_entities(self.y_pred))\n",
    "\n",
    "    def print_sentence(self, sen_id):\n",
    "        \"\"\"Print entities for a specific sentence ID.\"\"\"\n",
    "        true_entities = self.extract_entities(self.y_true).entities\n",
    "        pred_entities = self.extract_entities(self.y_pred).entities\n",
    "        print(f\"True: {true_entities[sen_id]}\")\n",
    "        print(f\"Pred: {pred_entities[sen_id]}\")\n",
    "        sentence_data = self.df[self.df['Sentence Ids']  == sen_id].copy()\n",
    "        print(sentence_data[['Words', 'Sentence Ids', 'True Labels', 'Pred Labels', 'Strict True Entities', 'Strict Pred Entities', 'True Entities', 'Pred Entities']].head(60).to_string())\n",
    "\n",
    "    @staticmethod\n",
    "    def flatten_entities(entities):\n",
    "        \"\"\"Flatten strict entities into tuples.\"\"\"\n",
    "        return [e.to_tuple() for sen in entities.entities for e in sen]\n",
    "    \n",
    "    \n",
    "    \n",
    "class NonStrictEntityAnalyzer(EntityErrorAnalyzer):\n",
    "    \"\"\"Analyzer for non-strict entity processing.\"\"\"\n",
    "\n",
    "    def extract_entities(self, y_data):\n",
    "        \"\"\"Extract entities in non-strict mode.\"\"\"\n",
    "        return [\n",
    "            [(sen_id,) + entity for entity in get_entities(sen)]\n",
    "            for sen_id, sen in enumerate(y_data)\n",
    "        ]\n",
    "\n",
    "    def prepare_entities(self):\n",
    "        \"\"\"Prepare true and predicted entities for non-strict mode.\"\"\"\n",
    "        self.true_entities = self.flatten_entities(self.extract_entities(self.y_true))\n",
    "        self.pred_entities = self.flatten_entities(self.extract_entities(self.y_pred))\n",
    "\n",
    "    def print_sentence(self, sen_id):\n",
    "        \"\"\"Print entities for a specific sentence ID.\"\"\"\n",
    "        true_entities = self.extract_entities(self.y_true)\n",
    "        pred_entities = self.extract_entities(self.y_pred)\n",
    "        print(f\"True: {true_entities[sen_id]}\")\n",
    "        print(f\"Pred: {pred_entities[sen_id]}\")\n",
    "        sentence_data = self.df[self.df['Sentence Ids']  == sen_id].copy()\n",
    "        print(sentence_data[['Words', 'Sentence Ids', 'True Labels', 'Pred Labels', 'Strict True Entities', 'Strict Pred Entities', 'True Entities', 'Pred Entities']].head(60).to_string())\n",
    "        \n",
    "    @staticmethod\n",
    "    def flatten_entities(entities):\n",
    "        \"\"\"Flatten non-strict entities into tuples.\"\"\"\n",
    "        return [e for sen in entities for e in sen]\n",
    "\n",
    "class ErrorAnalysisManager:\n",
    "    \"\"\"Manages all error analysis workflows and stores results.\"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        Initialize the manager with the dataset.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The dataset containing y_true and y_pred.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.strict_analyzer = StrictEntityAnalyzer(df)\n",
    "        self.non_strict_analyzer = NonStrictEntityAnalyzer(df)\n",
    "        self.results = {\n",
    "            \"IOB2\": {\"false_negatives\": None, \"false_positives\": None, \"errors\": None},\n",
    "            \"IOB\": {\"false_negatives\": None, \"false_positives\": None, \"errors\": None},\n",
    "        }\n",
    "\n",
    "    def run_workflows(self):\n",
    "        \"\"\"Run all error analysis workflows.\"\"\"\n",
    "        self.results[\"IOB2\"][\"false_negatives\"] = self.strict_analyzer.analyze_component(\"false_negatives\")\n",
    "        self.results[\"IOB2\"][\"false_positives\"] = self.strict_analyzer.analyze_component(\"false_positives\")\n",
    "        self.results[\"IOB2\"][\"errors\"] = self.strict_analyzer.analyze_errors()\n",
    "\n",
    "        self.results[\"IOB\"][\"false_negatives\"] = self.non_strict_analyzer.analyze_component(\"false_negatives\")\n",
    "        self.results[\"IOB\"][\"false_positives\"] = self.non_strict_analyzer.analyze_component(\"false_positives\")\n",
    "        self.results[\"IOB\"][\"errors\"] = self.non_strict_analyzer.analyze_errors()\n",
    "\n",
    "    def get_results(self):\n",
    "        \"\"\"Get the results of all workflows.\"\"\"\n",
    "        return self.results\n",
    "\n",
    "class SchemeComparator:\n",
    "    \"\"\"Facilitator for comparing annotation schemes.\"\"\"\n",
    "\n",
    "    def __init__(self, results):\n",
    "        \"\"\"\n",
    "        Initialize the comparator with results from error analysis.\n",
    "\n",
    "        Args:\n",
    "            results (dict): Results from the manager's workflows, structured by scheme.\n",
    "        \"\"\"\n",
    "        self.results = results\n",
    "\n",
    "    def compare_component(self, component, entity_type):\n",
    "        \"\"\"\n",
    "        Compare all error types for a specific entity across schemes.\n",
    "\n",
    "        Args:\n",
    "            entity_type (str): The entity type to compare (e.g., \"MISC\").\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary with set operation results for all error types.\n",
    "        \"\"\"\n",
    "        schemes = list(self.results.keys())\n",
    "        if len(schemes) != 2:\n",
    "            raise ValueError(\"Comparator requires exactly two schemes for comparison.\")\n",
    "\n",
    "        scheme_1, scheme_2 = schemes\n",
    "        component_1 = self.results[scheme_1][component]\n",
    "        component_2 = self.results[scheme_2][component]\n",
    "\n",
    "        results = {}\n",
    "        entity_1 = component_1.get(entity_type, {})\n",
    "        entity_2 = component_2.get(entity_type, {})\n",
    "\n",
    "        # Compare all error types under the given entity\n",
    "        all_error_types = set(entity_1.keys()).union(set(entity_2.keys()))\n",
    "        for error_type in all_error_types:\n",
    "            set_1 = set(entity_1.get(error_type, []))\n",
    "            set_2 = set(entity_2.get(error_type, []))\n",
    "\n",
    "            results[error_type] = {\n",
    "                \"overlap\": set_1 & set_2,\n",
    "                f\"{scheme_1} Only\": set_1 - set_2,\n",
    "                f\"{scheme_2} Only\": set_2 - set_1,\n",
    "            }\n",
    "\n",
    "        return results\n",
    "\n",
    "    def compare_errors(self, component, error_type):\n",
    "        \"\"\"\n",
    "        Compare errors across all entities and error types for both schemes.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary with set operation results for all error types.\n",
    "        \"\"\"\n",
    "        schemes = list(self.results.keys())\n",
    "        print(schemes)\n",
    "        if len(schemes) != 2:\n",
    "            raise ValueError(\"Comparator requires exactly two schemes for comparison.\")\n",
    "\n",
    "        schemes_map = {'scheme_1': 'IOB', 'scheme_2': 'IOB2'}\n",
    "        errors_1 = self.results[schemes_map['scheme_1']][\"errors\"][component]\n",
    "        errors_2 = self.results[schemes_map['scheme_2']][\"errors\"][component]\n",
    "\n",
    "       \n",
    "       \n",
    "        comparison_result = ComparisonResult.from_lists(errors_1, errors_2, error_type, schemes_map)\n",
    "\n",
    "        return comparison_result.to_dict()\n",
    "\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Set\n",
    "\n",
    "@dataclass\n",
    "class ComparisonResult:\n",
    "    \"\"\"Dataclass to store comparison results.\"\"\"\n",
    "    scheme_1_name: str\n",
    "    scheme_2_name: str\n",
    "    set_1_errors: Set[int] = field(default=set)\n",
    "    set_2_errors: Set[int] = field(default=set)\n",
    "    overlap: Set[int] = field(default_factory=set)\n",
    "    scheme_1_only: Set[int] = field(default_factory=set)\n",
    "    scheme_2_only: Set[int] = field(default_factory=set)\n",
    "\n",
    "    @staticmethod\n",
    "    def from_lists(errors_1: Dict, errors_2: Dict, error_type: str, schemes_map: Dict) -> \"ComparisonResult\":\n",
    "        \"\"\"\n",
    "        Create a ComparisonResult from two lists.\n",
    "\n",
    "        Args:\n",
    "            lst_1: List of values from scheme 1.\n",
    "            lst_2: List of values from scheme 2.\n",
    "\n",
    "        Returns:\n",
    "            ComparisonResult: Dataclass containing the comparison and statistics.\n",
    "        \"\"\"\n",
    "        set_1 = set(errors_1.get(error_type, []))\n",
    "        \n",
    "        set_2 = set(errors_2.get(error_type, []))\n",
    "        \n",
    "        sentence_lst_1 = [error[0] for error in errors_1.get(error_type, [])]\n",
    "        sentence_lst_2 = [error[0] for error in errors_2.get(error_type, [])]\n",
    "        sentence_set_1 = set(sentence_lst_1)\n",
    "        sentence_set_2 = set(sentence_lst_2)\n",
    "        \n",
    "        overlap = sentence_set_1 & sentence_set_2\n",
    "        scheme_1_only = sentence_set_1 - sentence_set_2\n",
    "        scheme_2_only = sentence_set_2 - sentence_set_1\n",
    "\n",
    "        return ComparisonResult(\n",
    "            scheme_1_name=schemes_map['scheme_1'],\n",
    "            scheme_2_name=schemes_map['scheme_2'],\n",
    "            set_1_errors= set_1,\n",
    "            set_2_errors= set_2,\n",
    "            overlap=overlap,\n",
    "            scheme_1_only=scheme_1_only,\n",
    "            scheme_2_only=scheme_2_only,\n",
    "        )\n",
    "        \n",
    "    def to_dict(self) -> Dict[str, Dict[str, Set[int]]]:\n",
    "        \"\"\"R\"Overlap\": self.overlap, comparison results as a dictionary.\"\"\"\n",
    "        return {\n",
    "            f\"{self.scheme_1_name} Errors\": self.set_1_errors,\n",
    "            f\"{self.scheme_2_name} Errors\": self.set_2_errors,\n",
    "            \"Overlap\": self.overlap,\n",
    "            f\"{self.scheme_1_name} Only Errors\": self.scheme_1_only,\n",
    "            f\"{self.scheme_2_name} Only Errors\": self.scheme_2_only,\n",
    "        }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = ErrorAnalysisManager(df)\n",
    "manager.run_workflows()\n",
    "results = manager.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([id[0] for id in results['IOB2']['errors']['false_negatives']['Entity and Boundary']]) - set([id[0] for id in results['IOB']['errors']['false_negatives']['Entity and Boundary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['IOB2']['errors']['false_negatives']['Entity and Boundary'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_comparison['IOB2 Errors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator = SchemeComparator(results)\n",
    "component_comparison = comparator.compare_component(\"false_negatives\", \"LOC\")\n",
    "component_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_comparison = comparator.compare_errors('false_negatives', 'Entity and Boundary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_analyzer = StrictEntityAnalyzer(df)\n",
    "strict_errors = strict_analyzer.analyze_component(\"false_negatives\")\n",
    "\n",
    "\n",
    "non_strict_analyzer = NonStrictEntityAnalyzer(df)\n",
    "non_strict_errors = non_strict_analyzer.analyze_component(\"false_positives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = 'LOC'\n",
    "print(dash_data['ANERCorp_CamelLab_arabertv02'].entity_non_strict_confusion_data['false_negatives'][entity])\n",
    "print(dash_data['ANERCorp_CamelLab_arabertv02'].entity_strict_confusion_data['false_negatives'][entity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dash_data['ANERCorp_CamelLab_arabertv02'].entity_non_strict_confusion_data['false_negatives'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator = EntitySchemeComparator(strict_errors, non_strict_errors)\n",
    "\n",
    "# Compare all error types for a specific entity\n",
    "misc_comparison = comparator.compare_entity(\"MISC\")\n",
    "print(\"Comparison for MISC:\", misc_comparison)\n",
    "\n",
    "# Compare errors across all entities\n",
    "overall_comparison = comparator.compare_overall()\n",
    "print(\"Overall Comparison:\", overall_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_analyzer = StrictEntityAnalyzer(df)\n",
    "strict_errors = strict_analyzer.analyze_errors()\n",
    "\n",
    "\n",
    "non_strict_analyzer = NonStrictEntityAnalyzer(df)\n",
    "non_strict_errors = non_strict_analyzer.analyze_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_strict_errors['false_negatives']['Boundary'] - strict_errors['false_negatives']['Boundary']  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_errors['false_negatives']['Entity and Boundary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_analyzer.print_sentence(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sen_id = 20\n",
    "print(Entities([y_true[sen_id]], IOB2, False).entities)\n",
    "print(Entities([y_pred[sen_id]], IOB2, False).entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entities([y_true[124]], IOB2, False).entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entities([y_pred[124]], IOB2, False).entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.scheme import auto_detect, Entities\n",
    "from seqeval.metrics.sequence_labeling import get_entities\n",
    "from collections import Counter\n",
    "\n",
    "true_entities = get_entities(y_true)\n",
    "scheme = auto_detect(y_true, False)\n",
    "entities = Entities(y_true, scheme, False)\n",
    "print(Counter([entity[0] for entity in true_entities]))\n",
    "print(Counter([entity.to_tuple()[1] for sen in entities.entities for entity in sen]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_error_sentences['Entity and Boundary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_strict_error_sentences['Entity and Boundary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dash_data['ANERCorp_CamelLab_arabertv02'].analysis_data\n",
    "core_df = df[df['Labels']!= -100]\n",
    "y_true = core_df.groupby('Sentence Ids')['True Labels'].apply(list)\n",
    "y_pred = core_df.groupby('Sentence Ids')['Pred Labels'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dash_data['ANERCorp_CamelLab_arabertv02'].analysis_data\n",
    "pd.set_option('display.max_rows', 300)\n",
    "misc = df[df['Strict True Entities'] == 'MISC']\n",
    "df[~(df['True Aligned Scheme']) | ~(df['Pred Aligned Scheme'])][['Words', 'Sentence Ids', 'True Labels', 'Pred Labels', 'Strict True Entities', 'Strict Pred Entities', 'True Entities', 'Pred Entities', 'Error Type']]\n",
    "# df[(df['True Entities'] != 'O') & (df['Pred Entities'] == 'O') & (df['Strict True Entities'] != df['True Entities'])][['Words', 'Sentence Ids', 'True Labels', 'Pred Labels', 'Strict True Entities', 'Strict Pred Entities', 'True Entities', 'Pred Entities', 'Error Type']]\n",
    "df[df['Sentence Ids']  == 250][['Words', 'Sentence Ids', 'True Labels', 'Pred Labels', 'Strict True Entities', 'Strict Pred Entities', 'True Entities', 'Pred Entities']]\n",
    "# misc[~(misc['Pred Aligned Scheme'])][['Words', 'Sentence Ids', 'True Labels', 'Pred Labels', 'Strict True Entities', 'Strict Pred Entities', 'True Entities', 'Pred Entities']]\n",
    "# misc[(misc['Error Type'] != 'No Errors')][['Words', 'Sentence Ids', 'True Labels', 'Pred Labels', 'Strict True Entities', 'Strict Pred Entities', 'True Entities', 'Pred Entities']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = 'LOC'\n",
    "print(dash_data['ANERCorp_CamelLab_arabertv02'].entity_non_strict_confusion_data['false_positives'][entity])\n",
    "print(dash_data['ANERCorp_CamelLab_arabertv02'].entity_strict_confusion_data['false_positives'][entity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ANERCorp_CamelLab'\n",
    "model_name = 'arabertv02'\n",
    "base_path = Path(f\"/Users/ay227/Library/CloudStorage/GoogleDrive-ahmed.younes.sam@gmail.com/My Drive/Final Year Experiments/Thesis-Experiments/Experiments/BaseLineExperiment/{dataset_name}_{model_name}/extractions\")\n",
    "df = pd.read_json(\n",
    "\tbase_path / 'results/non_strict_entity_misclassifications.json',\n",
    "\torient='index'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = 'LOC'\n",
    "print(df[entity].sum()) \n",
    "print(df.loc[entity].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives': {'LOC': {'O': 15,\n",
    "   'Boundary': 14,\n",
    "   'Entity and Boundary': 15,\n",
    "   'MISC': 6,\n",
    "   'PERS': 6,\n",
    "   'ORG': 20},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "32+2+3+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = dash_data['ANERCorp_CamelLab_arabertv02'].analysis_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fad = ad[ad['Labels'] !=-100].copy()\n",
    "loc_fad = fad[fad['Pred Entities'] == 'LOC'].copy()\n",
    "loc_fad[loc_fad['True Entities'] == 'ORG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fad[(fad['True Labels'] == 'I-LOC') & (fad['Pred Labels'] == 'B-LOC') | (fad['True Labels'] == 'B-LOC') & (fad['Pred Labels'] == 'I-LOC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fad[(fad['True Labels'] == 'I-LOC') & (fad['Pred Labels'] == 'O') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fad[(fad['True Labels'] == 'B-LOC') & (fad['Pred Labels'] == 'O') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fad[fad['Sentence Ids']  == 315]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives': {'LOC': {'O': 29,\n",
    "   'Boundary': 10,\n",
    "   'PERS': 1,\n",
    "   'MISC': 3,\n",
    "   'ORG': 3,\n",
    "   'Entity and Boundary': 3},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_data = []\n",
    "for data, values in dash_data.items():\n",
    "    entity_report = values.entity_non_strict_report\n",
    "    entity_strict_report = values.entity_strict_report\n",
    "    entity_report['Dataset'] = data\n",
    "    entity_report['Scheme'] = 'IOB'\n",
    "    entity_strict_report['Dataset'] = data\n",
    "    entity_strict_report['Scheme'] = 'IOB2'\n",
    "    report_data.append(pd.concat([\n",
    "\t\tentity_report, \n",
    "\t\tentity_strict_report\n",
    "\t]))\n",
    "df = pd.concat(report_data)\n",
    "\n",
    "\n",
    "tag_mapping = {\n",
    "    'PERS': 'PER'\n",
    "}\n",
    "\n",
    "dataset_mapping = {\n",
    "    'ANERCorp_CamelLab_arabertv02': 'ANERCorp',\n",
    "    'conll2003_bert': 'CoNLL-2003'\n",
    "}\n",
    "\n",
    "df['Tag'] = df['Tag'].replace(tag_mapping)\n",
    "df['Dataset'] = df['Dataset'].replace(dataset_mapping)\n",
    "# df = df[[col for col in df.columns if col != 'F1']].copy()\n",
    "entity_report_data = df[~df['Tag'].isin(['micro', 'macro', 'weighted'])]\n",
    "\n",
    "entity_report_data\n",
    "\n",
    "\n",
    "\n",
    "# Assuming 'df_long' is your DataFrame reshaped\n",
    "df_long = entity_report_data.melt(id_vars=[\"Tag\", \"Support\", \"Dataset\", \"Scheme\"], \n",
    "                  value_vars=[\"Precision\", \"Recall\"], \n",
    "                  var_name=\"Metric\", value_name=\"Value\")\n",
    "df_long['Value'] = df_long['Value'].round(2)\n",
    "# Creating the faceted bar plot using the reshaped data\n",
    "fig = px.bar(df_long, x=\"Tag\", y=\"Value\",\n",
    "             facet_row=\"Scheme\", facet_col=\"Dataset\",\n",
    "             title=\"Precision and Recall Scores by Tag, Dataset, and Scheme\",\n",
    "             labels={\"Value\": \"Score\"},\n",
    "             color=\"Metric\", barmode=\"group\",\n",
    "             template=\"plotly_white\",\n",
    "             facet_row_spacing=0.15,  # Adjust to a higher value for more space\n",
    "             facet_col_spacing=0.1,  # Adjust to a higher value for more space\n",
    "             text='Value',  # Display the Value on top of each bar\n",
    "            #  text_auto='.2s'  # Automatically format the text with 2 significant digits\n",
    "             )\n",
    "# fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')\n",
    "\n",
    "\n",
    "\n",
    "# Update layout for better clarity\n",
    "# fig.update_layout(\n",
    "#     plot_bgcolor='rgba(255,255,255,1)',  # Ensure the background is white\n",
    "#     paper_bgcolor='rgba(255,255,255,1)',  # Ensure the paper background is also white\n",
    "# )\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confusion heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_data = []\n",
    "for data, values in dash_data.items():\n",
    "    entity_matrix = pd.DataFrame(values.entity_non_strict_confusion_data['confusion_matrix']).T \n",
    "    entity_strict_matrix = pd.DataFrame(values.entity_strict_confusion_data['confusion_matrix']).T\n",
    "    entity_matrix['Dataset'] = data\n",
    "    entity_matrix['Scheme'] = 'IOB'\n",
    "    entity_strict_matrix['Dataset'] = data\n",
    "    entity_strict_matrix['Scheme'] = 'IOB2'\n",
    "    matrix_data.append(pd.concat([\n",
    "\t\tentity_matrix, \n",
    "\t\tentity_strict_matrix\n",
    "\t]))\n",
    "    \n",
    "matrix_df = pd.concat(matrix_data)\n",
    "matrix_df.reset_index(inplace=True)\n",
    "matrix_df.rename(columns={'index': 'Tag'}, inplace=True)\n",
    "tag_mapping = {\n",
    "    'PERS': 'PER'\n",
    "}\n",
    "\n",
    "dataset_mapping = {\n",
    "    'ANERCorp_CamelLab_arabertv02': 'ANERCorp',\n",
    "    'conll2003_bert': 'CoNLL-2003'\n",
    "}\n",
    "\n",
    "matrix_df['Tag'] = matrix_df['Tag'].replace(tag_mapping)\n",
    "matrix_df['Dataset'] = matrix_df['Dataset'].replace(dataset_mapping)\n",
    "# # df = df[[col for col in df.columns if col != 'F1']].copy()\n",
    "# entity_report_data = df[~df['Tag'].isin(['micro', 'macro', 'weighted'])]\n",
    "matrix_df\n",
    "\n",
    "\n",
    "\n",
    "# Melt the DataFrame to align with Plotly requirements\n",
    "df_final = matrix_df.melt(id_vars=['Tag', 'Dataset', 'Scheme'], value_vars=['TP', 'FP', 'FN'], \n",
    "                    var_name='Metric', value_name='Count')\n",
    "\n",
    "\n",
    "\n",
    "# Assuming 'df_final' is your DataFrame prepared for plotting\n",
    "unique_schemes = df_final['Scheme'].unique()\n",
    "unique_datasets = df_final['Dataset'].unique()\n",
    "\n",
    "# Create subplot configuration\n",
    "fig = make_subplots(rows=len(unique_schemes), cols=len(unique_datasets),\n",
    "                    subplot_titles=[f\"{dataset} - {scheme}\" for scheme in unique_schemes for dataset in unique_datasets],\n",
    "                    shared_yaxes=True, horizontal_spacing=0.02, vertical_spacing=0.1)\n",
    "\n",
    "# Determine the range of values to set a common scale\n",
    "max_value = df_final['Count'].max()\n",
    "\n",
    "# Add heatmaps\n",
    "for idx, scheme in enumerate(unique_schemes):\n",
    "    for jdx, dataset in enumerate(unique_datasets):\n",
    "        filtered_data = df_final[(df_final['Scheme'] == scheme) & (df_final['Dataset'] == dataset)]\n",
    "        heatmap_data = filtered_data.pivot_table(index='Metric', columns='Tag', values='Count', fill_value=0)\n",
    "        text_data = filtered_data.pivot_table(index='Metric', columns='Tag', values='Count', fill_value=0).astype(int)\n",
    "\n",
    "        \n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Heatmap(\n",
    "                z=heatmap_data,\n",
    "                x=heatmap_data.columns,\n",
    "                y=heatmap_data.index,\n",
    "                colorscale='RdBu_r',\n",
    "                coloraxis=\"coloraxis\",  # Use a unified color axis\n",
    "                text=text_data,  # Add text annotations\n",
    "                texttemplate=\"%{text}\",  # Use the text values directly\n",
    "                hovertemplate=\"Metric: %{y}<br>Tag: %{x}<br>Count: %{text}<extra></extra>\",\n",
    "            ),\n",
    "            row=idx + 1, col=jdx + 1\n",
    "        )\n",
    "\n",
    "# Update layout with a unified color scale and adjust the color bar\n",
    "fig.update_layout(\n",
    "    coloraxis=dict(colorscale='RdBu_r', cmin=0, cmax=max_value, colorbar=dict(title=\"Counts\")),\n",
    "    title_text=\"Confusion Matrix Metrics by Tag, Dataset, and Scheme\",\n",
    "    template=\"plotly_white\",\n",
    "    height=700, width=700,\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bar confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_data = []\n",
    "for data, values in dash_data.items():\n",
    "    entity_matrix = pd.DataFrame(values.entity_non_strict_confusion_data['confusion_matrix']).T \n",
    "    entity_strict_matrix = pd.DataFrame(values.entity_strict_confusion_data['confusion_matrix']).T\n",
    "    entity_matrix['Dataset'] = data\n",
    "    entity_matrix['Scheme'] = 'IOB'\n",
    "    entity_strict_matrix['Dataset'] = data\n",
    "    entity_strict_matrix['Scheme'] = 'IOB2'\n",
    "    matrix_data.append(pd.concat([\n",
    "\t\tentity_matrix, \n",
    "\t\tentity_strict_matrix\n",
    "\t]))\n",
    "    \n",
    "matrix_df = pd.concat(matrix_data)\n",
    "matrix_df.reset_index(inplace=True)\n",
    "matrix_df.rename(columns={'index': 'Tag'}, inplace=True)\n",
    "\n",
    "matrix_df['Tag'] = matrix_df['Tag'].replace(tag_mapping)\n",
    "matrix_df['Dataset'] = matrix_df['Dataset'].replace(dataset_mapping)\n",
    "# Assuming 'matrix_df' has been set up as your DataFrame\n",
    "df = matrix_df.copy()\n",
    "\n",
    "# Calculate the sum of TP, FP, and FN per group for normalization purposes\n",
    "grouped = df.groupby(['Tag', 'Dataset', 'Scheme']).sum()\n",
    "grouped['Total'] = grouped['TP'] + grouped['FP'] + grouped['FN']\n",
    "\n",
    "# Merge the total back into the original DataFrame\n",
    "df = df.merge(grouped['Total'], on=['Tag', 'Dataset', 'Scheme'], how='left')\n",
    "\n",
    "# Store actual counts for displaying as text\n",
    "df['TP_Count'] = df['TP']\n",
    "df['FP_Count'] = df['FP']\n",
    "df['FN_Count'] = df['FN']\n",
    "\n",
    "# Normalize the TP, FP, FN values for plotting\n",
    "df['TP'] = df['TP'] / df['Total']\n",
    "df['FP'] = df['FP'] / df['Total']\n",
    "df['FN'] = df['FN'] / df['Total']\n",
    "\n",
    "# Melt the DataFrame for plotting\n",
    "df_long = df.melt(id_vars=[\"Tag\", \"Dataset\", \"Scheme\"], value_vars=[\"TP\", \"FP\", \"FN\"], var_name=\"Metric\", value_name=\"Scale\")\n",
    "df_counts = df.melt(id_vars=[\"Tag\", \"Dataset\", \"Scheme\"], value_vars=[\"TP_Count\", \"FP_Count\", \"FN_Count\"], var_name=\"Metric\", value_name=\"Count\")\n",
    "\n",
    "# Replace '_Count' to align with the other metric names\n",
    "df_counts['Metric'] = df_counts['Metric'].str.replace('_Count', '')\n",
    "\n",
    "# Merge percentage and actual count data\n",
    "df_long = df_long.merge(df_counts, on=[\"Tag\", \"Dataset\", \"Scheme\", \"Metric\"])\n",
    "\n",
    "# Creating the faceted bar plot with actual counts displayed on normalized bars\n",
    "fig = px.bar(df_long, x=\"Tag\", y=\"Scale\", color=\"Metric\",\n",
    "             facet_row=\"Scheme\", facet_col=\"Dataset\",\n",
    "             title=\"Confusion Matrix Metrics by Tag, Dataset, and Scheme\",\n",
    "             labels={\"Scale\": \"Scaled Counts\"},\n",
    "             barmode='group',\n",
    "             template=\"plotly_white\",\n",
    "             facet_row_spacing=0.1,  # Adjusted spacing\n",
    "             facet_col_spacing=0.08,\n",
    "             text='Count'  # Display the actual Count on top of each bar\n",
    "             )\n",
    "\n",
    "# Set text to display above bars\n",
    "# fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
    "fig.update_layout(\n",
    "    plot_bgcolor='rgba(255,255,255,1)',  # Ensure the background is white\n",
    "    paper_bgcolor='rgba(255,255,255,1)',  # Ensure the paper background is also white\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
